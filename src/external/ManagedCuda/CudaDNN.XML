<?xml version="1.0"?>
<doc>
    <assembly>
        <name>CudaDNN</name>
    </assembly>
    <members>
        <member name="T:ManagedCuda.CudaDNN.ActivationDescriptor">
            <summary>
            
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.ActivationDescriptor.#ctor">
            <summary>
            An opaque structure holding the description of an activation operation.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.ActivationDescriptor.Finalize">
            <summary>
            For dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.ActivationDescriptor.Dispose">
            <summary>
            Dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.ActivationDescriptor.Dispose(System.Boolean)">
            <summary>
            For IDisposable
            </summary>
            <param name="fDisposing"></param>
        </member>
        <member name="P:ManagedCuda.CudaDNN.ActivationDescriptor.Desc">
            <summary>
            Returns the inner handle.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.ActivationDescriptor.SetActivationDescriptor(ManagedCuda.CudaDNN.cudnnActivationMode,ManagedCuda.CudaDNN.cudnnNanPropagation,System.Double)">
            <summary>
             This function initializes then previously created activation descriptor object.
             </summary>
             <param name="mode">Enumerant to specify the activation mode.</param>
             <param name="reluNanOpt">Nan propagation option for the relu.</param>
             <param name="coef">floating point number to specify the clipping threashold when the activation
             mode is set to CUDNN_ACTIVATION_CLIPPED_RELU or to specify the alpha
             coefficient when the activation mode is set to CUDNN_ACTIVATION_ELU.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.ActivationDescriptor.GetActivationDescriptor(ManagedCuda.CudaDNN.cudnnActivationMode@,ManagedCuda.CudaDNN.cudnnNanPropagation@,System.Double@)">
            <summary>
            This function queries the parameters of the previouly initialized activation descriptor object.
            </summary>
            <param name="mode">Enumerant to specify the activation mode.</param>
            <param name="reluNanOpt">Nan propagation option for the relu.</param>
            <param name="coef">floating point number to specify the clipping threashold when the activation
            mode is set to CUDNN_ACTIVATION_CLIPPED_RELU or to specify the alpha
            coefficient when the activation mode is set to CUDNN_ACTIVATION_ELU.</param>
        </member>
        <member name="T:ManagedCuda.CudaDNN.ConvolutionDescriptor">
            <summary>
            An opaque structure holding the
            description of a convolution operation.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.ConvolutionDescriptor.#ctor">
            <summary>
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.ConvolutionDescriptor.Finalize">
            <summary>
            For dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.ConvolutionDescriptor.Dispose">
            <summary>
            Dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.ConvolutionDescriptor.Dispose(System.Boolean)">
            <summary>
            For IDisposable
            </summary>
            <param name="fDisposing"></param>
        </member>
        <member name="P:ManagedCuda.CudaDNN.ConvolutionDescriptor.Desc">
            <summary>
            Returns the inner handle.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.ConvolutionDescriptor.SetConvolution2dDescriptor(System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,ManagedCuda.CudaDNN.cudnnConvolutionMode,ManagedCuda.CudaDNN.cudnnDataType)">
            <summary>
            This function initializes a previously created convolution descriptor object into a 2D
            correlation. This function assumes that the tensor and filter descriptors corresponds
            to the formard convolution path and checks if their settings are valid. That same
            convolution descriptor can be reused in the backward path provided it corresponds to
            the same layer.
            </summary>
            <param name="pad_h">zero-padding height: number of rows of zeros implicitly concatenated
            onto the top and onto the bottom of input images.</param>
            <param name="pad_w">zero-padding width: number of columns of zeros implicitly concatenated
            onto the left and onto the right of input images.</param>
            <param name="u">Vertical filter stride.</param>
            <param name="v">Horizontal filter stride.</param>
            <param name="dilation_h">Filter height dilation.</param>
            <param name="dilation_w">Filter width dilation.</param>
            <param name="mode">Selects between CUDNN_CONVOLUTION and CUDNN_CROSS_CORRELATION.</param>
            <param name="dataType">Selects the datatype in which the computation will be done.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.ConvolutionDescriptor.GetConvolution2dDescriptor(System.Int32@,System.Int32@,System.Int32@,System.Int32@,System.Int32@,System.Int32@,ManagedCuda.CudaDNN.cudnnConvolutionMode@,ManagedCuda.CudaDNN.cudnnDataType@)">
            <summary>
            This function queries a previously initialized 2D convolution descriptor object.
            </summary>
            <param name="pad_h">zero-padding height: number of rows of zeros implicitly concatenated
            onto the top and onto the bottom of input images.</param>
            <param name="pad_w">zero-padding width: number of columns of zeros implicitly concatenated
            onto the left and onto the right of input images.</param>
            <param name="u">Vertical filter stride.</param>
            <param name="v">Horizontal filter stride.</param>
            <param name="dilation_h">Filter height dilation.</param>
            <param name="dilation_w">Filter width dilation.</param>
            <param name="mode">convolution mode.</param>
            <param name="dataType">Selects the datatype in which the computation will be done.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.ConvolutionDescriptor.GetConvolution2dForwardOutputDim(ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.FilterDescriptor,System.Int32@,System.Int32@,System.Int32@,System.Int32@)">
            <summary>
            This function returns the dimensions of the resulting 4D tensor of a 2D convolution,
            given the convolution descriptor, the input tensor descriptor and the filter descriptor
            This function can help to setup the output tensor and allocate the proper amount of
            memory prior to launch the actual convolution.<para/>
            Each dimension h and w of the output images is computed as followed:<para/>
            outputDim = 1 + (inputDim + 2*pad - filterDim)/convolutionStride;
            </summary>
            <param name="inputTensorDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="filterDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="n">Number of output images.</param>
            <param name="c">Number of output feature maps per image.</param>
            <param name="h">Height of each output feature map.</param>
            <param name="w">Width of each output feature map.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.ConvolutionDescriptor.SetConvolutionNdDescriptor(System.Int32,System.Int32[],System.Int32[],System.Int32[],ManagedCuda.CudaDNN.cudnnConvolutionMode,ManagedCuda.CudaDNN.cudnnDataType)">
            <summary>
            This function initializes a previously created generic convolution descriptor object into
            a n-D correlation. That same convolution descriptor can be reused in the backward path
            provided it corresponds to the same layer. The convolution computation will done in the
            specified dataType, which can be potentially different from the input/output tensors.
            </summary>
            <param name="arrayLength">Dimension of the convolution.</param>
            <param name="padA">Array of dimension arrayLength containing the zero-padding size
            for each dimension. For every dimension, the padding represents the
            number of extra zeros implicitly concatenated at the start and at the
            end of every element of that dimension.</param>
            <param name="filterStrideA">Array of dimension arrayLength containing the filter stride for each
            dimension. For every dimension, the fitler stride represents the number
            of elements to slide to reach the next start of the filtering window of
            the next point.</param>
            <param name="dilationA">Array of dimension arrayLength containing the dilation factor for each dimension.</param>
            <param name="mode">Selects between CUDNN_CONVOLUTION and CUDNN_CROSS_CORRELATION.</param>
            <param name="computeType">Selects the datatype in which the computation will be done.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.ConvolutionDescriptor.GetConvolutionNdDescriptor(System.Int32,System.Int32@,System.Int32[],System.Int32[],System.Int32[],ManagedCuda.CudaDNN.cudnnConvolutionMode@,ManagedCuda.CudaDNN.cudnnDataType@)">
            <summary>
            This function queries a previously initialized convolution descriptor object.
            </summary>
            <param name="arrayLengthRequested">Dimension of the expected convolution descriptor. It is also the
            minimum size of the arrays padA, filterStrideA and upsacleA in
            order to be able to hold the results</param>
            <param name="arrayLength">actual dimension of the convolution descriptor.</param>
            <param name="padA">Array of dimension of at least arrayLengthRequested that will be
            filled with the padding parameters from the provided convolution
            descriptor.</param>
            <param name="strideA">Array of dimension of at least arrayLengthRequested that will be
            filled with the filter stride from the provided convolution descriptor.</param>
            <param name="dilationA">Array of dimension at least arrayLengthRequested that will be filled
            with the dilation parameters from the provided convolution descriptor.</param>
            <param name="mode">convolution mode of the provided descriptor.</param>
            <param name="computeType">datatype of the provided descriptor.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.ConvolutionDescriptor.GetConvolutionNdForwardOutputDim(ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.FilterDescriptor,System.Int32,System.Int32[])">
            <summary>
            This function returns the dimensions of the resulting n-D tensor of a nbDims-2-D
            convolution, given the convolution descriptor, the input tensor descriptor and the filter
            descriptor This function can help to setup the output tensor and allocate the proper
            amount of memory prior to launch the actual convolution.<para/>
            Each dimension of the (nbDims-2)-D images of the output tensor is computed as
            followed:<para/>
            outputDim = 1 + (inputDim + 2*pad - filterDim)/convolutionStride;
            </summary>
            <param name="inputTensorDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="filterDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="nbDims">Dimension of the output tensor</param>
            <param name="tensorOuputDimA">Array of dimensions nbDims that contains on exit of this routine the sizes
            of the output tensor</param>
        </member>
        <member name="P:ManagedCuda.CudaDNN.ConvolutionDescriptor.MathType">
            <summary>
            The math type specified in a given convolution descriptor.
            </summary>
        </member>
        <member name="P:ManagedCuda.CudaDNN.ConvolutionDescriptor.GroupCount">
            <summary>
            This function allows the user to specify the number of groups to be used in the associated convolution.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.CTCLossDescriptor">
            <summary>
            
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CTCLossDescriptor.#ctor(ManagedCuda.CudaDNN.CudaDNNContext)">
            <summary>
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CTCLossDescriptor.Finalize">
            <summary>
            For dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CTCLossDescriptor.Dispose">
            <summary>
            Dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CTCLossDescriptor.Dispose(System.Boolean)">
            <summary>
            For IDisposable
            </summary>
            <param name="fDisposing"></param>
        </member>
        <member name="P:ManagedCuda.CudaDNN.CTCLossDescriptor.Desc">
            <summary>
            Returns the inner handle.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CTCLossDescriptor.SetCTCLossDescriptor(ManagedCuda.CudaDNN.cudnnDataType)">
            <summary>
            This function initializes a previously created CTC Loss descriptor object.
            </summary>
            <param name="dataType">Math precision.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CTCLossDescriptor.CTCLoss(ManagedCuda.CudaDNN.CudaDNNContext,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},System.Int32[],System.Int32[],System.Int32[],ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.cudnnCTCLossAlgo,ManagedCuda.CudaDeviceVariable{System.Byte})">
            <summary>
            This function returns the ctc costs and gradients, given the probabilities and labels.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="probsDesc">Handle to the previously initialized probabilities tensor descriptor.</param>
            <param name="probs">Pointer to a previously initialized probabilities tensor.</param>
            <param name="labels">Pointer to a previously initialized labels list.</param>
            <param name="labelLengths">Pointer to a previously initialized lengths list, to walk the above labels list.</param>
            <param name="inputLengths">Pointer to a previously initialized list of the lengths of the timing steps in each batch.</param>
            <param name="costs">Pointer to the computed costs of CTC.</param>
            <param name="gradientsDesc">Handle to a previously initialized gradients tensor descriptor.</param>
            <param name="gradients">Pointer to the computed gradients of CTC.</param>
            <param name="algo">Enumerant that specifies the chosen CTC loss algorithm.</param>
            <param name="workspace">Pointer to GPU memory of a workspace needed to able to execute the specified algorithm.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CTCLossDescriptor.CTCLoss(ManagedCuda.CudaDNN.CudaDNNContext,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},System.Int32[],System.Int32[],System.Int32[],ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.cudnnCTCLossAlgo,ManagedCuda.CudaDeviceVariable{System.Byte})">
            <summary>
            This function returns the ctc costs and gradients, given the probabilities and labels.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="probsDesc">Handle to the previously initialized probabilities tensor descriptor.</param>
            <param name="probs">Pointer to a previously initialized probabilities tensor.</param>
            <param name="labels">Pointer to a previously initialized labels list.</param>
            <param name="labelLengths">Pointer to a previously initialized lengths list, to walk the above labels list.</param>
            <param name="inputLengths">Pointer to a previously initialized list of the lengths of the timing steps in each batch.</param>
            <param name="costs">Pointer to the computed costs of CTC.</param>
            <param name="gradientsDesc">Handle to a previously initialized gradients tensor descriptor.</param>
            <param name="gradients">Pointer to the computed gradients of CTC.</param>
            <param name="algo">Enumerant that specifies the chosen CTC loss algorithm.</param>
            <param name="workspace">Pointer to GPU memory of a workspace needed to able to execute the specified algorithm.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CTCLossDescriptor.CTCLoss(ManagedCuda.CudaDNN.CudaDNNContext,ManagedCuda.CudaDNN.TensorDescriptor,System.Int32[],System.Int32[],System.Int32[],ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.cudnnCTCLossAlgo)">
            <summary>
            return the workspace size needed for ctc
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="probsDesc">Handle to the previously initialized probabilities tensor descriptor.</param>
            <param name="gradientsDesc">Handle to a previously initialized gradients tensor descriptor.</param>
            <param name="labels">Pointer to a previously initialized labels list.</param>
            <param name="labelLengths">Pointer to a previously initialized lengths list, to walk the above labels list.</param>
            <param name="inputLengths">Pointer to a previously initialized list of the lengths of the timing steps in each batch.</param>
            <param name="algo">Enumerant that specifies the chosen CTC loss algorithm</param>
            <returns>Amount of GPU memory needed as workspace to be able to execute the CTC
            loss computation with the specified algo.</returns>
        </member>
        <member name="T:ManagedCuda.CudaDNN.CudaDNNContext">
            <summary>
            An opaque structure holding the cuDNN library context.<para/>
            The cuDNN library context must be created using cudnnCreate() and the returned
            handle must be passed to all subsequent library function calls. The context should be
            destroyed at the end using cudnnDestroy(). The context is associated with only one
            GPU device, the current device at the time of the call to cudnnCreate(). However
            multiple contexts can be created on the same GPU device.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.#ctor">
            <summary>
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.Finalize">
            <summary>
            For dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.Dispose">
            <summary>
            Dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.Dispose(System.Boolean)">
            <summary>
            For IDisposable
            </summary>
            <param name="fDisposing"></param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.SetStream(ManagedCuda.CudaStream)">
            <summary>
            This function sets the stream to be used by the cudnn library to execute its routines.
            </summary>
            <param name="stream">the stream to be used by the library.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.GetStream">
            <summary>
            This function gets the stream to be used by the cudnn library to execute its routines.
            </summary>
        </member>
        <member name="P:ManagedCuda.CudaDNN.CudaDNNContext.Handle">
            <summary>
            Returns the inner handle.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.TransformTensor(System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single})">
            <summary>
            This function copies the scaled data from one tensor to another tensor with a different
            layout. Those descriptors need to have the same dimensions but not necessarily the
            same strides. The input and output tensors must not overlap in any way (i.e., tensors
            cannot be transformed in place). This function can be used to convert a tensor with an
            unsupported format to a supported one.
            </summary>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the source
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*srcValue + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="xDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="x">Pointer to data of the tensor described by the srcDesc descriptor.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the source
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*srcValue + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="y">Pointer to data of the tensor described by the destDesc descriptor.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.AddTensor(System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single})">
            <summary>
            This function adds the scaled values of one bias tensor to another tensor. Each dimension
            of the bias tensor must match the coresponding dimension of the srcDest tensor or
            must be equal to 1. In the latter case, the same value from the bias tensor for thoses
            dimensions will be used to blend into the srcDest tensor.
            </summary>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the source
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*srcValue + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="aDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="a">Pointer to data of the tensor described by the biasDesc descriptor.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the source
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*srcValue + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="cDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="c">Pointer to data of the tensor described by the srcDestDesc descriptor.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.SetTensor(ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},System.Single)">
            <summary>
            This function sets all the elements of a tensor to a given value
            </summary>
            <param name="yDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="y">Pointer to data of the tensor described by the srcDestDesc descriptor.</param>
            <param name="value">Pointer in Host memory to a value that all elements of the tensor will be set to.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.ScaleTensor(ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},System.Single)">
            <summary>
            This function scale all the elements of a tensor by a give factor.
            </summary>
            <param name="yDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="y">Pointer to data of the tensor described by the srcDestDesc descriptor.</param>
            <param name="alpha">Pointer in Host memory to a value that all elements of the tensor will be scaled with.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.ConvolutionForward(System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.ConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgo,ManagedCuda.CudaDeviceVariable{System.Byte},System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single})">
            <summary>
            This function executes convolutions or cross-correlations over src using the specified
            filters, returning results in dest. Scaling factors alpha and beta can be used to scale
            the input tensor and the output tensor respectively.
            </summary>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="xDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor filterDesc.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="algo">Enumerant that specifies which convolution algorithm shoud be used to compute the results</param>
            <param name="workSpace">Data pointer to GPU memory to a workspace needed to able to execute
            the specified algorithm. If no workspace is needed for a particular
            algorithm, that pointer can be nil</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the tensor descriptor
            destDesc that carries the result of the convolution.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.ConvolutionBackwardBias(System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single})">
            <summary>
            This function computes the convolution gradient with respect to the bias, which is the
            sum of every element belonging to the same feature map across all of the images of the
            input tensor. Therefore, the number of elements produced is equal to the number of
            features maps of the input tensor.
            </summary>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dyDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="dy">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dbDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="db">Data pointer to GPU memory associated with the output tensor descriptor destDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.ConvolutionBackwardFilter(System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.ConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterAlgo,ManagedCuda.CudaDeviceVariable{System.Byte},System.Single,ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDeviceVariable{System.Single})">
            <summary>
            This function computes the convolution gradient with respect to filter coefficients using
            the specified algo, returning results in gradDesc.Scaling factors alpha and beta can be
            used to scale the input tensor and the output tensor respectively.
            </summary>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="xDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="dy">Data pointer to GPU memory associated with the input differential tensor descriptor diffDesc.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="algo">Enumerant that specifies which convolution algorithm shoud be used to compute the results</param>
            <param name="workSpace">Data pointer to GPU memory to a workspace needed to able to execute
            the specified algorithm. If no workspace is needed for a particular
            algorithm, that pointer can be nil</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dwDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="dw">Data pointer to GPU memory associated with the filter descriptor
            gradDesc that carries the result.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.ConvolutionBackwardData(System.Single,ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.ConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionBwdDataAlgo,ManagedCuda.CudaDeviceVariable{System.Byte},System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single})">
            <summary>
            This function computes the convolution gradient with respect to the output tensor using
            the specified algo, returning results in gradDesc. Scaling factors alpha and beta can
            be used to scale the input tensor and the output tensor respectively.
            </summary>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor filterDesc.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="dy">Data pointer to GPU memory associated with the input differential tensor descriptor diffDesc.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="algo">Enumerant that specifies which backward data convolution algorithm shoud be used to compute the results</param>
            <param name="workSpace">Data pointer to GPU memory to a workspace needed to able to execute
            the specified algorithm. If no workspace is needed for a particular
            algorithm, that pointer can be nil</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dxDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="dx">Data pointer to GPU memory associated with the output tensor descriptor
            gradDesc that carries the result.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.Im2Col(ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDNN.ConvolutionDescriptor,ManagedCuda.CudaDeviceVariable{System.Byte})">
            <summary>
            
            </summary>
            <param name="srcDesc"></param>
            <param name="srcData"></param>
            <param name="filterDesc"></param>
            <param name="convDesc"></param>
            <param name="colBuffer"></param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.SoftmaxForward(ManagedCuda.CudaDNN.cudnnSoftmaxAlgorithm,ManagedCuda.CudaDNN.cudnnSoftmaxMode,System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single})">
            <summary>
            This routine computes the softmax function.
            </summary>
            <param name="algorithm">Enumerant to specify the softmax algorithm.</param>
            <param name="mode">Enumerant to specify the softmax mode.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor destDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.SoftmaxBackward(ManagedCuda.CudaDNN.cudnnSoftmaxAlgorithm,ManagedCuda.CudaDNN.cudnnSoftmaxMode,System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single})">
            <summary>
            This routine computes the gradient of the softmax function.
            </summary>
            <param name="algorithm">Enumerant to specify the softmax algorithm.</param>
            <param name="mode">Enumerant to specify the softmax mode.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="dy">Data pointer to GPU memory associated with the tensor descriptor srcDiffData.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dxDesc">Handle to the previously initialized output differential tensor descriptor.</param>
            <param name="dx">Data pointer to GPU memory associated with the output tensor descriptor destDiffDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.PoolingForward(ManagedCuda.CudaDNN.PoolingDescriptor,System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single})">
            <summary>
            This function computes pooling of input values (i.e., the maximum or average of several
            adjacent values) to produce an output with smaller height and/or width.
            </summary>
            <param name="poolingDesc">Handle to a previously initialized pooling descriptor.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor destDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.PoolingBackward(ManagedCuda.CudaDNN.PoolingDescriptor,System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single})">
            <summary>
            This function computes the gradient of a pooling operation.
            </summary>
            <param name="poolingDesc">Handle to the previously initialized pooling descriptor.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="dy">Data pointer to GPU memory associated with the tensor descriptor srcDiffData.</param>
            <param name="xDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the output tensor descriptor destDesc.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dxDesc">Handle to the previously initialized output differential tensor descriptor.</param>
            <param name="dx">Data pointer to GPU memory associated with the output tensor descriptor destDiffDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.ActivationForward(ManagedCuda.CudaDNN.ActivationDescriptor,System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single})">
            <summary>
            This routine applies a specified neuron activation function element-wise over each input value.
            </summary>
            <param name="activationDesc">Handle to the previously created activation descriptor object.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor destDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.ActivationBackward(ManagedCuda.CudaDNN.ActivationDescriptor,System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single})">
            <summary>
            This routine computes the gradient of a neuron activation function.
            </summary>
            <param name="activationDesc">Handle to the previously created activation descriptor object.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="dy">Data pointer to GPU memory associated with the tensor descriptor srcDiffData.</param>
            <param name="xDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the output tensor descriptor destDesc.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dxDesc">Handle to the previously initialized output differential tensor descriptor.</param>
            <param name="dx">Data pointer to GPU memory associated with the output tensor descriptor destDiffDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.DeriveBNTensorDescriptor(ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.cudnnBatchNormMode)">
            <summary>
            Derives a tensor descriptor from layer data descriptor for BatchNormalization 
            scale, invVariance, bnBias, bnScale tensors.Use this tensor desc for 
            bnScaleBiasMeanVarDesc and bnScaleBiasDiffDesc in Batch Normalization forward and backward functions.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.BatchNormalizationForwardTraining(ManagedCuda.CudaDNN.cudnnBatchNormMode,System.Single,System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDeviceVariable{System.Single},System.Double,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDeviceVariable{System.Single},System.Double,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDeviceVariable{System.Single})">
            <summary>
            This function performs the forward BatchNormalization layer computation for the training phase. 
            This layer is based on the paper "Batch Normalization: Accelerating Deep Network Training by 
            Reducing Internal Covariate Shift", S. Ioffe, C. Szegedy, 2015.
            </summary>
            <param name="mode"> Mode of operation (spatial or per-activation). </param>
            <param name="alpha"> Pointer to scaling factors (in host memory) used to blend the layer output value with prior value in the destination tensor as follows: dstValue = alpha[0]*resultValue + beta[0]*priorDstValue. </param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the layer output value with prior value in the destination tensor as follows: dstValue = alpha[0]*resultValue + beta[0]*priorDstValue. </param>
            <param name="xDesc">Tensor descriptor layer's x data.</param>
            <param name="x">Pointer in device memory for the layer's x data.</param>
            <param name="yDesc">Tensor descriptor the layer's y data.</param>
            <param name="y">Pointer in device memory for the layer's y data.</param>
            <param name="bnScaleBiasMeanVarDesc">Shared tensor descriptor desc for all the 6 tensors below in the argument list. The dimensions for this tensor descriptor are dependent on the normalization mode.</param>
            <param name="bnScale">Pointer in device memory for the batch normalization scale parameters (in original paper scale is referred to as gamma).</param>
            <param name="bnBias">Pointers in device memory for the batch normalization bias parameters (in original paper bias is referred to as beta). Note that bnBias parameter can replace the previous layer's bias parameter for improved efficiency. </param>
            <param name="exponentialAverageFactor">Factor used in the moving average computation runningMean = newMean*factor + runningMean*(1-factor). Use a factor=1/(1+n) at Nth call to the function to get Cumulative Moving Average (CMA) behavior CMA[n] = (x[1]+...+x[n])/n. Since CMA[n+1] = (n*CMA[n]+x[n+1])/(n+1)= ((n+1)*CMA[n]-CMA[n])/(n+1) + x[n+1]/(n+1) = CMA[n]*(1-1/(n+1))+x[n +1]*1/(n+1)</param>
            <param name="resultRunningMean">Running mean tensor (it has the same descriptor as the bias and scale). If this tensor is initially uninitialized, it is required that exponentialAverageFactor=1 is used for the very first call of a complete training cycle. This is necessary to properly initialize the moving average. Both resultRunningMean and resultRunningInvVariance can be NULL but only at the same time.</param>
            <param name="resultRunningVariance">Running variance tensor (it has the same descriptor as the bias and scale). If this tensors is initially uninitialized, it is required that exponentialAverageFactor=1 is used for the very first call of a complete training cycle. This is necessary to properly initialize the moving average. Both resultRunningMean and resultRunningInvVariance can be NULL but only at the same time. The value stored in resultRunningInvVariance (or passed as an input in inference mode) is the moving average of the expression 1 / sqrt(eps+variance[x]) where variance is computed either over batch or spatial+batch dimensions depending on the mode. </param>
            <param name="epsilon">Epsilon value used in the batch normalization formula. Minimum allowed value is currently 1e-5. Same epsilon value should be used in forward and backward functions.</param>
            <param name="resultSaveMean">Optional cache to save intermediate results computed during the forward pass - these can then be reused to speed up the backward pass. For this to work correctly, the bottom layer data has to remain unchanged until the backward function is called. Note that both resultSaveMean and resultSaveInvVariance can be NULL but only at the same time. It is recommended to use this cache since memory overhead is relatively small because these tensors have a much lower product of dimensions than the data tensors.</param>
            <param name="resultSaveVariance">Optional cache to save intermediate results computed during the forward pass - these can then be reused to speed up the backward pass. For this to work correctly, the bottom layer data has to remain unchanged until the backward function is called. Note that both resultSaveMean and resultSaveInvVariance can be NULL but only at the same time. It is recommended to use this cache since memory overhead is relatively small because these tensors have a much lower product of dimensions than the data tensors.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.BatchNormalizationForwardInference(ManagedCuda.CudaDNN.cudnnBatchNormMode,System.Single,System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDeviceVariable{System.Single},System.Double)">
            <summary>
            This function performs the forward BatchNormalization layer computation for the inference phase. 
            This layer is based on the paper "Batch Normalization: Accelerating Deep Network 
            Training by Reducing Internal Covariate Shift", S. Ioffe, C. Szegedy, 2015.
            </summary>
            <param name="mode"> Mode of operation (spatial or per-activation). </param>
            <param name="alpha"> Pointer to scaling factors (in host memory) used to blend the layer output value with prior value in the destination tensor as follows: dstValue = alpha[0]*resultValue + beta[0]*priorDstValue. </param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the layer output value with prior value in the destination tensor as follows: dstValue = alpha[0]*resultValue + beta[0]*priorDstValue. </param>
            <param name="xDesc">Tensor descriptor layer's x data.</param>
            <param name="x">Pointer in device memory for the layer's x data.</param>
            <param name="yDesc">Tensor descriptor the layer's y data.</param>
            <param name="y">Pointer in device memory for the layer's y data.</param>
            <param name="bnScaleBiasMeanVarDesc">Shared tensor descriptor desc for all the 4 tensors below in the argument list. The dimensions for this tensor descriptor are dependent on the normalization mode.</param>
            <param name="bnScale">Pointer in device memory for the batch normalization scale parameters (in original paper scale is referred to as gamma).</param>
            <param name="bnBias">Pointers in device memory for the batch normalization bias parameters (in original paper bias is referred to as beta). Note that bnBias parameter can replace the previous layer's bias parameter for improved efficiency. </param>
            <param name="estimatedMean">Mean tensor (has the same descriptor as the bias and scale). It is suggested that resultRunningMean from the cudnnBatchNormalizationForwardTraining call accumulated during the training phase be passed as input here.</param>
            <param name="estimatedVariance">Variance tensor (has the same descriptor as the bias and scale). It is suggested that resultRunningVariance from the cudnnBatchNormalizationForwardTraining call accumulated during the training phase be passed as input here.</param>
            <param name="epsilon">Epsilon value used in the batch normalization formula. Minimum allowed value is currently 1e-5. Same epsilon value should be used in forward and backward functions.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.BatchNormalizationBackward(ManagedCuda.CudaDNN.cudnnBatchNormMode,System.Single,System.Single,System.Single,System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDeviceVariable{System.Single},System.Double,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDeviceVariable{System.Single})">
            <summary>
            This function performs the backward BatchNormalization layer computation.
            </summary>
            <param name="mode"> Mode of operation (spatial or per-activation). </param>
            <param name="alphaDataDiff">Pointer to scaling factors in host memory used to blend the gradient output dx with a prior value in the destination tensor as follows: dstValue = alpha[0]*resultValue + beta[0]*priorDstValue.</param>
            <param name="betaDataDiff">Pointer to scaling factors in host memory used to blend the gradient output dx with a prior value in the destination tensor as follows: dstValue = alpha[0]*resultValue + beta[0]*priorDstValue.</param>
            <param name="alphaParamDiff">Pointer to scaling factors (in host memory) used to blend the gradient outputs dBnScaleResult and dBnBiasResult with prior values in the destination tensor as follows: dstValue = alpha[0]*resultValue + beta[0]*priorDstValue.</param>
            <param name="betaParamDiff">Pointer to scaling factors (in host memory) used to blend the gradient outputs dBnScaleResult and dBnBiasResult with prior values in the destination tensor as follows: dstValue = alpha[0]*resultValue + beta[0]*priorDstValue.</param>
            <param name="xDesc">Tensor descriptor for the layer's x data.</param>
            <param name="x">Pointers in device memory for the layer's x data.</param>
            <param name="dyDesc">Tensor descriptor for the layer's backpropagated differential dy (inputs).</param>
            <param name="dy">Pointers in device memory for the layer's backpropagated differential dy (inputs).</param>
            <param name="dxDesc">Tensor descriptor for the layer's resulting differential with respect to x, dx (output).</param>
            <param name="dx">Pointer in device memory for the layer's resulting differential with respect to x, dx (output).</param>
            <param name="dBnScaleBiasDesc">Shared tensor descriptor for all the 5 tensors below in the argument list (bnScale, resultBnScaleDiff, resultBnBiasDiff, savedMean, savedInvVariance). The dimensions for this tensor descriptor are dependent on normalization mode. Note: The data type of this tensor descriptor must be 'float' for FP16 and FP32 input tensors, and 'double' for FP64 input tensors.</param>
            <param name="bnScale">Pointers in device memory for the batch normalization scale parameter (in original paper bias is referred to as gamma). Note that bnBias parameter is not needed for this layer's computation.</param>
            <param name="dBnScaleResult">Pointer in device memory for the resulting scale differentials computed by this routine. Note that scale and bias gradients are not backpropagated below this layer (since they are dead-end computation DAG nodes).</param>
            <param name="dBnBiasResult">Pointer in device memory for the resulting bias differentials computed by this routine. Note that scale and bias gradients are not backpropagated below this layer (since they are dead-end computation DAG nodes).</param>
            <param name="epsilon">Epsilon value used in the batch normalization formula. Minimum allowed value is currently 1e-5. Same epsilon value should be used in forward and backward functions.</param>
            <param name="savedMean">Optional cache parameter saved intermediate results computed during the forward pass. For this to work correctly, the layer's x and bnScale, bnBias data has to remain unchanged until the backward function is called. Note that both savedMean and savedInvVariance parameters can be NULL but only at the same time. It is recommended to use this cache since the memory overhead is relatively small.</param>
            <param name="savedInvVariance">Optional cache parameter saved intermediate results computed during the forward pass. For this to work correctly, the layer's x and bnScale, bnBias data has to remain unchanged until the backward function is called. Note that both savedMean and savedInvVariance parameters can be NULL but only at the same time. It is recommended to use this cache since the memory overhead is relatively small.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.OpTensor(ManagedCuda.CudaDNN.OpTensorDescriptor,System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single})">
            <summary>
            This function implements the equation C = op(alpha1[0] * A, alpha2[0] * B) + beta[0] * C, 
            given tensors A, B, and C and scaling factors alpha1, alpha2, and beta.The op to use is 
            indicated by the descriptor opTensorDesc.Currently-supported ops are listed by the 
            cudnnOpTensorOp_t enum. Each dimension of the input tensor A must match the corresponding 
            dimension of the destination tensor C, and each dimension of the input tensor B must match 
            the corresponding dimension of the destination tensor C or must be equal to 1. In the latter 
            case, the same value from the input tensor B for those dimensions will be used to blend into the 
            C tensor.The data types of the input tensors A and B must match. If the data type of the 
            destination tensor C is double, then the data type of the input tensors also must be double. If 
            the data type of the destination tensor C is double, then opTensorCompType in opTensorDesc must 
            be double. Else opTensorCompType must be float. If the input tensor B is the same tensor as 
            the destination tensor C, then the input tensor A also must be the same tensor as the 
            destination tensor C.
            </summary>
            <param name="op_desc">Handle to a previously initialized op tensor descriptor.</param>
            <param name="alpha1">Pointer to the scaling factor(in host memory) used to blend the source value with prior 
            value in the destination tensor as indicated by the above op equation.</param>
            <param name="a_desc">Handle to a previously initialized tensor descriptor.</param>
            <param name="a">Pointer to data of the tensor described by the a_desc.</param>
            <param name="alpha2">Pointer to the scaling factor(in host memory) used to blend the source value with prior 
            value in the destination tensor as indicated by the above op equation.</param>
            <param name="b_desc">Handle to a previously initialized tensor descriptor.</param>
            <param name="b">Pointer to data of the tensor described by the b_desc.</param>
            <param name="beta">Pointer to the scaling factor(in host memory) used to blend the source value with prior 
            value in the destination tensor as indicated by the above op equation.</param>
            <param name="c_desc">Handle to a previously initialized tensor descriptor.</param>
            <param name="c">Output pointer to data of the tensor described by the c_desc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.ConvolutionBiasActivationForward(System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.ConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgo,ManagedCuda.CudaDeviceVariable{System.Byte},System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.ActivationDescriptor,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single})">
            <summary>
            This function applies a bias and then an activation to the convolutions or crosscorrelations
            of cudnnConvolutionForward(), returning results in y.The full computation
            follows the equation y = act(alpha1* conv(x) + alpha2* z + bias ).<para/>
            The routine cudnnGetConvolution2dForwardOutputDim or
            cudnnGetConvolutionNdForwardOutputDim can be used to determine the proper
            dimensions of the output tensor descriptor yDesc with respect to xDesc, convDesc and wDesc.
            </summary>
            <param name="alpha1">Pointers to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as described by the above equation.</param>
            <param name="xDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor xDesc.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor wDesc.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="algo">Enumerant that specifies which convolution algorithm shoud be used to compute the results</param>
            <param name="workSpace">Data pointer to GPU memory to a workspace needed to able to execute
            the specified algorithm.If no workspace is needed for a particular
            algorithm, that pointer can be nil</param>
            <param name="alpha2">Pointers to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as described by the above equation.</param>
            <param name="zDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="z">Data pointer to GPU memory associated with the tensor descriptor zDesc.</param>
            <param name="biasDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="bias">Data pointer to GPU memory associated with the tensor descriptor biasDesc.</param>
            <param name="activationDesc">Handle to a previously initialized activation descriptor.</param>
            <param name="yDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the tensor descriptor yDesc
            that carries the result of the convolution.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.ReduceTensor(ManagedCuda.CudaDNN.ReduceTensorDescriptor,ManagedCuda.CudaDeviceVariable{System.UInt32},ManagedCuda.CudaDeviceVariable{System.Byte},ManagedCuda.BasicTypes.SizeT,System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},System.Single,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single})">
            <summary>
            This function reduces tensor A by implementing the equation C = alpha * reduce op ( A )
            + beta* C, given tensors A and C and scaling factors alpha and beta.The reduction op
            to use is indicated by the descriptor reduceTensorDesc.Currently-supported ops are
            listed by the cudnnReduceTensorOp_t enum.
            </summary>
            <param name="reduceTensorDesc">Handle to a previously initialized reduce tensor descriptor.</param>
            <param name="indices">Handle to a previously allocated space for writing indices.</param>
            <param name="workspace">Handle to a previously allocated space for the reduction implementation.</param>
            <param name="workspaceSizeInBytes">Size of the above previously allocated space.</param>
            <param name="alpha">Pointer to scaling factor (in host memory) used to blend the source value
            with prior value in the destination tensor as indicated by the above op equation.</param>
            <param name="aDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="A">Pointer to data of the tensor described by the aDesc descriptor.</param>
            <param name="beta">Pointer to scaling factor (in host memory) used to blend the source value
            with prior value in the destination tensor as indicated by the above op equation.</param>
            <param name="cDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="C">Pointer to data of the tensor described by the cDesc descriptor.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.DropoutForward(ManagedCuda.CudaDNN.DropoutDescriptor,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDeviceVariable{System.Byte})">
            <summary>  
            This function performs forward dropout operation over x returning results in y. If dropout was   
            used as a parameter to cudnnSetDropoutDescriptor, the approximately dropout fraction of x values   
            will be replaces by 0, and the rest will be scaled by 1/(1-dropout) This function should not be   
            running concurrently with another cudnnDropoutForward function using the same states.  
            </summary>  
            <param name="dropoutDesc">Handle to a previously created dropout descriptor object.</param>  
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>  
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>  
            <param name="yDesc">Handle to the previously initialized output tensor descriptor.</param>  
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor destDesc.</param>  
            <param name="reserveSpace">Data pointer to GPU memory used by this function. It is expected that contents of reserveSpace doe not change between cudnnDropoutForward and cudnnDropoutBackward calls.</param>  
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.DropoutBackward(ManagedCuda.CudaDNN.DropoutDescriptor,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDeviceVariable{System.Byte})">
            <summary>  
            This function performs backward dropout operation over dy returning results in dx. If during   
            forward dropout operation value from x was propagated to y then during backward operation value   
            from dy will be propagated to dx, otherwise, dx value will be set to 0.  
            </summary>  
            <param name="dropoutDesc">Handle to a previously created dropout descriptor object.</param>  
            <param name="dyDesc">Handle to a previously initialized tensor descriptor.</param>  
            <param name="dy">Pointer to data of the tensor described by the dyDesc descriptor.</param>  
            <param name="dxDesc">Handle to a previously initialized tensor descriptor.</param>  
            <param name="dx">Pointer to data of the tensor described by the dxDesc descriptor.</param>  
            <param name="reserveSpace">Data pointer to GPU memory used by this function. It is expected that contents of reserveSpace doe not change between cudnnDropoutForward and cudnnDropoutBackward calls.</param>  
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.TransformTensor(System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double})">
            <summary>
            This function copies the scaled data from one tensor to another tensor with a different
            layout. Those descriptors need to have the same dimensions but not necessarily the
            same strides. The input and output tensors must not overlap in any way (i.e., tensors
            cannot be transformed in place). This function can be used to convert a tensor with an
            unsupported format to a supported one.
            </summary>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the source
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*srcValue + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="xDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="x">Pointer to data of the tensor described by the srcDesc descriptor.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the source
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*srcValue + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="y">Pointer to data of the tensor described by the destDesc descriptor.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.AddTensor(System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double})">
            <summary>
            This function adds the scaled values of one bias tensor to another tensor. Each dimension
            of the bias tensor must match the coresponding dimension of the srcDest tensor or
            must be equal to 1. In the latter case, the same value from the bias tensor for thoses
            dimensions will be used to blend into the srcDest tensor.
            </summary>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the source
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*srcValue + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="aDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="a">Pointer to data of the tensor described by the biasDesc descriptor.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the source
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*srcValue + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="cDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="c">Pointer to data of the tensor described by the srcDestDesc descriptor.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.SetTensor(ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},System.Double)">
            <summary>
            This function sets all the elements of a tensor to a given value
            </summary>
            <param name="yDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="y">Pointer to data of the tensor described by the srcDestDesc descriptor.</param>
            <param name="value">Pointer in Host memory to a value that all elements of the tensor will be set to.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.ScaleTensor(ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},System.Double)">
            <summary>
            This function scale all the elements of a tensor by a give factor.
            </summary>
            <param name="yDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="y">Pointer to data of the tensor described by the srcDestDesc descriptor.</param>
            <param name="alpha">Pointer in Host memory to a value that all elements of the tensor will be scaled with.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.ConvolutionForward(System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.ConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgo,ManagedCuda.CudaDeviceVariable{System.Byte},System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double})">
            <summary>
            This function executes convolutions or cross-correlations over src using the specified
            filters, returning results in dest. Scaling factors alpha and beta can be used to scale
            the input tensor and the output tensor respectively.
            </summary>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="xDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor filterDesc.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="algo">Enumerant that specifies which convolution algorithm shoud be used to compute the results</param>
            <param name="workSpace">Data pointer to GPU memory to a workspace needed to able to execute
            the specified algorithm. If no workspace is needed for a particular
            algorithm, that pointer can be nil</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the tensor descriptor
            destDesc that carries the result of the convolution.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.ConvolutionBackwardBias(System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double})">
            <summary>
            This function computes the convolution gradient with respect to the bias, which is the
            sum of every element belonging to the same feature map across all of the images of the
            input tensor. Therefore, the number of elements produced is equal to the number of
            features maps of the input tensor.
            </summary>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dyDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="dy">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dbDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="db">Data pointer to GPU memory associated with the output tensor descriptor destDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.ConvolutionBackwardFilter(System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.ConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterAlgo,ManagedCuda.CudaDeviceVariable{System.Byte},System.Double,ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDeviceVariable{System.Double})">
            <summary>
            This function computes the convolution gradient with respect to filter coefficients using
            the specified algo, returning results in gradDesc.Scaling factors alpha and beta can be
            used to scale the input tensor and the output tensor respectively.
            </summary>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="xDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="dy">Data pointer to GPU memory associated with the input differential tensor descriptor diffDesc.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="algo">Enumerant that specifies which convolution algorithm shoud be used to compute the results</param>
            <param name="workSpace">Data pointer to GPU memory to a workspace needed to able to execute
            the specified algorithm. If no workspace is needed for a particular
            algorithm, that pointer can be nil</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dwDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="dw">Data pointer to GPU memory associated with the filter descriptor
            gradDesc that carries the result.</param>    
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.ConvolutionBackwardData(System.Double,ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.ConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionBwdDataAlgo,ManagedCuda.CudaDeviceVariable{System.Byte},System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double})">
            <summary>
            This function computes the convolution gradient with respect to the output tensor using
            the specified algo, returning results in gradDesc. Scaling factors alpha and beta can
            be used to scale the input tensor and the output tensor respectively.
            </summary>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor filterDesc.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="dy">Data pointer to GPU memory associated with the input differential tensor descriptor diffDesc.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="algo">Enumerant that specifies which backward data convolution algorithm shoud be used to compute the results</param>
            <param name="workSpace">Data pointer to GPU memory to a workspace needed to able to execute
            the specified algorithm. If no workspace is needed for a particular
            algorithm, that pointer can be nil</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dxDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="dx">Data pointer to GPU memory associated with the output tensor descriptor
            gradDesc that carries the result.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.Im2Col(ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDNN.ConvolutionDescriptor,ManagedCuda.CudaDeviceVariable{System.Byte})">
            <summary>
            
            </summary>
            <param name="srcDesc"></param>
            <param name="srcData"></param>
            <param name="filterDesc"></param>
            <param name="convDesc"></param>
            <param name="colBuffer"></param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.SoftmaxForward(ManagedCuda.CudaDNN.cudnnSoftmaxAlgorithm,ManagedCuda.CudaDNN.cudnnSoftmaxMode,System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double})">
            <summary>
            This routine computes the softmax function.
            </summary>
            <param name="algorithm">Enumerant to specify the softmax algorithm.</param>
            <param name="mode">Enumerant to specify the softmax mode.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor destDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.SoftmaxBackward(ManagedCuda.CudaDNN.cudnnSoftmaxAlgorithm,ManagedCuda.CudaDNN.cudnnSoftmaxMode,System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double})">
            <summary>
            This routine computes the gradient of the softmax function.
            </summary>
            <param name="algorithm">Enumerant to specify the softmax algorithm.</param>
            <param name="mode">Enumerant to specify the softmax mode.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="dy">Data pointer to GPU memory associated with the tensor descriptor srcDiffData.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dxDesc">Handle to the previously initialized output differential tensor descriptor.</param>
            <param name="dx">Data pointer to GPU memory associated with the output tensor descriptor destDiffDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.PoolingForward(ManagedCuda.CudaDNN.PoolingDescriptor,System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double})">
            <summary>
            This function computes pooling of input values (i.e., the maximum or average of several
            adjacent values) to produce an output with smaller height and/or width.
            </summary>
            <param name="poolingDesc">Handle to a previously initialized pooling descriptor.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor destDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.PoolingBackward(ManagedCuda.CudaDNN.PoolingDescriptor,System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double})">
            <summary>
            This function computes the gradient of a pooling operation.
            </summary>
            <param name="poolingDesc">Handle to the previously initialized pooling descriptor.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="dy">Data pointer to GPU memory associated with the tensor descriptor srcDiffData.</param>
            <param name="xDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the output tensor descriptor destDesc.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dxDesc">Handle to the previously initialized output differential tensor descriptor.</param>
            <param name="dx">Data pointer to GPU memory associated with the output tensor descriptor destDiffDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.ActivationForward(ManagedCuda.CudaDNN.ActivationDescriptor,System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double})">
            <summary>
            This routine applies a specified neuron activation function element-wise over each input value.
            </summary>
            <param name="activationDesc">Handle to the previously created activation descriptor object.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor destDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.ActivationBackward(ManagedCuda.CudaDNN.ActivationDescriptor,System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double})">
            <summary>
            This routine computes the gradient of a neuron activation function.
            </summary>
            <param name="activationDesc">Handle to the previously created activation descriptor object.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="dy">Data pointer to GPU memory associated with the tensor descriptor srcDiffData.</param>
            <param name="xDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the output tensor descriptor destDesc.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dxDesc">Handle to the previously initialized output differential tensor descriptor.</param>
            <param name="dx">Data pointer to GPU memory associated with the output tensor descriptor destDiffDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.BatchNormalizationForwardTraining(ManagedCuda.CudaDNN.cudnnBatchNormMode,System.Double,System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDeviceVariable{System.Double},System.Double,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDeviceVariable{System.Double},System.Double,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDeviceVariable{System.Double})">
            <summary>
            This function performs the forward BatchNormalization layer computation for the training phase. 
            This layer is based on the paper "Batch Normalization: Accelerating Deep Network Training by 
            Reducing Internal Covariate Shift", S. Ioffe, C. Szegedy, 2015.
            </summary>
            <param name="mode"> Mode of operation (spatial or per-activation). </param>
            <param name="alpha"> Pointer to scaling factors (in host memory) used to blend the layer output value with prior value in the destination tensor as follows: dstValue = alpha[0]*resultValue + beta[0]*priorDstValue. </param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the layer output value with prior value in the destination tensor as follows: dstValue = alpha[0]*resultValue + beta[0]*priorDstValue. </param>
            <param name="xDesc">Tensor descriptor layer's x data.</param>
            <param name="x">Pointer in device memory for the layer's x data.</param>
            <param name="yDesc">Tensor descriptor the layer's y data.</param>
            <param name="y">Pointer in device memory for the layer's y data.</param>
            <param name="bnScaleBiasMeanVarDesc">Shared tensor descriptor desc for all the 6 tensors below in the argument list. The dimensions for this tensor descriptor are dependent on the normalization mode.</param>
            <param name="bnScale">Pointer in device memory for the batch normalization scale parameters (in original paper scale is referred to as gamma).</param>
            <param name="bnBias">Pointers in device memory for the batch normalization bias parameters (in original paper bias is referred to as beta). Note that bnBias parameter can replace the previous layer's bias parameter for improved efficiency. </param>
            <param name="exponentialAverageFactor">Factor used in the moving average computation runningMean = newMean*factor + runningMean*(1-factor). Use a factor=1/(1+n) at Nth call to the function to get Cumulative Moving Average (CMA) behavior CMA[n] = (x[1]+...+x[n])/n. Since CMA[n+1] = (n*CMA[n]+x[n+1])/(n+1)= ((n+1)*CMA[n]-CMA[n])/(n+1) + x[n+1]/(n+1) = CMA[n]*(1-1/(n+1))+x[n +1]*1/(n+1)</param>
            <param name="resultRunningMean">Running mean tensor (it has the same descriptor as the bias and scale). If this tensor is initially uninitialized, it is required that exponentialAverageFactor=1 is used for the very first call of a complete training cycle. This is necessary to properly initialize the moving average. Both resultRunningMean and resultRunningInvVariance can be NULL but only at the same time.</param>
            <param name="resultRunningVariance">Running variance tensor (it has the same descriptor as the bias and scale). If this tensors is initially uninitialized, it is required that exponentialAverageFactor=1 is used for the very first call of a complete training cycle. This is necessary to properly initialize the moving average. Both resultRunningMean and resultRunningInvVariance can be NULL but only at the same time. The value stored in resultRunningInvVariance (or passed as an input in inference mode) is the moving average of the expression 1 / sqrt(eps+variance[x]) where variance is computed either over batch or spatial+batch dimensions depending on the mode. </param>
            <param name="epsilon">Epsilon value used in the batch normalization formula. Minimum allowed value is currently 1e-5. Same epsilon value should be used in forward and backward functions.</param>
            <param name="resultSaveMean">Optional cache to save intermediate results computed during the forward pass - these can then be reused to speed up the backward pass. For this to work correctly, the bottom layer data has to remain unchanged until the backward function is called. Note that both resultSaveMean and resultSaveInvVariance can be NULL but only at the same time. It is recommended to use this cache since memory overhead is relatively small because these tensors have a much lower product of dimensions than the data tensors.</param>
            <param name="resultSaveVariance">Optional cache to save intermediate results computed during the forward pass - these can then be reused to speed up the backward pass. For this to work correctly, the bottom layer data has to remain unchanged until the backward function is called. Note that both resultSaveMean and resultSaveInvVariance can be NULL but only at the same time. It is recommended to use this cache since memory overhead is relatively small because these tensors have a much lower product of dimensions than the data tensors.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.BatchNormalizationForwardInference(ManagedCuda.CudaDNN.cudnnBatchNormMode,System.Double,System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDeviceVariable{System.Double},System.Double)">
            <summary>
            This function performs the forward BatchNormalization layer computation for the inference phase. 
            This layer is based on the paper "Batch Normalization: Accelerating Deep Network 
            Training by Reducing Internal Covariate Shift", S. Ioffe, C. Szegedy, 2015.
            </summary>
            <param name="mode"> Mode of operation (spatial or per-activation). </param>
            <param name="alpha"> Pointer to scaling factors (in host memory) used to blend the layer output value with prior value in the destination tensor as follows: dstValue = alpha[0]*resultValue + beta[0]*priorDstValue. </param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the layer output value with prior value in the destination tensor as follows: dstValue = alpha[0]*resultValue + beta[0]*priorDstValue. </param>
            <param name="xDesc">Tensor descriptor layer's x data.</param>
            <param name="x">Pointer in device memory for the layer's x data.</param>
            <param name="yDesc">Tensor descriptor the layer's y data.</param>
            <param name="y">Pointer in device memory for the layer's y data.</param>
            <param name="bnScaleBiasMeanVarDesc">Shared tensor descriptor desc for all the 4 tensors below in the argument list. The dimensions for this tensor descriptor are dependent on the normalization mode.</param>
            <param name="bnScale">Pointer in device memory for the batch normalization scale parameters (in original paper scale is referred to as gamma).</param>
            <param name="bnBias">Pointers in device memory for the batch normalization bias parameters (in original paper bias is referred to as beta). Note that bnBias parameter can replace the previous layer's bias parameter for improved efficiency. </param>
            <param name="estimatedMean">Mean tensor (has the same descriptor as the bias and scale). It is suggested that resultRunningMean from the cudnnBatchNormalizationForwardTraining call accumulated during the training phase be passed as input here.</param>
            <param name="estimatedVariance">Variance tensor (has the same descriptor as the bias and scale). It is suggested that resultRunningVariance from the cudnnBatchNormalizationForwardTraining call accumulated during the training phase be passed as input here.</param>
            <param name="epsilon">Epsilon value used in the batch normalization formula. Minimum allowed value is currently 1e-5. Same epsilon value should be used in forward and backward functions.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.BatchNormalizationBackward(ManagedCuda.CudaDNN.cudnnBatchNormMode,System.Double,System.Double,System.Double,System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDeviceVariable{System.Double},System.Double,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDeviceVariable{System.Double})">
            <summary>
            This function performs the backward BatchNormalization layer computation.
            </summary>
            <param name="mode"> Mode of operation (spatial or per-activation). </param>
            <param name="alphaDataDiff">Pointer to scaling factors in host memory used to blend the gradient output dx with a prior value in the destination tensor as follows: dstValue = alpha[0]*resultValue + beta[0]*priorDstValue.</param>
            <param name="betaDataDiff">Pointer to scaling factors in host memory used to blend the gradient output dx with a prior value in the destination tensor as follows: dstValue = alpha[0]*resultValue + beta[0]*priorDstValue.</param>
            <param name="alphaParamDiff">Pointer to scaling factors (in host memory) used to blend the gradient outputs dBnScaleResult and dBnBiasResult with prior values in the destination tensor as follows: dstValue = alpha[0]*resultValue + beta[0]*priorDstValue.</param>
            <param name="betaParamDiff">Pointer to scaling factors (in host memory) used to blend the gradient outputs dBnScaleResult and dBnBiasResult with prior values in the destination tensor as follows: dstValue = alpha[0]*resultValue + beta[0]*priorDstValue.</param>
            <param name="xDesc">Tensor descriptor for the layer's x data.</param>
            <param name="x">Pointers in device memory for the layer's x data.</param>
            <param name="dyDesc">Tensor descriptor for the layer's backpropagated differential dy (inputs).</param>
            <param name="dy">Pointers in device memory for the layer's backpropagated differential dy (inputs).</param>
            <param name="dxDesc">Tensor descriptor for the layer's resulting differential with respect to x, dx (output).</param>
            <param name="dx">Pointer in device memory for the layer's resulting differential with respect to x, dx (output).</param>
            <param name="dBnScaleBiasDesc">Shared tensor descriptor for all the 5 tensors below in the argument list (bnScale, resultBnScaleDiff, resultBnBiasDiff, savedMean, savedInvVariance). The dimensions for this tensor descriptor are dependent on normalization mode. Note: The data type of this tensor descriptor must be 'float' for FP16 and FP32 input tensors, and 'double' for FP64 input tensors.</param>
            <param name="bnScale">Pointers in device memory for the batch normalization scale parameter (in original paper bias is referred to as gamma). Note that bnBias parameter is not needed for this layer's computation.</param>
            <param name="dBnScaleResult">Pointer in device memory for the resulting scale differentials computed by this routine. Note that scale and bias gradients are not backpropagated below this layer (since they are dead-end computation DAG nodes).</param>
            <param name="dBnBiasResult">Pointer in device memory for the resulting bias differentials computed by this routine. Note that scale and bias gradients are not backpropagated below this layer (since they are dead-end computation DAG nodes).</param>
            <param name="epsilon">Epsilon value used in the batch normalization formula. Minimum allowed value is currently 1e-5. Same epsilon value should be used in forward and backward functions.</param>
            <param name="savedMean">Optional cache parameter saved intermediate results computed during the forward pass. For this to work correctly, the layer's x and bnScale, bnBias data has to remain unchanged until the backward function is called. Note that both savedMean and savedInvVariance parameters can be NULL but only at the same time. It is recommended to use this cache since the memory overhead is relatively small.</param>
            <param name="savedInvVariance">Optional cache parameter saved intermediate results computed during the forward pass. For this to work correctly, the layer's x and bnScale, bnBias data has to remain unchanged until the backward function is called. Note that both savedMean and savedInvVariance parameters can be NULL but only at the same time. It is recommended to use this cache since the memory overhead is relatively small.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.OpTensor(ManagedCuda.CudaDNN.OpTensorDescriptor,System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double})">
            <summary>
            This function implements the equation C = op(alpha1[0] * A, alpha2[0] * B) + beta[0] * C, 
            given tensors A, B, and C and scaling factors alpha1, alpha2, and beta.The op to use is 
            indicated by the descriptor opTensorDesc.Currently-supported ops are listed by the 
            cudnnOpTensorOp_t enum. Each dimension of the input tensor A must match the corresponding 
            dimension of the destination tensor C, and each dimension of the input tensor B must match 
            the corresponding dimension of the destination tensor C or must be equal to 1. In the latter 
            case, the same value from the input tensor B for those dimensions will be used to blend into the 
            C tensor.The data types of the input tensors A and B must match. If the data type of the 
            destination tensor C is double, then the data type of the input tensors also must be double. If 
            the data type of the destination tensor C is double, then opTensorCompType in opTensorDesc must 
            be double. Else opTensorCompType must be float. If the input tensor B is the same tensor as 
            the destination tensor C, then the input tensor A also must be the same tensor as the 
            destination tensor C.
            </summary>
            <param name="op_desc">Handle to a previously initialized op tensor descriptor.</param>
            <param name="alpha1">Pointer to the scaling factor(in host memory) used to blend the source value with prior 
            value in the destination tensor as indicated by the above op equation.</param>
            <param name="a_desc">Handle to a previously initialized tensor descriptor.</param>
            <param name="a">Pointer to data of the tensor described by the a_desc.</param>
            <param name="alpha2">Pointer to the scaling factor(in host memory) used to blend the source value with prior 
            value in the destination tensor as indicated by the above op equation.</param>
            <param name="b_desc">Handle to a previously initialized tensor descriptor.</param>
            <param name="b">Pointer to data of the tensor described by the b_desc.</param>
            <param name="beta">Pointer to the scaling factor(in host memory) used to blend the source value with prior 
            value in the destination tensor as indicated by the above op equation.</param>
            <param name="c_desc">Handle to a previously initialized tensor descriptor.</param>
            <param name="c">Output pointer to data of the tensor described by the c_desc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.ConvolutionBiasActivationForward(System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.ConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgo,ManagedCuda.CudaDeviceVariable{System.Byte},System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.ActivationDescriptor,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double})">
            <summary>
            This function applies a bias and then an activation to the convolutions or crosscorrelations
            of cudnnConvolutionForward(), returning results in y.The full computation
            follows the equation y = act(alpha1* conv(x) + alpha2* z + bias ).<para/>
            The routine cudnnGetConvolution2dForwardOutputDim or
            cudnnGetConvolutionNdForwardOutputDim can be used to determine the proper
            dimensions of the output tensor descriptor yDesc with respect to xDesc, convDesc and wDesc.
            </summary>
            <param name="alpha1">Pointers to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as described by the above equation.</param>
            <param name="xDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor xDesc.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor wDesc.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="algo">Enumerant that specifies which convolution algorithm shoud be used to compute the results</param>
            <param name="workSpace">Data pointer to GPU memory to a workspace needed to able to execute
            the specified algorithm.If no workspace is needed for a particular
            algorithm, that pointer can be nil</param>
            <param name="alpha2">Pointers to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as described by the above equation.</param>
            <param name="zDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="z">Data pointer to GPU memory associated with the tensor descriptor zDesc.</param>
            <param name="biasDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="bias">Data pointer to GPU memory associated with the tensor descriptor biasDesc.</param>
            <param name="activationDesc">Handle to a previously initialized activation descriptor.</param>
            <param name="yDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the tensor descriptor yDesc
            that carries the result of the convolution.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.ReduceTensor(ManagedCuda.CudaDNN.ReduceTensorDescriptor,ManagedCuda.CudaDeviceVariable{System.UInt32},ManagedCuda.CudaDeviceVariable{System.Byte},ManagedCuda.BasicTypes.SizeT,System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},System.Double,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double})">
            <summary>
            This function reduces tensor A by implementing the equation C = alpha * reduce op ( A )
            + beta* C, given tensors A and C and scaling factors alpha and beta.The reduction op
            to use is indicated by the descriptor reduceTensorDesc.Currently-supported ops are
            listed by the cudnnReduceTensorOp_t enum.
            </summary>
            <param name="reduceTensorDesc">Handle to a previously initialized reduce tensor descriptor.</param>
            <param name="indices">Handle to a previously allocated space for writing indices.</param>
            <param name="workspace">Handle to a previously allocated space for the reduction implementation.</param>
            <param name="workspaceSizeInBytes">Size of the above previously allocated space.</param>
            <param name="alpha">Pointer to scaling factor (in host memory) used to blend the source value
            with prior value in the destination tensor as indicated by the above op equation.</param>
            <param name="aDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="A">Pointer to data of the tensor described by the aDesc descriptor.</param>
            <param name="beta">Pointer to scaling factor (in host memory) used to blend the source value
            with prior value in the destination tensor as indicated by the above op equation.</param>
            <param name="cDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="C">Pointer to data of the tensor described by the cDesc descriptor.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.DropoutForward(ManagedCuda.CudaDNN.DropoutDescriptor,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDeviceVariable{System.Byte})">
            <summary>  
            This function performs forward dropout operation over x returning results in y. If dropout was   
            used as a parameter to cudnnSetDropoutDescriptor, the approximately dropout fraction of x values   
            will be replaces by 0, and the rest will be scaled by 1/(1-dropout) This function should not be   
            running concurrently with another cudnnDropoutForward function using the same states.  
            </summary>  
            <param name="dropoutDesc">Handle to a previously created dropout descriptor object.</param>  
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>  
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>  
            <param name="yDesc">Handle to the previously initialized output tensor descriptor.</param>  
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor destDesc.</param>  
            <param name="reserveSpace">Data pointer to GPU memory used by this function. It is expected that contents of reserveSpace doe not change between cudnnDropoutForward and cudnnDropoutBackward calls.</param>  
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.DropoutBackward(ManagedCuda.CudaDNN.DropoutDescriptor,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDeviceVariable{System.Byte})">
            <summary>  
            This function performs backward dropout operation over dy returning results in dx. If during   
            forward dropout operation value from x was propagated to y then during backward operation value   
            from dy will be propagated to dx, otherwise, dx value will be set to 0.  
            </summary>  
            <param name="dropoutDesc">Handle to a previously created dropout descriptor object.</param>  
            <param name="dyDesc">Handle to a previously initialized tensor descriptor.</param>  
            <param name="dy">Pointer to data of the tensor described by the dyDesc descriptor.</param>  
            <param name="dxDesc">Handle to a previously initialized tensor descriptor.</param>  
            <param name="dx">Pointer to data of the tensor described by the dxDesc descriptor.</param>  
            <param name="reserveSpace">Data pointer to GPU memory used by this function. It is expected that contents of reserveSpace doe not change between cudnnDropoutForward and cudnnDropoutBackward calls.</param>  
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.GetConvolutionForwardAlgorithmMaxCount">
            <summary>
            
            </summary>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.GetConvolutionBackwardFilterAlgorithmMaxCount">
            <summary>
            
            </summary>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.GetConvolutionBackwardDataAlgorithmMaxCount">
            <summary>
            
            </summary>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.FindConvolutionForwardAlgorithm(ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDNN.ConvolutionDescriptor,ManagedCuda.CudaDNN.TensorDescriptor,System.Int32)">
            <summary>
            This function attempts all cuDNN algorithms and outputs performance metrics to a
            user-allocated array of cudnnConvolutionFwdAlgoPerf_t. These metrics are written
            in sorted fashion where the first element has the lowest compute time.
            </summary>
            <param name="srcDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="filterDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="destDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="requestedAlgoCount">The maximum number of elements to be stored in perfResults.</param>
            <returns>An array to store performance metrics sorted ascending by compute time.</returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.GetConvolutionForwardAlgorithm(ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDNN.ConvolutionDescriptor,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionFwdPreference,ManagedCuda.BasicTypes.SizeT)">
            <summary>
            This function serves as a heuristic for obtaining the best suited algorithm for
            cudnnConvolutionForward for the given layer specifications. Based on the input
            preference, this function will either return the fastest algorithm or the fastest algorithm
            within a given memory limit. For an exhaustive search for the fastest algorithm, please
            use cudnnFindConvolutionForwardAlgorithm.
            </summary>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="filterDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="yDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="preference">Enumerant to express the preference criteria in terms of memory
            requirement and speed.</param>
            <param name="memoryLimitInbytes">It is used when enumerant preference is set to
            CUDNN_CONVOLUTION_FWD_SPECIFY_WORKSPACE_LIMIT to specify the
            maximum amount of GPU memory the user is willing to use as a workspace</param>
            <returns>Enumerant that specifies which convolution algorithm should be used to
            compute the results according to the specified preference</returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.GetConvolutionForwardAlgorithm(ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDNN.ConvolutionDescriptor,ManagedCuda.CudaDNN.TensorDescriptor,System.Int32)">
            <summary>
            This function serves as a heuristic for obtaining the best suited algorithm for
            cudnnConvolutionForward for the given layer specifications.This function will return
            all algorithms sorted by expected (based on internal heuristic) relative performance with
            fastest being index 0 of perfResults.For an exhaustive search for the fastest algorithm,
            please use cudnnFindConvolutionForwardAlgorithm.
            </summary>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="filterDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="yDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="requestedAlgoCount">The maximum number of elements to be stored in perfResults.</param>
            <returns>array to store performance metrics sorted ascending by compute time.</returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.GetConvolutionForwardWorkspaceSize(ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDNN.ConvolutionDescriptor,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgo)">
            <summary>
            This function returns the amount of GPU memory workspace the user needs
            to allocate to be able to call cudnnConvolutionForward with the specified
            algorithm. The workspace allocated will then be passed to the routine
            cudnnConvolutionForward. The specified algorithm can be the result of the call to
            cudnnGetConvolutionForwardAlgorithm or can be chosen arbitrarily by the user.
            Note that not every algorithm is available for every configuration of the input tensor
            and/or every configuration of the convolution descriptor.
            </summary>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="filterDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="yDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="algo">Enumerant that specifies the chosen convolution algorithm</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.FindConvolutionBackwardFilterAlgorithm(ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.ConvolutionDescriptor,ManagedCuda.CudaDNN.FilterDescriptor,System.Int32)">
            <summary>
            This function attempts all cuDNN algorithms for cudnnConvolutionBackwardFilter_v3 and outputs performance metrics to a user-
            allocated array of cudnnConvolutionBwdFilterAlgoPerf_t. These metrics are
            written in sorted fashion where the first element has the lowest compute time. 
            </summary>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="dwDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="requestedAlgoCount">The maximum number of elements to be stored in perfResults.</param>
            <returns>An array to store performance metrics sorted ascending by compute time.</returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.GetConvolutionBackwardFilterAlgorithm(ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.ConvolutionDescriptor,ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterPreference,ManagedCuda.BasicTypes.SizeT)">
            <summary>
            This function serves as a heuristic for obtaining the best suited algorithm for
            cudnnConvolutionBackwardFilter_v3 for the given layer specifications. Based
            on the input preference, this function will either return the fastest algorithm or the
            fastest algorithm within a given memory limit. For an exhaustive search for the fastest
            algorithm, please use cudnnFindConvolutionBackwardFilterAlgorithm.
            </summary>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="dwDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="preference">Enumerant to express the preference criteria in terms of memory requirement and speed.</param>
            <param name="memoryLimitInbytes">It is to specify the maximum amount of GPU memory the user is willing to 
            use as a workspace. This is currently a placeholder and is not used.</param>
            <returns>Enumerant that specifies which convolution algorithm should be used to
            compute the results according to the specified preference</returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.GetConvolutionBackwardFilterWorkspaceSize(ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.ConvolutionDescriptor,ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterAlgo)">
            <summary>
            This function returns the amount of GPU memory workspace the user needs
            to allocate to be able to call cudnnConvolutionBackwardFilter_v3 with the
            specified algorithm. The workspace allocated will then be passed to the routine
            cudnnConvolutionBackwardFilter_v3. The specified algorithm can be the result
            of the call to cudnnGetConvolutionBackwardFilterAlgorithm or can be chosen
            arbitrarily by the user. Note that not every algorithm is available for every configuration
            of the input tensor and/or every configuration of the convolution descriptor.
            </summary>
            <param name = "xDesc" > Handle to the previously initialized input tensor descriptor.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="gradDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="algo">Enumerant that specifies the chosen convolution algorithm
            sizeInBytes output Amount of GPU memory needed as workspace to be able to execute</param>
            <returns>Amount of GPU memory needed as workspace to be able to execute a
            forward convolution with the specified algo</returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.FindConvolutionBackwardDataAlgorithm(ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.ConvolutionDescriptor,ManagedCuda.CudaDNN.TensorDescriptor,System.Int32)">
            <summary>
            This function attempts all cuDNN algorithms for
            cudnnConvolutionBackwardData_v3 and outputs performance metrics to a user-
            allocated array of cudnnConvolutionBwdDataAlgoPerf_t. These metrics are written
            in sorted fashion where the first element has the lowest compute time.
            </summary>
            <param name="wDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="dxDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="requestedAlgoCount">The maximum number of elements to be stored in perfResults.</param>
            <returns>An array to store performance metrics sorted ascending by compute time.</returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.GetConvolutionBackwardDataAlgorithm(ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.ConvolutionDescriptor,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionBwdDataPreference,ManagedCuda.BasicTypes.SizeT)">
            <summary>
            This function serves as a heuristic for obtaining the best suited algorithm for
            cudnnConvolutionBackwardData_v3 for the given layer specifications. Based
            on the input preference, this function will either return the fastest algorithm or the
            fastest algorithm within a given memory limit. For an exhaustive search for the fastest
            algorithm, please use cudnnFindConvolutionBackwardDataAlgorithm.
            </summary>
            <param name="wDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="dxDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="preference">Enumerant to express the preference criteria in terms of memory
            requirement and speed.</param>
            <param name="memoryLimitInbytes">It is to specify the maximum amount of GPU memory the user is willing to
            use as a workspace. This is currently a placeholder and is not used.</param>
            <returns>Enumerant that specifies which convolution algorithm should be used to
            compute the results according to the specified preference</returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.GetConvolutionBackwardFilterAlgorithm(ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDNN.ConvolutionDescriptor,System.Int32)">
            <summary>
            This function serves as a heuristic for obtaining the best suited algorithm for
            cudnnConvolutionBackwardFilter for the given layer specifications.This function
            will return all algorithms sorted by expected (based on internal heuristic) relative
            performance with fastest being index 0 of perfResults.For an exhaustive search for the
            fastest algorithm, please use cudnnFindConvolutionBackwardFilterAlgorithm.
            </summary>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="filterDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="requestedAlgoCount">The maximum number of elements to be stored in perfResults.</param>
            <returns>array to store performance metrics sorted ascending by compute time.</returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.GetConvolutionBackwardDataAlgorithm(ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.ConvolutionDescriptor,ManagedCuda.CudaDNN.TensorDescriptor,System.Int32)">
            <summary>
            This function serves as a heuristic for obtaining the best suited algorithm for
            cudnnConvolutionBackwardData for the given layer specifications.This function
            will return all algorithms sorted by expected (based on internal heuristic) relative
            performance with fastest being index 0 of perfResults.For an exhaustive search for the
            fastest algorithm, please use cudnnFindConvolutionBackwardDataAlgorithm.
            </summary>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="dxDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="requestedAlgoCount">The maximum number of elements to be stored in perfResults.</param>
            <param name="filterDesc">Handle to a previously initialized filter descriptor.</param>
            <returns>array to store performance metrics sorted ascending by compute time.</returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.GetConvolutionBackwardDataWorkspaceSize(ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.ConvolutionDescriptor,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionBwdDataAlgo)">
            <summary>
            This function returns the amount of GPU memory workspace the user needs
            to allocate to be able to call cudnnConvolutionBackwardData_v3 with the
            specified algorithm. The workspace allocated will then be passed to the routine
            cudnnConvolutionBackwardData_v3. The specified algorithm can be the result of the
            call to cudnnGetConvolutionBackwardDataAlgorithm or can be chosen arbitrarily
            by the user. Note that not every algorithm is available for every configuration of the
            input tensor and/or every configuration of the convolution descriptor.
            </summary>
            <param name="wDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="dxDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="algo">Enumerant that specifies the chosen convolution algorithm</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.GetReductionIndicesSize(ManagedCuda.CudaDNN.ReduceTensorDescriptor,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.TensorDescriptor)">
            <summary>
            Helper function to return the minimum size of the index space to be passed to the reduction given the input and output tensors
            </summary>
            <param name="reduceTensorDesc"></param>
            <param name="aDesc"></param>
            <param name="cDesc"></param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.GetReductionWorkspaceSize(ManagedCuda.CudaDNN.ReduceTensorDescriptor,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.TensorDescriptor)">
            <summary>
            Helper function to return the minimum size of the workspace to be passed to the reduction given the input and output tensors
            </summary>
            <param name="reduceTensorDesc"></param>
            <param name="aDesc"></param>
            <param name="cDesc"></param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.SetRNNDescriptor(ManagedCuda.CudaDNN.RNNDescriptor,System.Int32,System.Int32,ManagedCuda.CudaDNN.DropoutDescriptor,ManagedCuda.CudaDNN.cudnnRNNInputMode,ManagedCuda.CudaDNN.cudnnDirectionMode,ManagedCuda.CudaDNN.cudnnRNNMode,ManagedCuda.CudaDNN.cudnnRNNAlgo,ManagedCuda.CudaDNN.cudnnDataType)">
            <summary>
            This function initializes a previously created RNN descriptor object.
            </summary>
            <param name="rnnDesc">A previously created RNN descriptor.</param>
            <param name="hiddenSize">Size of the internal hidden state for each layer.</param>
            <param name="numLayers">Number of stacked layers.</param>
            <param name="dropoutDesc">Handle to a previously created and initialized dropout descriptor.
            Dropout will be applied between layers(eg.a single layer network will have no dropout applied).</param>
            <param name="inputMode">Specifies the behavior at the input to the first layer</param>
            <param name="direction">Specifies the recurrence pattern. (eg. bidirectional)</param>
            <param name="mode">Specifies the type of RNN to compute.</param>
            <param name="algo">Specifies which RNN algorithm should be used to compute the results.</param>
            <param name="dataType">Compute precision.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.GetDropoutReserveSpaceSize(ManagedCuda.CudaDNN.TensorDescriptor)">
            <summary>  
            This function is used to query the amount of reserve needed to run dropout with the input dimensions given by xDesc.   
            The same reserve space is expected to be passed to cudnnDropoutForward and cudnnDropoutBackward, and its contents is   
            expected to remain unchanged between cudnnDropoutForward and cudnnDropoutBackward calls.   
            </summary>  
            <param name="xDesc">Handle to a previously initialized tensor descriptor, describing input to a dropout operation.</param>  
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.GetDropoutStateSize">
            <summary>  
            This function is used to query the amount of space required to store the states of the random number generators used by cudnnDropoutForward function.  
            </summary>  
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.QueryRuntimeError(ManagedCuda.CudaDNN.cudnnErrQueryMode)">
            <summary>
            cuDNN library functions perform extensive input argument checking before launching
            GPU kernels.The last step is to verify that the GPU kernel actually started. When
            a kernel fails to start, CUDNN_STATUS_EXECUTION_FAILED is returned by the
            corresponding API call. Typically, after a GPU kernel starts, no runtime checks are
            performed by the kernel itself -- numerical results are simply written to output buffers.<para/>
            When the CUDNN_BATCHNORM_SPATIAL_PERSISTENT mode is selected in cudnnBatchNormalizationForwardTraining or
            cudnnBatchNormalizationBackward, the algorithm may encounter numerical overflows
            where CUDNN_BATCHNORM_SPATIAL performs just fine albeit at a slower speed.<para/>
            The user can invoke cudnnQueryRuntimeError to make sure numerical overflows did
            not occur during the kernel execution.Those issues are reported by the kernel that
            performs computations.
            </summary>
            <param name="mode">Remote error query mode.</param>
            <returns>the user's error code</returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.GetDropoutDescriptor(ManagedCuda.CudaDNN.DropoutDescriptor,System.Single@,System.UInt64@)">
            <summary>
            This function queries the fields of a previously initialized dropout descriptor.
            </summary>
            <param name="dropoutDesc">Previously initialized dropout descriptor.</param>
            <param name="droupout">The probability with which the value from input is set to 0 during the 
            dropout layer.</param>
            <param name="seed">Seed used to initialize random number generator states.</param>
            <returns>user-allocated GPU memory that holds random number generator states.</returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNContext.RestoreDropoutDescriptor(ManagedCuda.CudaDNN.DropoutDescriptor,ManagedCuda.CudaDeviceVariable{System.Byte},System.Single@,System.UInt64@)">
            <summary>
            This function restores a dropout descriptor to a previously saved-off state.
            </summary>
            <param name="dropoutDesc">Previously created dropout descriptor.</param>
            <param name="droupout">Probability with which the value from an input tensor is set to 0 when performing dropout.</param>
            <param name="seed">Seed used in prior call to cudnnSetDropoutDescriptor that initialized
            #states' buffer. Using a different seed from this has no effect. A change of seed, and subsequent update to random number generator states can be achieved by calling
            cudnnSetDropoutDescriptor.</param>
            <param name="states">Pointer to GPU memory that holds random number generator states initialized by a prior call to cudnnSetDropoutDescriptor.</param>
        </member>
        <member name="T:ManagedCuda.CudaDNN.CudaDNNException">
            <summary>
            An CudaDNNException is thrown, if any wrapped call to the cudnn-library does not return <see cref="F:ManagedCuda.CudaDNN.cudnnStatus.Success"/>.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNException.#ctor">
            <summary>
            
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNException.#ctor(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)">
            <summary>
            
            </summary>
            <param name="serInfo"></param>
            <param name="streamingContext"></param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNException.#ctor(ManagedCuda.CudaDNN.cudnnStatus)">
            <summary>
            
            </summary>
            <param name="error"></param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNException.#ctor(System.String)">
            <summary>
            
            </summary>
            <param name="message"></param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNException.#ctor(System.String,System.Exception)">
            <summary>
            
            </summary>
            <param name="message"></param>
            <param name="exception"></param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNException.#ctor(ManagedCuda.CudaDNN.cudnnStatus,System.String,System.Exception)">
            <summary>
            
            </summary>
            <param name="error"></param>
            <param name="message"></param>
            <param name="exception"></param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNException.ToString">
            <summary>
            
            </summary>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNException.GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)">
            <summary>
            
            </summary>
            <param name="info"></param>
            <param name="context"></param>
        </member>
        <member name="P:ManagedCuda.CudaDNN.CudaDNNException.DNNStatus">
            <summary>
            
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.CudaDNNNativeMethods">
            <summary/>
        </member>
        <member name="P:ManagedCuda.CudaDNN.CudaDNNNativeMethods.Version">
            <summary>
            Gives the version of the wrapped api
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetVersion">
            <summary>
            This function returns the version number of the cuDNN Library. It returns the
            CUDNN_VERSION define present in the cudnn.h header file. Starting with release R2, the
            routine can be used to identify dynamically the current cuDNN Library used by the
            application. The define CUDNN_VERSION can be used to have the same application linked
            against different cuDNN versions using conditional compilation statements.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetProperty(ManagedCuda.CudaDNN.libraryPropertyType,System.Int32@)">
            <summary>
            
            </summary>
            <param name="type"></param>
            <param name="value"></param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetErrorString(ManagedCuda.CudaDNN.cudnnStatus)">
            <summary>
            This function returns a human-readable character string describing the cudnnStatus enumerate passed as input parameter.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnQueryRuntimeError(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnStatus@,ManagedCuda.CudaDNN.cudnnErrQueryMode,ManagedCuda.CudaDNN.cudnnRuntimeTag)">
            <summary>
            
            </summary>
            <param name="handle"></param>
            <param name="rstatus"></param>
            <param name="mode"></param>
            <param name="tag"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnCreate(ManagedCuda.CudaDNN.cudnnHandle@)">
            <summary>
            This function initializes the cuDNN library and creates a handle to an opaque
            structure holding the cuDNN library context. It allocates hardware resources on
            the host and device and must be called prior to making any other cuDNN library
            calls. The cuDNN library context is tied to the current CUDA device. To use the
            library on multiple devices, one cuDNN handle needs to be created for each device.
            For a given device, multiple cuDNN handles with different configurations (e.g.,
            different current CUDA streams) may be created. Because cudnnCreate allocates
            some internal resources, the release of those resources by calling cudnnDestroy will
            implicitly call cudaDeviceSynchronize; therefore, the recommended best practice
            is to call cudnnCreate/cudnnDestroy outside of performance-critical code paths.
            For multithreaded applications that use the same device from different threads, the
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnDestroy(ManagedCuda.CudaDNN.cudnnHandle)">
            <summary>
            This function releases hardware resources used by the cuDNN library. This function
            is usually the last call with a particular handle to the cuDNN library. Because
            cudnnCreate allocates some internal resources, the release of those resources by
            calling cudnnDestroy will implicitly call cudaDeviceSynchronize; therefore,
            the recommended best practice is to call cudnnCreate/cudnnDestroy outside of
            performance-critical code paths.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetStream(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.BasicTypes.CUstream)">
            <summary>
            This function sets the cuDNN library stream, which will be used to execute all
            subsequent calls to the cuDNN library functions with that particular handle. If the
            cuDNN library stream is not set, all kernels use the default (NULL) stream. In particular,
            this routine can be used to change the stream between kernel launches and then to reset
            the cuDNN library stream back to NULL.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetStream(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.BasicTypes.CUstream@)">
            <summary>
            This function gets the cuDNN library stream, which is being used to execute all calls to
            the cuDNN library functions. If the cuDNN library stream is not set, all kernels use the
            default NULL stream.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnCreateTensorDescriptor(ManagedCuda.CudaDNN.cudnnTensorDescriptor@)">
            <summary>
            This function creates a generic Tensor descriptor object by allocating the memory needed
            to hold its opaque structure. The data is initialized to be all zero.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetTensor4dDescriptor(ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnTensorFormat,ManagedCuda.CudaDNN.cudnnDataType,System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            This function initializes a previously created generic Tensor descriptor object into a
            4D tensor. The strides of the four dimensions are inferred from the format parameter
            and set in such a way that the data is contiguous in memory with no padding between
            dimensions.
            </summary>
            <param name="tensorDesc">Handle to a previously created tensor descriptor.</param>
            <param name="format">Type of format.</param>
            <param name="dataType">Data type.</param>
            <param name="n">Number of images.</param>
            <param name="c">Number of feature maps per image.</param>
            <param name="h">Height of each feature map.</param>
            <param name="w">Width of each feature map.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetTensor4dDescriptorEx(ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnDataType,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            This function initializes a previously created generic Tensor descriptor object into a
            4D tensor, similarly to cudnnSetTensor4dDescriptor but with the strides explicitly
            passed as parameters. This can be used to lay out the 4D tensor in any order or simply to
            define gaps between dimensions.
            </summary>
            <param name="tensorDesc">Handle to a previously created tensor descriptor.</param>
            <param name="dataType">Data type.</param>
            <param name="n">Number of images.</param>
            <param name="c">Number of feature maps per image.</param>
            <param name="h">Height of each feature map.</param>
            <param name="w">Width of each feature map.</param>
            <param name="nStride">Stride between two consecutive images.</param>
            <param name="cStride">Stride between two consecutive feature maps.</param>
            <param name="hStride">Stride between two consecutive rows.</param>
            <param name="wStride">Stride between two consecutive columns.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetTensor4dDescriptor(ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnDataType@,System.Int32@,System.Int32@,System.Int32@,System.Int32@,System.Int32@,System.Int32@,System.Int32@,System.Int32@)">
            <summary>
            This function queries the parameters of the previouly initialized Tensor4D descriptor object.
            </summary>
            <param name="tensorDesc">Handle to a previously insitialized tensor descriptor.</param>
            <param name="dataType">Data type.</param>
            <param name="n">Number of images.</param>
            <param name="c">Number of feature maps per image.</param>
            <param name="h">Height of each feature map.</param>
            <param name="w">Width of each feature map.</param>
            <param name="nStride">Stride between two consecutive images.</param>
            <param name="cStride">Stride between two consecutive feature maps.</param>
            <param name="hStride">Stride between two consecutive rows.</param>
            <param name="wStride">Stride between two consecutive columns.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetTensorNdDescriptor(ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnDataType,System.Int32,System.Int32[],System.Int32[])">
            <summary>
            This function initializes a previously created generic Tensor descriptor object.
            </summary>
            <param name="tensorDesc">Handle to a previously created tensor descriptor.</param>
            <param name="dataType">Data type.</param>
            <param name="nbDims">Dimension of the tensor.</param>
            <param name="dimA">Array of dimension nbDims that contain the size of the tensor for every dimension.</param>
            <param name="strideA">Array of dimension nbDims that contain the stride of the tensor for every dimension.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetTensorNdDescriptorEx(ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnTensorFormat,ManagedCuda.CudaDNN.cudnnDataType,System.Int32,System.Int32[])">
            <summary>
            This function initializes a previously created generic Tensor descriptor object.
            </summary>
            <param name="tensorDesc">Handle to a previously created tensor descriptor.</param>
            <param name="format"></param>
            <param name="dataType">Data type.</param>
            <param name="nbDims">Dimension of the tensor.</param>
            <param name="dimA">Array of dimension nbDims that contain the size of the tensor for every dimension.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetTensorNdDescriptor(ManagedCuda.CudaDNN.cudnnTensorDescriptor,System.Int32,ManagedCuda.CudaDNN.cudnnDataType@,System.Int32@,System.Int32[],System.Int32[])">
            <summary>
            This function retrieves values stored in a previously initialized Tensor descriptor object.
            </summary>
            <param name="tensorDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="nbDimsRequested">Number of dimensions to extract from a given tensor descriptor. It is
            also the minimum size of the arrays dimA and strideA. If this number is
            greater than the resulting nbDims[0], only nbDims[0] dimensions will be
            returned.</param>
            <param name="dataType">Data type.</param>
            <param name="nbDims">Actual number of dimensions of the tensor will be returned in nbDims[0].</param>
            <param name="dimA">Array of dimension of at least nbDimsRequested that will be filled with
            the dimensions from the provided tensor descriptor.</param>
            <param name="strideA">Array of dimension of at least nbDimsRequested that will be filled with
            the strides from the provided tensor descriptor.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetTensorSizeInBytes(ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.SizeT@)">
            <summary>
            This function returns the size of the tensor in memory in respect to the given descriptor.
            This function can be used to know the amount of GPU memory to be allocated to hold that tensor.
            </summary>
            <param name="tensorDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="size">Size in bytes needed to hold the tensor in GPU memory.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnDestroyTensorDescriptor(ManagedCuda.CudaDNN.cudnnTensorDescriptor)">
            <summary>
            This function destroys a previously created Tensor descriptor object.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnTransformTensor(ManagedCuda.CudaDNN.cudnnHandle,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function copies the scaled data from one tensor to another tensor with a different
            layout. Those descriptors need to have the same dimensions but not necessarily the
            same strides. The input and output tensors must not overlap in any way (i.e., tensors
            cannot be transformed in place). This function can be used to convert a tensor with an
            unsupported format to a supported one.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the source
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*srcValue + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="xDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="x">Pointer to data of the tensor described by the srcDesc descriptor.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the source
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*srcValue + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="y">Pointer to data of the tensor described by the destDesc descriptor.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnTransformTensor(ManagedCuda.CudaDNN.cudnnHandle,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function copies the scaled data from one tensor to another tensor with a different
            layout. Those descriptors need to have the same dimensions but not necessarily the
            same strides. The input and output tensors must not overlap in any way (i.e., tensors
            cannot be transformed in place). This function can be used to convert a tensor with an
            unsupported format to a supported one.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the source
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*srcValue + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="xDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="x">Pointer to data of the tensor described by the srcDesc descriptor.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the source
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*srcValue + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="y">Pointer to data of the tensor described by the destDesc descriptor.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnAddTensor(ManagedCuda.CudaDNN.cudnnHandle,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function adds the scaled values of one bias tensor to another tensor. Each dimension
            of the bias tensor must match the coresponding dimension of the srcDest tensor or
            must be equal to 1. In the latter case, the same value from the bias tensor for thoses
            dimensions will be used to blend into the srcDest tensor.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the source
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*srcValue + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="aDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="a">Pointer to data of the tensor described by the biasDesc descriptor.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the source
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*srcValue + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="cDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="c">Pointer to data of the tensor described by the srcDestDesc descriptor.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnAddTensor(ManagedCuda.CudaDNN.cudnnHandle,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function adds the scaled values of one bias tensor to another tensor. Each dimension
            of the bias tensor must match the coresponding dimension of the srcDest tensor or
            must be equal to 1. In the latter case, the same value from the bias tensor for thoses
            dimensions will be used to blend into the srcDest tensor.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the source
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*srcValue + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="aDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="a">Pointer to data of the tensor described by the biasDesc descriptor.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the source
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*srcValue + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="cDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="cData">Pointer to data of the tensor described by the srcDestDesc descriptor.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnCreateOpTensorDescriptor(ManagedCuda.CudaDNN.cudnnOpTensorDescriptor@)">
            <summary>
            
            </summary>
            <param name="opTensorDesc"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetOpTensorDescriptor(ManagedCuda.CudaDNN.cudnnOpTensorDescriptor,ManagedCuda.CudaDNN.cudnnOpTensorOp,ManagedCuda.CudaDNN.cudnnDataType,ManagedCuda.CudaDNN.cudnnNanPropagation)">
            <summary>
            
            </summary>
            <param name="opTensorDesc"></param>
            <param name="opTensorOp"></param>
            <param name="opTensorCompType"></param>
            <param name="opTensorNanOpt"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetOpTensorDescriptor(ManagedCuda.CudaDNN.cudnnOpTensorDescriptor,ManagedCuda.CudaDNN.cudnnOpTensorOp@,ManagedCuda.CudaDNN.cudnnDataType@,ManagedCuda.CudaDNN.cudnnNanPropagation@)">
            <summary>
            
            </summary>
            <param name="opTensorDesc"></param>
            <param name="opTensorOp"></param>
            <param name="opTensorCompType"></param>
            <param name="opTensorNanOpt"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnDestroyOpTensorDescriptor(ManagedCuda.CudaDNN.cudnnOpTensorDescriptor)">
            <summary>
            
            </summary>
            <param name="opTensorDesc"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnOpTensor(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnOpTensorDescriptor,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function implements the equation C = op ( alpha1[0] * A, alpha2[0] * B ) + beta[0] * C, given 
            tensors A, B, and C and scaling factors alpha1, alpha2, and beta. The op to use is indicated by 
            the descriptor opTensorDesc. Currently-supported ops are listed by the cudnnOpTensorOp_t enum. 
            Each dimension of the input tensor A must match the corresponding dimension of the destination 
            tensor C, and each dimension of the input tensor B must match the corresponding dimension of the 
            destination tensor C or must be equal to 1. In the latter case, the same value from the input tensor 
            B for those dimensions will be used to blend into the C tensor. The data types of the input tensors 
            A and B must match. If the data type of the destination tensor C is double, then the data type of 
            the input tensors also must be double. If the data type of the destination tensor C is double, then 
            opTensorCompType in opTensorDesc must be double. Else opTensorCompType must be float. If the input 
            tensor B is the same tensor as the destination tensor C, then the input tensor A also must be the 
            same tensor as the destination tensor C.
            </summary>        
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="opTensorDesc">Handle to a previously initialized op tensor descriptor.</param>
            <param name="alpha1">Pointer to scaling factors(in host memory) used to blend the source value with prior value in the destination tensor as indicated by the above op equation.</param>
            <param name="aDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="A">Pointer to data of the tensors described by the aDesc descriptor.</param>
            <param name="alpha2">Pointer to scaling factors(in host memory) used to blend the source value with prior value in the destination tensor as indicated by the above op equation.</param>
            <param name="bDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="B">Pointer to data of the tensors described by the bDesc descriptor.</param>
            <param name="beta">Pointer to scaling factors(in host memory) used to blend the source value with prior value in the destination tensor as indicated by the above op equation.</param>
            <param name="cDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="C">Pointer to data of the tensor described by the cDesc descriptor.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnOpTensor(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnOpTensorDescriptor,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function implements the equation C = op ( alpha1[0] * A, alpha2[0] * B ) + beta[0] * C, given 
            tensors A, B, and C and scaling factors alpha1, alpha2, and beta. The op to use is indicated by 
            the descriptor opTensorDesc. Currently-supported ops are listed by the cudnnOpTensorOp_t enum. 
            Each dimension of the input tensor A must match the corresponding dimension of the destination 
            tensor C, and each dimension of the input tensor B must match the corresponding dimension of the 
            destination tensor C or must be equal to 1. In the latter case, the same value from the input tensor 
            B for those dimensions will be used to blend into the C tensor. The data types of the input tensors 
            A and B must match. If the data type of the destination tensor C is double, then the data type of 
            the input tensors also must be double. If the data type of the destination tensor C is double, then 
            opTensorCompType in opTensorDesc must be double. Else opTensorCompType must be float. If the input 
            tensor B is the same tensor as the destination tensor C, then the input tensor A also must be the 
            same tensor as the destination tensor C.
            </summary>        
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="opTensorDesc">Handle to a previously initialized op tensor descriptor.</param>
            <param name="alpha1">Pointer to scaling factors(in host memory) used to blend the source value with prior value in the destination tensor as indicated by the above op equation.</param>
            <param name="aDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="A">Pointer to data of the tensors described by the aDesc descriptor.</param>
            <param name="alpha2">Pointer to scaling factors(in host memory) used to blend the source value with prior value in the destination tensor as indicated by the above op equation.</param>
            <param name="bDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="B">Pointer to data of the tensors described by the bDesc descriptor.</param>
            <param name="beta">Pointer to scaling factors(in host memory) used to blend the source value with prior value in the destination tensor as indicated by the above op equation.</param>
            <param name="cDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="C">Pointer to data of the tensor described by the cDesc descriptor.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnCreateReduceTensorDescriptor(ManagedCuda.CudaDNN.cudnnReduceTensorDescriptor@)">
            <summary>
            
            </summary>
            <param name="reduceTensorDesc"></param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetReduceTensorDescriptor(ManagedCuda.CudaDNN.cudnnReduceTensorDescriptor,ManagedCuda.CudaDNN.cudnnReduceTensorOp,ManagedCuda.CudaDNN.cudnnDataType,ManagedCuda.CudaDNN.cudnnNanPropagation,ManagedCuda.CudaDNN.cudnnReduceTensorIndices,ManagedCuda.CudaDNN.cudnnIndicesType)">
            <summary>
            
            </summary>
            <param name="reduceTensorDesc"></param>
            <param name="reduceTensorOp"></param>
            <param name="reduceTensorCompType"></param>
            <param name="reduceTensorNanOpt"></param>
            <param name="reduceTensorIndices"></param>
            <param name="reduceTensorIndicesType"></param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetReduceTensorDescriptor(ManagedCuda.CudaDNN.cudnnReduceTensorDescriptor,ManagedCuda.CudaDNN.cudnnReduceTensorOp@,ManagedCuda.CudaDNN.cudnnDataType@,ManagedCuda.CudaDNN.cudnnNanPropagation@,ManagedCuda.CudaDNN.cudnnReduceTensorIndices@,ManagedCuda.CudaDNN.cudnnIndicesType@)">
            <summary>
            
            </summary>
            <param name="reduceTensorDesc"></param>
            <param name="reduceTensorOp"></param>
            <param name="reduceTensorCompType"></param>
            <param name="reduceTensorNanOpt"></param>
            <param name="reduceTensorIndices"></param>
            <param name="reduceTensorIndicesType"></param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnDestroyReduceTensorDescriptor(ManagedCuda.CudaDNN.cudnnReduceTensorDescriptor)">
            <summary>
            
            </summary>
            <param name="reduceTensorDesc"></param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetReductionIndicesSize(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnReduceTensorDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.SizeT@)">
            <summary>
            Helper function to return the minimum size of the index space to be passed to the reduction given the input and output tensors
            </summary>
            <param name="handle"></param>
            <param name="reduceTensorDesc"></param>
            <param name="aDesc"></param>
            <param name="cDesc"></param>
            <param name="sizeInBytes"></param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetReductionWorkspaceSize(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnReduceTensorDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.SizeT@)">
            <summary>
            Helper function to return the minimum size of the workspace to be passed to the reduction given the input and output tensors
            </summary>
            <param name="handle"></param>
            <param name="reduceTensorDesc"></param>
            <param name="aDesc"></param>
            <param name="cDesc"></param>
            <param name="sizeInBytes"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnReduceTensor(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnReduceTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function reduces tensor A by implementing the equation C = alpha * reduce op ( A )
            + beta* C, given tensors A and C and scaling factors alpha and beta.The reduction op
            to use is indicated by the descriptor reduceTensorDesc.Currently-supported ops are
            listed by the cudnnReduceTensorOp_t enum.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="reduceTensorDesc">Handle to a previously initialized reduce tensor descriptor.</param>
            <param name="indices">Handle to a previously allocated space for writing indices.</param>
            <param name="indicesSizeInBytes">Size of the above previously allocated space.</param>
            <param name="workspace">Handle to a previously allocated space for the reduction implementation.</param>
            <param name="workspaceSizeInBytes">Size of the above previously allocated space.</param>
            <param name="alpha">Pointer to scaling factor (in host memory) used to blend the source value
            with prior value in the destination tensor as indicated by the above op equation.</param>
            <param name="aDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="A">Pointer to data of the tensor described by the aDesc descriptor.</param>
            <param name="beta">Pointer to scaling factor (in host memory) used to blend the source value
            with prior value in the destination tensor as indicated by the above op equation.</param>
            <param name="cDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="C">Pointer to data of the tensor described by the cDesc descriptor.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnReduceTensor(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnReduceTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function reduces tensor A by implementing the equation C = alpha * reduce op ( A )
            + beta* C, given tensors A and C and scaling factors alpha and beta.The reduction op
            to use is indicated by the descriptor reduceTensorDesc.Currently-supported ops are
            listed by the cudnnReduceTensorOp_t enum.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="reduceTensorDesc">Handle to a previously initialized reduce tensor descriptor.</param>
            <param name="indices">Handle to a previously allocated space for writing indices.</param>
            <param name="indicesSizeInBytes">Size of the above previously allocated space.</param>
            <param name="workspace">Handle to a previously allocated space for the reduction implementation.</param>
            <param name="workspaceSizeInBytes">Size of the above previously allocated space.</param>
            <param name="alpha">Pointer to scaling factor (in host memory) used to blend the source value
            with prior value in the destination tensor as indicated by the above op equation.</param>
            <param name="aDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="A">Pointer to data of the tensor described by the aDesc descriptor.</param>
            <param name="beta">Pointer to scaling factor (in host memory) used to blend the source value
            with prior value in the destination tensor as indicated by the above op equation.</param>
            <param name="cDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="C">Pointer to data of the tensor described by the cDesc descriptor.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetTensor(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Single@)">
            <summary>
            This function sets all the elements of a tensor to a given value
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="yDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="y">Pointer to data of the tensor described by the srcDestDesc descriptor.</param>
            <param name="value">Pointer in Host memory to a value that all elements of the tensor will be set to.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetTensor(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Double@)">
            <summary>
            This function sets all the elements of a tensor to a given value
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="yDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="y">Pointer to data of the tensor described by the srcDestDesc descriptor.</param>
            <param name="value">Pointer in Host memory to a value that all elements of the tensor will be set to.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnScaleTensor(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Single@)">
            <summary>
            This function scale all the elements of a tensor by a give factor.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="yDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="y">Pointer to data of the tensor described by the srcDestDesc descriptor.</param>
            <param name="alpha">Pointer in Host memory to a value that all elements of the tensor will be scaled with.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnScaleTensor(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Double@)">
            <summary>
            This function scale all the elements of a tensor by a give factor.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="yDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="y">Pointer to data of the tensor described by the srcDestDesc descriptor.</param>
            <param name="alpha">Pointer in Host memory to a value that all elements of the tensor will be scaled with.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnCreateFilterDescriptor(ManagedCuda.CudaDNN.cudnnFilterDescriptor@)">
            <summary>
            This function creates a filter descriptor object by allocating the memory needed to hold its opaque structure.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetFilter4dDescriptor(ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.CudaDNN.cudnnDataType,ManagedCuda.CudaDNN.cudnnTensorFormat,System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            This function initializes a previously created filter descriptor object into a 4D filter.
            Filters layout must be contiguous in memory.
            v4 version of the function also has the format parameter.
            </summary>
            <param name="filterDesc">Handle to a previously created filter descriptor.</param>
            <param name="dataType">Data type.</param>
            <param name="format">Layout format.</param>
            <param name="k">Number of output feature maps.</param>
            <param name="c">Number of input feature maps.</param>
            <param name="h">Height of each filter.</param>
            <param name="w">Width of each filter.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetFilter4dDescriptor(ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.CudaDNN.cudnnDataType@,ManagedCuda.CudaDNN.cudnnTensorFormat@,System.Int32@,System.Int32@,System.Int32@,System.Int32@)">
            <summary>
            This function queries the parameters of the previouly initialized filter descriptor object.
            v4 version of the function also has the format parameter.
            </summary>
            <param name="filterDesc">Handle to a previously created filter descriptor.</param>
            <param name="dataType">Data type.</param>
            <param name="format">Layout format.</param>
            <param name="k">Number of output feature maps.</param>
            <param name="c">Number of input feature maps.</param>
            <param name="h">Height of each filter.</param>
            <param name="w">Width of each filter.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetFilterNdDescriptor(ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.CudaDNN.cudnnDataType,ManagedCuda.CudaDNN.cudnnTensorFormat,System.Int32,System.Int32[])">
            <summary>
            This function initializes a previously created filter descriptor object. Filters layout must
            be contiguous in memory.
            v4 version of the function also has the format parameter.
            </summary>
            <param name="filterDesc">Handle to a previously created filter descriptor.</param>
            <param name="dataType">Data type.</param>
            <param name="format">Layout format.</param>
            <param name="nbDims">Dimension of the filter.</param>
            <param name="filterDimA">Array of dimension nbDims containing the size of the filter for each dimension.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetFilterNdDescriptor(ManagedCuda.CudaDNN.cudnnFilterDescriptor,System.Int32,ManagedCuda.CudaDNN.cudnnDataType@,ManagedCuda.CudaDNN.cudnnTensorFormat@,System.Int32@,System.Int32[])">
            <summary>
            This function queries a previously initialized filter descriptor object.
            v4 version of the function also has the format parameter.
            </summary>
            <param name="filterDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="nbDimsRequested">Dimension of the expected filter descriptor. It is also the minimum size of
            the arrays filterDimA in order to be able to hold the results</param>
            <param name="dataType">Data type.</param>
            <param name="format">Layout format.</param>
            <param name="nbDims">Actual dimension of the filter.</param>
            <param name="filterDimA">Array of dimension of at least nbDimsRequested that will be filled with
            the filter parameters from the provided filter descriptor.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnDestroyFilterDescriptor(ManagedCuda.CudaDNN.cudnnFilterDescriptor)">
            <summary>
            This function destroys a previously created Tensor4D descriptor object.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnCreateConvolutionDescriptor(ManagedCuda.CudaDNN.cudnnConvolutionDescriptor@)">
            <summary>
            This function creates a convolution descriptor object by allocating the memory needed to
            hold its opaque structure
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetConvolutionMathType(ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnMathType)">
            <summary>
            
            </summary>
            <param name="convDesc"></param>
            <param name="mathType"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetConvolutionMathType(ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnMathType@)">
            <summary>
            
            </summary>
            <param name="convDesc"></param>
            <param name="mathType"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetConvolutionGroupCount(ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,System.Int32)">
            <summary>
            
            </summary>
            <param name="convDesc"></param>
            <param name="groupCount"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetConvolutionGroupCount(ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,System.Int32@)">
            <summary>
            
            </summary>
            <param name="convDesc"></param>
            <param name="groupCount"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetConvolution2dDescriptor(ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,ManagedCuda.CudaDNN.cudnnConvolutionMode,ManagedCuda.CudaDNN.cudnnDataType)">
            <summary>
            This function initializes a previously created convolution descriptor object into a 2D
            correlation. This function assumes that the tensor and filter descriptors corresponds
            to the forward convolution path and checks if their settings are valid. That same
            convolution descriptor can be reused in the backward path provided it corresponds to
            the same layer.
            </summary>
            <param name="convDesc">Handle to a previously created convolution descriptor.</param>
            <param name="pad_h">zero-padding height: number of rows of zeros implicitly concatenated
            onto the top and onto the bottom of input images.</param>
            <param name="pad_w">zero-padding width: number of columns of zeros implicitly concatenated
            onto the left and onto the right of input images.</param>
            <param name="u">Vertical filter stride.</param>
            <param name="v">Horizontal filter stride.</param>
            <param name="dilation_h">Filter height dilation.</param>
            <param name="dilation_w">Filter width dilation.</param>
            <param name="mode">Selects between CUDNN_CONVOLUTION and CUDNN_CROSS_CORRELATION.</param>
            <param name="dataType">Selects the datatype in which the computation will be done.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetConvolution2dDescriptor(ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,System.Int32@,System.Int32@,System.Int32@,System.Int32@,System.Int32@,System.Int32@,ManagedCuda.CudaDNN.cudnnConvolutionMode@,ManagedCuda.CudaDNN.cudnnDataType@)">
            <summary>
            This function queries a previously initialized 2D convolution descriptor object.
            </summary>
            <param name="convDesc">Handle to a previously created convolution descriptor.</param>
            <param name="pad_h">zero-padding height: number of rows of zeros implicitly concatenated
            onto the top and onto the bottom of input images.</param>
            <param name="pad_w">zero-padding width: number of columns of zeros implicitly concatenated
            onto the left and onto the right of input images.</param>
            <param name="u">Vertical filter stride.</param>
            <param name="v">Horizontal filter stride.</param>
            <param name="dilation_h">Filter height dilation.</param>
            <param name="dilation_w">Filter width dilation.</param>
            <param name="mode">Selects between CUDNN_CONVOLUTION and CUDNN_CROSS_CORRELATION.</param>
            <param name="dataType">Data type.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetConvolution2dForwardOutputDim(ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnFilterDescriptor,System.Int32@,System.Int32@,System.Int32@,System.Int32@)">
            <summary>
            This function returns the dimensions of the resulting 4D tensor of a 2D convolution,
            given the convolution descriptor, the input tensor descriptor and the filter descriptor
            This function can help to setup the output tensor and allocate the proper amount of
            memory prior to launch the actual convolution.<para/>
            Each dimension h and w of the output images is computed as followed:<para/>
            outputDim = 1 + (inputDim + 2*pad - filterDim)/convolutionStride;
            </summary>
            <param name="convDesc">Handle to a previously created convolution descriptor.</param>
            <param name="inputTensorDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="filterDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="n">Number of output images.</param>
            <param name="c">Number of output feature maps per image.</param>
            <param name="h">Height of each output feature map.</param>
            <param name="w">Width of each output feature map.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetConvolutionNdDescriptor(ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,System.Int32,System.Int32[],System.Int32[],System.Int32[],ManagedCuda.CudaDNN.cudnnConvolutionMode,ManagedCuda.CudaDNN.cudnnDataType)">
            <summary>
            This function initializes a previously created generic convolution descriptor object into
            a n-D correlation. That same convolution descriptor can be reused in the backward path
            provided it corresponds to the same layer. The convolution computation will done in the
            specified dataType, which can be potentially different from the input/output tensors.
            </summary>
            <param name="convDesc">Handle to a previously created convolution descriptor.</param>
            <param name="arrayLength">Dimension of the convolution.</param>
            <param name="padA">Array of dimension arrayLength containing the zero-padding size
            for each dimension. For every dimension, the padding represents the
            number of extra zeros implicitly concatenated at the start and at the
            end of every element of that dimension.</param>
            <param name="filterStrideA">Array of dimension arrayLength containing the filter stride for each
            dimension. For every dimension, the fitler stride represents the number
            of elements to slide to reach the next start of the filtering window of
            the next point.</param>
            <param name="dilationA">Array of dimension arrayLength containing the dilation factor for each dimension.</param>
            <param name="mode">Selects between CUDNN_CONVOLUTION and CUDNN_CROSS_CORRELATION.</param>
            <param name="computeType">Selects the datatype in which the computation will be done.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetConvolutionNdDescriptor(ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,System.Int32,System.Int32@,System.Int32[],System.Int32[],System.Int32[],ManagedCuda.CudaDNN.cudnnConvolutionMode@,ManagedCuda.CudaDNN.cudnnDataType@)">
            <summary>
            This function queries a previously initialized convolution descriptor object.
            </summary>
            <param name="convDesc">Handle to a previously created convolution descriptor.</param>
            <param name="arrayLengthRequested">Dimension of the expected convolution descriptor. It is also the
            minimum size of the arrays padA, filterStrideA and upsacleA in
            order to be able to hold the results</param>
            <param name="arrayLength">actual dimension of the convolution descriptor.</param>
            <param name="padA">Array of dimension of at least arrayLengthRequested that will be
            filled with the padding parameters from the provided convolution
            descriptor.</param>
            <param name="strideA">Array of dimension of at least arrayLengthRequested that will be
            filled with the filter stride from the provided convolution descriptor.</param>
            <param name="dilationA">Array of dimension at least arrayLengthRequested that will be filled
            with the dilation parameters from the provided convolution descriptor.</param>
            <param name="mode">convolution mode of the provided descriptor.</param>
            <param name="computeType">datatype of the provided descriptor.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetConvolutionNdForwardOutputDim(ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnFilterDescriptor,System.Int32,System.Int32[])">
            <summary>
            This function returns the dimensions of the resulting n-D tensor of a nbDims-2-D
            convolution, given the convolution descriptor, the input tensor descriptor and the filter
            descriptor This function can help to setup the output tensor and allocate the proper
            amount of memory prior to launch the actual convolution.<para/>
            Each dimension of the (nbDims-2)-D images of the output tensor is computed as
            followed:<para/>
            outputDim = 1 + (inputDim + 2*pad - filterDim)/convolutionStride;
            </summary>
            <param name="convDesc">Handle to a previously created convolution descriptor.</param>
            <param name="inputTensorDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="filterDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="nbDims">Dimension of the output tensor</param>
            <param name="tensorOuputDimA">Array of dimensions nbDims that contains on exit of this routine the sizes
            of the output tensor</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnDestroyConvolutionDescriptor(ManagedCuda.CudaDNN.cudnnConvolutionDescriptor)">
            <summary>
            This function destroys a previously created convolution descriptor object.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetConvolutionForwardAlgorithmMaxCount(ManagedCuda.CudaDNN.cudnnHandle,System.Int32@)">
            <summary>
            
            </summary>
            <param name="handle"></param>
            <param name="count"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnFindConvolutionForwardAlgorithm(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,System.Int32,System.Int32@,ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgoPerf[])">
            <summary>
            This function attempts all cuDNN algorithms and outputs performance metrics to a
            user-allocated array of cudnnConvolutionFwdAlgoPerf_t. These metrics are written
            in sorted fashion where the first element has the lowest compute time.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="srcDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="filterDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="destDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="requestedAlgoCount">The maximum number of elements to be stored in perfResults.</param>
            <param name="returnedAlgoCount">The number of output elements stored in perfResults.</param>
            <param name="perfResults">A user-allocated array to store performance metrics sorted ascending by
            compute time.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnFindConvolutionForwardAlgorithmEx(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Int32,System.Int32@,ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgoPerf@,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT)">
            <summary>
            This function attempts all available cuDNN algorithms for cudnnConvolutionForward, using 
            user-allocated GPU memory, and outputs performance metrics to a user-allocated array of 
            cudnnConvolutionFwdAlgoPerf_t. These metrics are written in sorted fashion where the first 
            element has the lowest compute time. The workspace size should be the largest workspace you 
            can spare in device memory; the size of this workspace will determine the availablity of 
            the convolution algorithms.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor xDesc.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor wDesc.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="yDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the tensor descriptor yDesc. The content of this tensor will be overwritten with arbitary values.</param>
            <param name="requestedAlgoCount">The maximum number of elements to be stored in perfResults.</param>
            <param name="returnedAlgoCount">The number of output elements stored in perfResults.</param>
            <param name="perfResults">A user-allocated array to store performance metrics sorted ascending by compute time.</param>
            <param name="workSpace">Data pointer to GPU memory that is a necessary workspace for some algorithms. The size of this workspace will determine the availability of algorithms. A nil pointer is considered a workSpace of 0 bytes.</param>
            <param name="workSpaceSizeInBytes">Specifies the size in bytes of the provided workSpace.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetConvolutionForwardAlgorithm(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionFwdPreference,ManagedCuda.BasicTypes.SizeT,ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgo@)">
            <summary>
            This function serves as a heuristic for obtaining the best suited algorithm for
            cudnnConvolutionForward for the given layer specifications. Based on the input
            preference, this function will either return the fastest algorithm or the fastest algorithm
            within a given memory limit. For an exhaustive search for the fastest algorithm, please
            use cudnnFindConvolutionForwardAlgorithm.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="filterDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="yDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="preference">Enumerant to express the preference criteria in terms of memory
            requirement and speed.</param>
            <param name="memoryLimitInbytes">It is used when enumerant preference is set to
            CUDNN_CONVOLUTION_FWD_SPECIFY_WORKSPACE_LIMIT to specify the
            maximum amount of GPU memory the user is willing to use as a workspace</param>
            <param name="algo">Enumerant that specifies which convolution algorithm should be used to
            compute the results according to the specified preference</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetConvolutionForwardAlgorithm_v7(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,System.Int32,System.Int32@,ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgoPerf[])">
            <summary>
            
            </summary>
            <param name="handle"></param>
            <param name="srcDesc"></param>
            <param name="filterDesc"></param>
            <param name="convDesc"></param>
            <param name="destDesc"></param>
            <param name="requestedAlgoCount"></param>
            <param name="returnedAlgoCount"></param>
            <param name="perfResults"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetConvolutionForwardWorkspaceSize(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgo,ManagedCuda.BasicTypes.SizeT@)">
            <summary>
            This function returns the amount of GPU memory workspace the user needs
            to allocate to be able to call cudnnConvolutionForward with the specified
            algorithm. The workspace allocated will then be passed to the routine
            cudnnConvolutionForward. The specified algorithm can be the result of the call to
            cudnnGetConvolutionForwardAlgorithm or can be chosen arbitrarily by the user.
            Note that not every algorithm is available for every configuration of the input tensor
            and/or every configuration of the convolution descriptor.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="filterDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="yDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="algo">Enumerant that specifies the chosen convolution algorithm</param>
            <param name="sizeInBytes">Amount of GPU memory needed as workspace to be able to execute a
            forward convolution with the specified algo</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnConvolutionForward(ManagedCuda.CudaDNN.cudnnHandle,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgo,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function executes convolutions or cross-correlations over src using the specified
            filters, returning results in dest. Scaling factors alpha and beta can be used to scale
            the input tensor and the output tensor respectively.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="xDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor filterDesc.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="algo">Enumerant that specifies which convolution algorithm shoud be used to compute the results</param>
            <param name="workSpace">Data pointer to GPU memory to a workspace needed to able to execute
            the specified algorithm. If no workspace is needed for a particular
            algorithm, that pointer can be nil</param>
            <param name="workSpaceSizeInBytes">Specifies the size in bytes of the provided workSpace</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the tensor descriptor
            destDesc that carries the result of the convolution.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnConvolutionForward(ManagedCuda.CudaDNN.cudnnHandle,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgo,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function executes convolutions or cross-correlations over src using the specified
            filters, returning results in dest. Scaling factors alpha and beta can be used to scale
            the input tensor and the output tensor respectively.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="xDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor filterDesc.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="algo">Enumerant that specifies which convolution algorithm shoud be used to compute the results</param>
            <param name="workSpace">Data pointer to GPU memory to a workspace needed to able to execute
            the specified algorithm. If no workspace is needed for a particular
            algorithm, that pointer can be nil</param>
            <param name="workSpaceSizeInBytes">Specifies the size in bytes of the provided workSpace</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the tensor descriptor
            destDesc that carries the result of the convolution.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnConvolutionBiasActivationForward(ManagedCuda.CudaDNN.cudnnHandle,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgo,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnActivationDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function applies a bias and then an activation to the convolutions or crosscorrelations
            of cudnnConvolutionForward(), returning results in y.The full computation
            follows the equation y = act(alpha1* conv(x) + alpha2* z + bias ).<para/>
            The routine cudnnGetConvolution2dForwardOutputDim or
            cudnnGetConvolutionNdForwardOutputDim can be used to determine the proper
            dimensions of the output tensor descriptor yDesc with respect to xDesc, convDesc and wDesc.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="alpha1">Pointers to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as described by the above equation.</param>
            <param name="xDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor xDesc.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor wDesc.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="algo">Enumerant that specifies which convolution algorithm shoud be used to compute the results</param>
            <param name="workSpace">Data pointer to GPU memory to a workspace needed to able to execute
            the specified algorithm.If no workspace is needed for a particular
            algorithm, that pointer can be nil</param>
            <param name="workSpaceSizeInBytes">Specifies the size in bytes of the provided workSpace</param>
            <param name="alpha2">Pointers to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as described by the above equation.</param>
            <param name="zDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="z">Data pointer to GPU memory associated with the tensor descriptor zDesc.</param>
            <param name="biasDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="bias">Data pointer to GPU memory associated with the tensor descriptor biasDesc.</param>
            <param name="activationDesc">Handle to a previously initialized activation descriptor.</param>
            <param name="yDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the tensor descriptor yDesc
            that carries the result of the convolution.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnConvolutionBiasActivationForward(ManagedCuda.CudaDNN.cudnnHandle,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgo,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnActivationDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function applies a bias and then an activation to the convolutions or crosscorrelations
            of cudnnConvolutionForward(), returning results in y.The full computation
            follows the equation y = act(alpha1* conv(x) + alpha2* z + bias ).<para/>
            The routine cudnnGetConvolution2dForwardOutputDim or
            cudnnGetConvolutionNdForwardOutputDim can be used to determine the proper
            dimensions of the output tensor descriptor yDesc with respect to xDesc, convDesc and wDesc.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="alpha1">Pointers to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as described by the above equation.</param>
            <param name="xDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor xDesc.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor wDesc.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="algo">Enumerant that specifies which convolution algorithm shoud be used to compute the results</param>
            <param name="workSpace">Data pointer to GPU memory to a workspace needed to able to execute
            the specified algorithm.If no workspace is needed for a particular
            algorithm, that pointer can be nil</param>
            <param name="workSpaceSizeInBytes">Specifies the size in bytes of the provided workSpace</param>
            <param name="alpha2">Pointers to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as described by the above equation.</param>
            <param name="zDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="z">Data pointer to GPU memory associated with the tensor descriptor zDesc.</param>
            <param name="biasDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="bias">Data pointer to GPU memory associated with the tensor descriptor biasDesc.</param>
            <param name="activationDesc">Handle to a previously initialized activation descriptor.</param>
            <param name="yDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the tensor descriptor yDesc
            that carries the result of the convolution.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnConvolutionBackwardBias(ManagedCuda.CudaDNN.cudnnHandle,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function computes the convolution gradient with respect to the bias, which is the
            sum of every element belonging to the same feature map across all of the images of the
            input tensor. Therefore, the number of elements produced is equal to the number of
            features maps of the input tensor.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dyDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="dy">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dbDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="db">Data pointer to GPU memory associated with the output tensor descriptor destDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnConvolutionBackwardBias(ManagedCuda.CudaDNN.cudnnHandle,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function computes the convolution gradient with respect to the bias, which is the
            sum of every element belonging to the same feature map across all of the images of the
            input tensor. Therefore, the number of elements produced is equal to the number of
            features maps of the input tensor.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dyDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="dy">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dbDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="db">Data pointer to GPU memory associated with the output tensor descriptor destDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetConvolutionBackwardFilterAlgorithmMaxCount(ManagedCuda.CudaDNN.cudnnHandle,System.Int32@)">
            <summary>
            
            </summary>
            <param name="handle"></param>
            <param name="count"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnFindConvolutionBackwardFilterAlgorithm(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnFilterDescriptor,System.Int32,System.Int32@,ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterAlgoPerf[])">
            <summary>
            This function attempts all cuDNN algorithms for cudnnConvolutionBackwardFilter_v3 and outputs performance metrics to a user-
            allocated array of cudnnConvolutionBwdFilterAlgoPerf_t. These metrics are
            written in sorted fashion where the first element has the lowest compute time. 
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="dwDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="requestedAlgoCount">The maximum number of elements to be stored in perfResults.</param>
            <param name="returnedAlgoCount">The number of output elements stored in perfResults.</param>
            <param name="perfResults">A user-allocated array to store performance metrics sorted ascending by compute time.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnFindConvolutionBackwardFilterAlgorithmEx(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Int32,System.Int32@,ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterAlgoPerf@,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT)">
            <summary>
            This function attempts all cuDNN algorithms for cudnnConvolutionBackwardFilter, 
            using user-allocated GPU memory, and outputs performance metrics to a 
            user-allocated array of cudnnConvolutionBwdFilterAlgoPerf_t. These metrics are 
            written in sorted fashion where the first element has the lowest compute time. The 
            workspace size should be the largest workspace you can spare in device memory; the 
            size of this workspace will determine the availablity of convolution algorithms.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor. </param>
            <param name="x">Data pointer to GPU memory associated with the filter descriptor xDesc.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="dy">Data pointer to GPU memory associated with the tensor descriptor dyDesc.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="dwDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="dw">Data pointer to GPU memory associated with the filter descriptor dwDesc.The content of this tensor will be overwritten with arbitary values.</param>
            <param name="requestedAlgoCount">The maximum number of elements to be stored in perfResults.</param>
            <param name="returnedAlgoCount">The number of output elements stored in perfResults.</param>
            <param name="perfResults">A user-allocated array to store performance metrics sorted ascending by compute time.</param>
            <param name="workSpace">Data pointer to GPU memory that is a necessary workspace for some algorithms. The size of this workspace will determine the availabilty of algorithms. A nil pointer is considered a workSpace of 0 bytes.</param>
            <param name="workSpaceSizeInBytes">Specifies the size in bytes of the provided workSpace.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetConvolutionBackwardFilterAlgorithm(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterPreference,ManagedCuda.BasicTypes.SizeT,ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterAlgo@)">
            <summary>
            This function serves as a heuristic for obtaining the best suited algorithm for
            cudnnConvolutionBackwardFilter for the given layer specifications. Based
            on the input preference, this function will either return the fastest algorithm or the
            fastest algorithm within a given memory limit. For an exhaustive search for the fastest
            algorithm, please use cudnnFindConvolutionBackwardFilterAlgorithm.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="dwDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="preference">Enumerant to express the preference criteria in terms of memory requirement and speed.</param>
            <param name="memoryLimitInbytes">It is to specify the maximum amount of GPU memory the user is willing to 
            use as a workspace. This is currently a placeholder and is not used.</param>
            <param name="algo">Enumerant that specifies which convolution algorithm should be used to
            compute the results according to the specified preference</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetConvolutionBackwardFilterAlgorithm_v7(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnFilterDescriptor,System.Int32,System.Int32@,ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterAlgoPerf[])">
            <summary>
            
            </summary>
            <param name="handle"></param>
            <param name="srcDesc"></param>
            <param name="diffDesc"></param>
            <param name="convDesc"></param>
            <param name="gradDesc"></param>
            <param name="requestedAlgoCount"></param>
            <param name="returnedAlgoCount"></param>
            <param name="perfResults"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetConvolutionBackwardFilterWorkspaceSize(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterAlgo,ManagedCuda.BasicTypes.SizeT@)">
            <summary>
            This function returns the amount of GPU memory workspace the user needs
            to allocate to be able to call cudnnConvolutionBackwardFilter_v3 with the
            specified algorithm. The workspace allocated will then be passed to the routine
            cudnnConvolutionBackwardFilter. The specified algorithm can be the result
            of the call to cudnnGetConvolutionBackwardFilterAlgorithm or can be chosen
            arbitrarily by the user. Note that not every algorithm is available for every configuration
            of the input tensor and/or every configuration of the convolution descriptor.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="gradDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="algo">Enumerant that specifies the chosen convolution algorithm
            sizeInBytes output Amount of GPU memory needed as workspace to be able to execute</param>
            <param name="sizeInBytes">Amount of GPU memory needed as workspace to be able to execute a
            forward convolution with the specified algo</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnConvolutionBackwardFilter(ManagedCuda.CudaDNN.cudnnHandle,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterAlgo,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT,System.Single@,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function computes the convolution gradient with respect to filter coefficients using
            the specified algo, returning results in gradDesc.Scaling factors alpha and beta can be
            used to scale the input tensor and the output tensor respectively.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="xDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="dy">Data pointer to GPU memory associated with the input differential tensor descriptor diffDesc.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="algo">Enumerant that specifies which convolution algorithm shoud be used to compute the results</param>
            <param name="workSpace">Data pointer to GPU memory to a workspace needed to able to execute
            the specified algorithm. If no workspace is needed for a particular
            algorithm, that pointer can be nil</param>
            <param name="workSpaceSizeInBytes">Specifies the size in bytes of the provided workSpace</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dwDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="dw">Data pointer to GPU memory associated with the filter descriptor
            gradDesc that carries the result.</param>    
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnConvolutionBackwardFilter(ManagedCuda.CudaDNN.cudnnHandle,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterAlgo,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT,System.Double@,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function computes the convolution gradient with respect to filter coefficients using
            the specified algo, returning results in gradDesc.Scaling factors alpha and beta can be
            used to scale the input tensor and the output tensor respectively.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="xDesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="dy">Data pointer to GPU memory associated with the input differential tensor descriptor diffDesc.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="algo">Enumerant that specifies which convolution algorithm shoud be used to compute the results</param>
            <param name="workSpace">Data pointer to GPU memory to a workspace needed to able to execute
            the specified algorithm. If no workspace is needed for a particular
            algorithm, that pointer can be nil</param>
            <param name="workSpaceSizeInBytes">Specifies the size in bytes of the provided workSpace</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dwDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="dw">Data pointer to GPU memory associated with the filter descriptor
            gradDesc that carries the result.</param>    
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetConvolutionBackwardDataAlgorithmMaxCount(ManagedCuda.CudaDNN.cudnnHandle,System.Int32@)">
            <summary>
            
            </summary>
            <param name="handle"></param>
            <param name="count"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnFindConvolutionBackwardDataAlgorithm(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,System.Int32,System.Int32@,ManagedCuda.CudaDNN.cudnnConvolutionBwdDataAlgoPerf[])">
            <summary>
            This function attempts all cuDNN algorithms for
            cudnnConvolutionBackwardData and outputs performance metrics to a user-
            allocated array of cudnnConvolutionBwdDataAlgoPerf_t. These metrics are written
            in sorted fashion where the first element has the lowest compute time.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="dxDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="requestedAlgoCount">The maximum number of elements to be stored in perfResults.</param>
            <param name="returnedAlgoCount">The number of output elements stored in perfResults.</param>
            <param name="perfResults">A user-allocated array to store performance metrics sorted ascending by compute time.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetConvolutionBackwardDataAlgorithm(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionBwdDataPreference,ManagedCuda.BasicTypes.SizeT,ManagedCuda.CudaDNN.cudnnConvolutionBwdDataAlgo@)">
            <summary>
            This function serves as a heuristic for obtaining the best suited algorithm for
            cudnnConvolutionBackwardData for the given layer specifications. Based
            on the input preference, this function will either return the fastest algorithm or the
            fastest algorithm within a given memory limit. For an exhaustive search for the fastest
            algorithm, please use cudnnFindConvolutionBackwardDataAlgorithm.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="dxDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="preference">Enumerant to express the preference criteria in terms of memory
            requirement and speed.</param>
            <param name="memoryLimitInbytes">It is to specify the maximum amount of GPU memory the user is willing to
            use as a workspace. This is currently a placeholder and is not used.</param>
            <param name="algo">Enumerant that specifies which convolution algorithm should be used to
            compute the results according to the specified preference</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetConvolutionBackwardDataAlgorithm_v7(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,System.Int32,System.Int32@,ManagedCuda.CudaDNN.cudnnConvolutionBwdDataAlgoPerf[])">
            <summary>
            
            </summary>
            <param name="handle"></param>
            <param name="filterDesc"></param>
            <param name="diffDesc"></param>
            <param name="convDesc"></param>
            <param name="gradDesc"></param>
            <param name="requestedAlgoCount"></param>
            <param name="returnedAlgoCount"></param>
            <param name="perfResults"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetConvolutionBackwardDataWorkspaceSize(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionBwdDataAlgo,ManagedCuda.BasicTypes.SizeT@)">
            <summary>
            This function returns the amount of GPU memory workspace the user needs
            to allocate to be able to call cudnnConvolutionBackwardData with the
            specified algorithm. The workspace allocated will then be passed to the routine
            cudnnConvolutionBackwardData. The specified algorithm can be the result of the
            call to cudnnGetConvolutionBackwardDataAlgorithm or can be chosen arbitrarily
            by the user. Note that not every algorithm is available for every configuration of the
            input tensor and/or every configuration of the convolution descriptor.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="dxDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="algo">Enumerant that specifies the chosen convolution algorithm</param>
            <param name="sizeInBytes">Amount of GPU memory needed as workspace to be able to execute a forward convolution with the specified algo</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnConvolutionBackwardData(ManagedCuda.CudaDNN.cudnnHandle,System.Single@,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionBwdDataAlgo,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function computes the convolution gradient with respect to the output tensor using
            the specified algo, returning results in gradDesc. Scaling factors alpha and beta can
            be used to scale the input tensor and the output tensor respectively.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor filterDesc.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="dy">Data pointer to GPU memory associated with the input differential tensor descriptor diffDesc.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="algo">Enumerant that specifies which backward data convolution algorithm shoud be used to compute the results</param>
            <param name="workSpace">Data pointer to GPU memory to a workspace needed to able to execute
            the specified algorithm. If no workspace is needed for a particular
            algorithm, that pointer can be nil</param>
            <param name="workSpaceSizeInBytes">Specifies the size in bytes of the provided workSpace</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dxDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="dx">Data pointer to GPU memory associated with the output tensor descriptor
            gradDesc that carries the result.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnConvolutionBackwardData(ManagedCuda.CudaDNN.cudnnHandle,System.Double@,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionBwdDataAlgo,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function computes the convolution gradient with respect to the output tensor using
            the specified algo, returning results in gradDesc. Scaling factors alpha and beta can
            be used to scale the input tensor and the output tensor respectively.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor filterDesc.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="dy">Data pointer to GPU memory associated with the input differential tensor descriptor diffDesc.</param>
            <param name="convDesc">Previously initialized convolution descriptor.</param>
            <param name="algo">Enumerant that specifies which backward data convolution algorithm shoud be used to compute the results</param>
            <param name="workSpace">Data pointer to GPU memory to a workspace needed to able to execute
            the specified algorithm. If no workspace is needed for a particular
            algorithm, that pointer can be nil</param>
            <param name="workSpaceSizeInBytes">Specifies the size in bytes of the provided workSpace</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dxDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="dx">Data pointer to GPU memory associated with the output tensor descriptor
            gradDesc that carries the result.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnIm2Col(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.CudaDNN.cudnnConvolutionDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSoftmaxForward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnSoftmaxAlgorithm,ManagedCuda.CudaDNN.cudnnSoftmaxMode,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This routine computes the softmax function.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="algorithm">Enumerant to specify the softmax algorithm.</param>
            <param name="mode">Enumerant to specify the softmax mode.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor destDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSoftmaxForward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnSoftmaxAlgorithm,ManagedCuda.CudaDNN.cudnnSoftmaxMode,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This routine computes the softmax function.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="algorithm">Enumerant to specify the softmax algorithm.</param>
            <param name="mode">Enumerant to specify the softmax mode.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor destDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSoftmaxBackward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnSoftmaxAlgorithm,ManagedCuda.CudaDNN.cudnnSoftmaxMode,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This routine computes the gradient of the softmax function.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="algorithm">Enumerant to specify the softmax algorithm.</param>
            <param name="mode">Enumerant to specify the softmax mode.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="dy">Data pointer to GPU memory associated with the tensor descriptor srcDiffData.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dxDesc">Handle to the previously initialized output differential tensor descriptor.</param>
            <param name="dx">Data pointer to GPU memory associated with the output tensor descriptor destDiffDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSoftmaxBackward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnSoftmaxAlgorithm,ManagedCuda.CudaDNN.cudnnSoftmaxMode,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This routine computes the gradient of the softmax function.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="algorithm">Enumerant to specify the softmax algorithm.</param>
            <param name="mode">Enumerant to specify the softmax mode.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="dy">Data pointer to GPU memory associated with the tensor descriptor srcDiffData.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dxDesc">Handle to the previously initialized output differential tensor descriptor.</param>
            <param name="dx">Data pointer to GPU memory associated with the output tensor descriptor destDiffDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnCreatePoolingDescriptor(ManagedCuda.CudaDNN.cudnnPoolingDescriptor@)">
            <summary>
            This function creates a pooling descriptor object by allocating the memory needed to hold its opaque structure
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetPooling2dDescriptor(ManagedCuda.CudaDNN.cudnnPoolingDescriptor,ManagedCuda.CudaDNN.cudnnPoolingMode,ManagedCuda.CudaDNN.cudnnNanPropagation,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            This function initializes a previously created generic pooling descriptor object into a 2D description.
            </summary>
            <param name="poolingDesc">Handle to a previously created pooling descriptor.</param>
            <param name="mode">Enumerant to specify the pooling mode.</param>
            <param name="maxpoolingNanOpt">Nan propagation option for max pooling.</param>
            <param name="windowHeight">Height of the pooling window.</param>
            <param name="windowWidth">Width of the pooling window.</param>
            <param name="verticalPadding">Size of vertical padding.</param>
            <param name="horizontalPadding">Size of horizontal padding</param>
            <param name="verticalStride">Pooling vertical stride.</param>
            <param name="horizontalStride">Pooling horizontal stride.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetPooling2dDescriptor(ManagedCuda.CudaDNN.cudnnPoolingDescriptor,ManagedCuda.CudaDNN.cudnnPoolingMode@,ManagedCuda.CudaDNN.cudnnNanPropagation@,System.Int32@,System.Int32@,System.Int32@,System.Int32@,System.Int32@,System.Int32@)">
            <summary>
            This function queries a previously created 2D pooling descriptor object.
            </summary>
            <param name="poolingDesc">Handle to a previously created pooling descriptor.</param>
            <param name="mode">Enumerant to specify the pooling mode.</param>
            <param name="maxpoolingNanOpt">Nan propagation option for max pooling.</param>
            <param name="windowHeight">Height of the pooling window.</param>
            <param name="windowWidth">Width of the pooling window.</param>
            <param name="verticalPadding">Size of vertical padding.</param>
            <param name="horizontalPadding">Size of horizontal padding.</param>
            <param name="verticalStride">Pooling vertical stride.</param>
            <param name="horizontalStride">Pooling horizontal stride.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetPoolingNdDescriptor(ManagedCuda.CudaDNN.cudnnPoolingDescriptor,ManagedCuda.CudaDNN.cudnnPoolingMode,ManagedCuda.CudaDNN.cudnnNanPropagation,System.Int32,System.Int32[],System.Int32[],System.Int32[])">
            <summary>
            This function initializes a previously created generic pooling descriptor object.
            </summary>
            <param name="poolingDesc">Handle to a previously created pooling descriptor.</param>
            <param name="mode">Enumerant to specify the pooling mode.</param>
            <param name="maxpoolingNanOpt">Nan propagation option for max pooling.</param>
            <param name="nbDims">Dimension of the pooling operation.</param>
            <param name="windowDimA">Array of dimension nbDims containing the window size for each dimension.</param>
            <param name="paddingA">Array of dimension nbDims containing the padding size for each dimension.</param>
            <param name="strideA">Array of dimension nbDims containing the striding size for each dimension.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetPoolingNdDescriptor(ManagedCuda.CudaDNN.cudnnPoolingDescriptor,System.Int32,ManagedCuda.CudaDNN.cudnnPoolingMode@,ManagedCuda.CudaDNN.cudnnNanPropagation@,System.Int32@,System.Int32[],System.Int32[],System.Int32[])">
            <summary>
            This function queries a previously initialized generic pooling descriptor object.
            </summary>
            <param name="poolingDesc">Handle to a previously created pooling descriptor.</param>
            <param name="nbDimsRequested">Dimension of the expected pooling descriptor. It is also the minimum
            size of the arrays windowDimA, paddingA and strideA in order to be
            able to hold the results</param>
            <param name="mode">Enumerant to specify the pooling mode.</param>
            <param name="maxpoolingNanOpt">Nan propagation option for max pooling.</param>
            <param name="nbDims">Actual dimension of the pooling descriptor.</param>
            <param name="windowDimA">Array of dimension of at least nbDimsRequested that will be filled with
            the window parameters from the provided pooling descriptor.</param>
            <param name="paddingA">Array of dimension of at least nbDimsRequested that will be filled with
            the padding parameters from the provided pooling descriptor.</param>
            <param name="strideA">Array of dimension at least nbDimsRequested that will be filled with
            the stride parameters from the provided pooling descriptor.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetPoolingNdForwardOutputDim(ManagedCuda.CudaDNN.cudnnPoolingDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,System.Int32,System.Int32[])">
            <summary>
            This function provides the output dimensions of a tensor after Nd pooling has been applied
            </summary>
            <param name="poolingDesc">Handle to a previously inititalized pooling descriptor.</param>
            <param name="inputTensorDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="nbDims">Number of dimensions in which pooling is to be applied.</param>
            <param name="outputTensorDimA">Array of nbDims output dimensions</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetPooling2dForwardOutputDim(ManagedCuda.CudaDNN.cudnnPoolingDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,System.Int32@,System.Int32@,System.Int32@,System.Int32@)">
            <summary>
            This function provides the output dimensions of a tensor after 2d pooling has been applied
            </summary>
            <param name="poolingDesc">Handle to a previously inititalized pooling descriptor.</param>
            <param name="inputTensorDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="n">Number of images in the output</param>
            <param name="c">Number of channels in the output</param>
            <param name="h">Height of images in the output</param>
            <param name="w">Width of images in the output</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnDestroyPoolingDescriptor(ManagedCuda.CudaDNN.cudnnPoolingDescriptor)">
            <summary>
            This function destroys a previously created pooling descriptor object.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnPoolingForward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnPoolingDescriptor,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function computes pooling of input values (i.e., the maximum or average of several
            adjacent values) to produce an output with smaller height and/or width.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="poolingDesc">Handle to a previously initialized pooling descriptor.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor destDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnPoolingForward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnPoolingDescriptor,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function computes pooling of input values (i.e., the maximum or average of several
            adjacent values) to produce an output with smaller height and/or width.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="poolingDesc">Handle to a previously initialized pooling descriptor.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor destDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnPoolingBackward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnPoolingDescriptor,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function computes the gradient of a pooling operation.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="poolingDesc">Handle to the previously initialized pooling descriptor.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="dy">Data pointer to GPU memory associated with the tensor descriptor srcDiffData.</param>
            <param name="xDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the output tensor descriptor destDesc.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dxDesc">Handle to the previously initialized output differential tensor descriptor.</param>
            <param name="dx">Data pointer to GPU memory associated with the output tensor descriptor destDiffDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnPoolingBackward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnPoolingDescriptor,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function computes the gradient of a pooling operation.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="poolingDesc">Handle to the previously initialized pooling descriptor.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="dy">Data pointer to GPU memory associated with the tensor descriptor srcDiffData.</param>
            <param name="xDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the output tensor descriptor destDesc.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dxDesc">Handle to the previously initialized output differential tensor descriptor.</param>
            <param name="dx">Data pointer to GPU memory associated with the output tensor descriptor destDiffDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnCreateActivationDescriptor(ManagedCuda.CudaDNN.cudnnActivationDescriptor@)">
            <summary>
             This function creates a activation descriptor object by allocating the memory needed to hold its opaque structure.
             </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetActivationDescriptor(ManagedCuda.CudaDNN.cudnnActivationDescriptor,ManagedCuda.CudaDNN.cudnnActivationMode,ManagedCuda.CudaDNN.cudnnNanPropagation,System.Double)">
            <summary>
             This function initializes then previously created activation descriptor object.
             </summary>
             <param name="activationDesc">Handle to the previously created activation descriptor object.</param>
             <param name="mode">Enumerant to specify the activation mode.</param>
             <param name="reluNanOpt">Nan propagation option for the relu.</param>
             <param name="coef">floating point number to specify the clipping threashold when the activation
             mode is set to CUDNN_ACTIVATION_CLIPPED_RELU or to specify the alpha
             coefficient when the activation mode is set to CUDNN_ACTIVATION_ELU.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetActivationDescriptor(ManagedCuda.CudaDNN.cudnnActivationDescriptor,ManagedCuda.CudaDNN.cudnnActivationMode@,ManagedCuda.CudaDNN.cudnnNanPropagation@,System.Double@)">
            <summary>
            This function queries the parameters of the previouly initialized activation descriptor object.
            </summary>
            <param name="activationDesc">Handle to the previously created activation descriptor object.</param>
            <param name="mode">Enumerant to specify the activation mode.</param>
            <param name="reluNanOpt">Nan propagation option for the relu.</param>
            <param name="coef">floating point number to specify the clipping threashold when the activation
            mode is set to CUDNN_ACTIVATION_CLIPPED_RELU or to specify the alpha
            coefficient when the activation mode is set to CUDNN_ACTIVATION_ELU.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnDestroyActivationDescriptor(ManagedCuda.CudaDNN.cudnnActivationDescriptor)">
            <summary>
            This function destroys a previously created activation descriptor object.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnActivationForward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnActivationDescriptor,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This routine applies a specified neuron activation function element-wise over each input value.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="activationDesc">Handle to the previously created activation descriptor object.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor destDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnActivationForward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnActivationDescriptor,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This routine applies a specified neuron activation function element-wise over each input value.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="activationDesc">Handle to the previously created activation descriptor object.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor destDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnActivationBackward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnActivationDescriptor,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This routine computes the gradient of a neuron activation function.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="activationDesc">Handle to the previously created activation descriptor object.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="dy">Data pointer to GPU memory associated with the tensor descriptor srcDiffData.</param>
            <param name="xDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the output tensor descriptor destDesc.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dxDesc">Handle to the previously initialized output differential tensor descriptor.</param>
            <param name="dx">Data pointer to GPU memory associated with the output tensor descriptor destDiffDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnActivationBackward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnActivationDescriptor,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This routine computes the gradient of a neuron activation function.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="activationDesc">Handle to the previously created activation descriptor object.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="yDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the tensor descriptor srcDesc.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="dy">Data pointer to GPU memory associated with the tensor descriptor srcDiffData.</param>
            <param name="xDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the output tensor descriptor destDesc.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the computation
            result with prior value in the output layer as follows: dstValue =
            alpha[0]*result + beta[0]*priorDstValue. Please refer to this section for
            additional details.</param>
            <param name="dxDesc">Handle to the previously initialized output differential tensor descriptor.</param>
            <param name="dx">Data pointer to GPU memory associated with the output tensor descriptor destDiffDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnCreateLRNDescriptor(ManagedCuda.CudaDNN.cudnnLRNDescriptor@)">
            <summary>
            Create an instance of LRN (Local Response Normalization) descriptor <para/>
            This function will set lrnN=5, lrnAlpha=1e-4, lrnBeta=0.75, lrnK=2.0 as defaults from Krizhevsky'12 ImageNet paper
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetLRNDescriptor(ManagedCuda.CudaDNN.cudnnLRNDescriptor,System.UInt32,System.Double,System.Double,System.Double)">
            <summary>
            This function initializes a previously created LRN descriptor object.
            </summary>
            <param name="normDesc">Handle to a previously created LRN descriptor.</param>
            <param name="lrnN">Normalization window width in elements. LRN layer uses a window
            [center-lookBehind, center+lookAhead], where lookBehind =
            floor( (lrnN-1)/2 ), lookAhead = lrnN-lookBehind-1. So for n=10,
            the window is [k-4...k...k+5] with a total of 10 samples. For
            DivisiveNormalization layer the window has the same extents as above in
            all 'spatial' dimensions (dimA[2], dimA[3], dimA[4]). By default lrnN is set
            to 5 in cudnnCreateLRNDescriptor.</param>
            <param name="lrnAlpha">Value of the alpha variance scaling parameter in the normalization
            formula. Inside the library code this value is divided by the
            window width for LRN and by (window width)^#spatialDimensions
            for DivisiveNormalization. By default this value is set to 1e-4 in
            cudnnCreateLRNDescriptor.</param>
            <param name="lrnBeta">Value of the beta power parameter in the normalization formula. By
            default this value is set to 0.75 in cudnnCreateLRNDescriptor.</param>
            <param name="lrnK">Value of the k parameter in normalization formula. By default this value is set to 2.0.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetLRNDescriptor(ManagedCuda.CudaDNN.cudnnLRNDescriptor,System.UInt32@,System.Double@,System.Double@,System.Double@)">
            <summary>
            This function retrieves values stored in the previously initialized LRN descriptor object.
            </summary>
            <param name="normDesc">Handle to a previously created LRN descriptor.</param>
            <param name="lrnN">Pointers to receive values of parameters stored in the descriptor object.
            See cudnnSetLRNDescriptor for more details. Any of these pointers can be
            NULL (no value is returned for the corresponding parameter).</param>
            <param name="lrnAlpha">Pointers to receive values of parameters stored in the descriptor object.
            See cudnnSetLRNDescriptor for more details. Any of these pointers can be
            NULL (no value is returned for the corresponding parameter).</param>
            <param name="lrnBeta">Pointers to receive values of parameters stored in the descriptor object.
            See cudnnSetLRNDescriptor for more details. Any of these pointers can be
            NULL (no value is returned for the corresponding parameter).</param>
            <param name="lrnK">Pointers to receive values of parameters stored in the descriptor object.
            See cudnnSetLRNDescriptor for more details. Any of these pointers can be
            NULL (no value is returned for the corresponding parameter).</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnDestroyLRNDescriptor(ManagedCuda.CudaDNN.cudnnLRNDescriptor)">
            <summary>
            This function destroys a previously created LRN descriptor object.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnLRNCrossChannelForward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnLRNDescriptor,ManagedCuda.CudaDNN.cudnnLRNMode,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function performs the forward LRN layer computation.
            </summary>
            <param name="handle">Handle to a previously created cuDNN library descriptor.</param>
            <param name="normDesc">Handle to a previously intialized LRN parameter descriptor.</param>
            <param name="lrnMode">LRN layer mode of operation. Currently only
            CUDNN_LRN_CROSS_CHANNEL_DIM1 is implemented. Normalization is
            performed along the tensor's dimA[1].</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="xDesc">Tensor descriptor objects for the input and output tensors.</param>
            <param name="x">Input tensor data pointer in device memory.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="yDesc">Tensor descriptor objects for the input and output tensors.</param>
            <param name="y">Output tensor data pointer in device memory.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnLRNCrossChannelForward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnLRNDescriptor,ManagedCuda.CudaDNN.cudnnLRNMode,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function performs the forward LRN layer computation.
            </summary>
            <param name="handle">Handle to a previously created cuDNN library descriptor.</param>
            <param name="normDesc">Handle to a previously intialized LRN parameter descriptor.</param>
            <param name="lrnMode">LRN layer mode of operation. Currently only
            CUDNN_LRN_CROSS_CHANNEL_DIM1 is implemented. Normalization is
            performed along the tensor's dimA[1].</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="xDesc">Tensor descriptor objects for the input and output tensors.</param>
            <param name="x">Input tensor data pointer in device memory.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="yDesc">Tensor descriptor objects for the input and output tensors.</param>
            <param name="y">Output tensor data pointer in device memory.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnLRNCrossChannelBackward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnLRNDescriptor,ManagedCuda.CudaDNN.cudnnLRNMode,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function performs the backward LRN layer computation.
            </summary>
            <param name="handle">Handle to a previously created cuDNN library descriptor.</param>
            <param name="normDesc">Handle to a previously intialized LRN parameter descriptor.</param>
            <param name="lrnMode">LRN layer mode of operation. Currently only
            CUDNN_LRN_CROSS_CHANNEL_DIM1 is implemented. Normalization is
            performed along the tensor's dimA[1].</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="yDesc">Tensor descriptor and pointer in device memory for the bottom layer's
            data. (Bottom layer is the earlier layer in the computation graph during
            inference).</param>
            <param name="y">Tensor descriptor and pointer in device memory for the bottom layer's
            data. (Bottom layer is the earlier layer in the computation graph during
            inference).</param>
            <param name="dyDesc">Tensor descriptor and pointer in device memory for the top layer's
            cumulative loss differential data (error backpropagation). (Top layer is the
            later layer in the computation graph during inference).</param>
            <param name="dy">Tensor descriptor and pointer in device memory for the top layer's
            cumulative loss differential data (error backpropagation). (Top layer is the
            later layer in the computation graph during inference).</param>
            <param name="xDesc">Tensor descriptor and pointer in device memory for the bottom layer's
            data. (Bottom layer is the earlier layer in the computation graph
            during inference). Note that these values are not modified during
            backpropagation.</param>
            <param name="x">Tensor descriptor and pointer in device memory for the bottom layer's
            data. (Bottom layer is the earlier layer in the computation graph
            during inference). Note that these values are not modified during
            backpropagation.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="dxDesc">Tensor descriptor and pointer in device memory for the bottom layer's
            cumulative loss differential data (error backpropagation). (Bottom layer is
            the earlier layer in the computation graph during inference).</param>
            <param name="dx">Tensor descriptor and pointer in device memory for the bottom layer's
            cumulative loss differential data (error backpropagation). (Bottom layer is
            the earlier layer in the computation graph during inference).</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnLRNCrossChannelBackward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnLRNDescriptor,ManagedCuda.CudaDNN.cudnnLRNMode,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function performs the backward LRN layer computation.
            </summary>
            <param name="handle">Handle to a previously created cuDNN library descriptor.</param>
            <param name="normDesc">Handle to a previously intialized LRN parameter descriptor.</param>
            <param name="lrnMode">LRN layer mode of operation. Currently only
            CUDNN_LRN_CROSS_CHANNEL_DIM1 is implemented. Normalization is
            performed along the tensor's dimA[1].</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="yDesc">Tensor descriptor and pointer in device memory for the bottom layer's
            data. (Bottom layer is the earlier layer in the computation graph during
            inference).</param>
            <param name="y">Tensor descriptor and pointer in device memory for the bottom layer's
            data. (Bottom layer is the earlier layer in the computation graph during
            inference).</param>
            <param name="dyDesc">Tensor descriptor and pointer in device memory for the top layer's
            cumulative loss differential data (error backpropagation). (Top layer is the
            later layer in the computation graph during inference).</param>
            <param name="dy">Tensor descriptor and pointer in device memory for the top layer's
            cumulative loss differential data (error backpropagation). (Top layer is the
            later layer in the computation graph during inference).</param>
            <param name="xDesc">Tensor descriptor and pointer in device memory for the bottom layer's
            data. (Bottom layer is the earlier layer in the computation graph
            during inference). Note that these values are not modified during
            backpropagation.</param>
            <param name="x">Tensor descriptor and pointer in device memory for the bottom layer's
            data. (Bottom layer is the earlier layer in the computation graph
            during inference). Note that these values are not modified during
            backpropagation.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="dxDesc">Tensor descriptor and pointer in device memory for the bottom layer's
            cumulative loss differential data (error backpropagation). (Bottom layer is
            the earlier layer in the computation graph during inference).</param>
            <param name="dx">Tensor descriptor and pointer in device memory for the bottom layer's
            cumulative loss differential data (error backpropagation). (Bottom layer is
            the earlier layer in the computation graph during inference).</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnDivisiveNormalizationForward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnLRNDescriptor,ManagedCuda.CudaDNN.cudnnDivNormMode,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function performs the forward DivisiveNormalization layer computation.
            </summary>
            <param name="handle">Handle to a previously created cuDNN library descriptor.</param>
            <param name="normDesc">Handle to a previously intialized LRN parameter descriptor. This descriptor
            is used for both LRN and DivisiveNormalization layers.</param>
            <param name="mode">DivisiveNormalization layer mode of operation. Currently only
            CUDNN_DIVNORM_PRECOMPUTED_MEANS is implemented. Normalization
            is performed using the means input tensor that is expected to be
            precomputed by the user.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="xDesc">Tensor descriptor objects for the input and output tensors. Note that
            srcDesc is shared between srcData, srcMeansData, tempData, tempData2
            tensors.</param>
            <param name="x">Input tensor data pointer in device memory.</param>
            <param name="means">Input means tensor data pointer in device memory. Note that this tensor
            can be NULL (in that case it's values are assumed to be zero during the
            computation). This tensor also doesn't have to contain means, these can
            be any values, a frequently used variation is a result of convolution with a
            normalized positive kernel (such as Gaussian).</param>
            <param name="temp">Temporary tensors in device memory. These are used for computing
            intermediate values during the forward pass. These tensors do not have
            to be preserved as inputs from forward to the backward pass. Both use
            srcDesc as a descriptor.</param>
            <param name="temp2">Temporary tensors in device memory. These are used for computing
            intermediate values during the forward pass. These tensors do not have
            to be preserved as inputs from forward to the backward pass. Both use
            srcDesc as a descriptor.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="yDesc">Tensor descriptor objects for the input and output tensors. Note that
            srcDesc is shared between srcData, srcMeansData, tempData, tempData2
            tensors.</param>
            <param name="y">Pointer in device memory to a tensor for the result of the forward DivisiveNormalization pass.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnDivisiveNormalizationForward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnLRNDescriptor,ManagedCuda.CudaDNN.cudnnDivNormMode,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function performs the forward DivisiveNormalization layer computation.
            </summary>
            <param name="handle">Handle to a previously created cuDNN library descriptor.</param>
            <param name="normDesc">Handle to a previously intialized LRN parameter descriptor. This descriptor
            is used for both LRN and DivisiveNormalization layers.</param>
            <param name="mode">DivisiveNormalization layer mode of operation. Currently only
            CUDNN_DIVNORM_PRECOMPUTED_MEANS is implemented. Normalization
            is performed using the means input tensor that is expected to be
            precomputed by the user.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="xDesc">Tensor descriptor objects for the input and output tensors. Note that
            srcDesc is shared between srcData, srcMeansData, tempData, tempData2
            tensors.</param>
            <param name="x">Input tensor data pointer in device memory.</param>
            <param name="means">Input means tensor data pointer in device memory. Note that this tensor
            can be NULL (in that case it's values are assumed to be zero during the
            computation). This tensor also doesn't have to contain means, these can
            be any values, a frequently used variation is a result of convolution with a
            normalized positive kernel (such as Gaussian).</param>
            <param name="temp">Temporary tensors in device memory. These are used for computing
            intermediate values during the forward pass. These tensors do not have
            to be preserved as inputs from forward to the backward pass. Both use
            srcDesc as a descriptor.</param>
            <param name="temp2">Temporary tensors in device memory. These are used for computing
            intermediate values during the forward pass. These tensors do not have
            to be preserved as inputs from forward to the backward pass. Both use
            srcDesc as a descriptor.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="yDesc">Tensor descriptor objects for the input and output tensors. Note that
            srcDesc is shared between srcData, srcMeansData, tempData, tempData2
            tensors.</param>
            <param name="y">Pointer in device memory to a tensor for the result of the forward DivisiveNormalization pass.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnDivisiveNormalizationBackward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnLRNDescriptor,ManagedCuda.CudaDNN.cudnnDivNormMode,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function performs the backward DivisiveNormalization layer computation.
            </summary>
            <param name="handle">Handle to a previously created cuDNN library descriptor.</param>
            <param name="normDesc">Handle to a previously intialized LRN parameter descriptor (this descriptor
            is used for both LRN and DivisiveNormalization layers).</param>
            <param name="mode">DivisiveNormalization layer mode of operation. Currently only
            CUDNN_DIVNORM_PRECOMPUTED_MEANS is implemented. Normalization
            is performed using the means input tensor that is expected to be
            precomputed by the user.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="xDesc">Tensor descriptor and pointers in device memory for the bottom layer's
            data and means. (Bottom layer is the earlier layer in the computation
            graph during inference). Note: the means tensor is expected to be
            precomputed by the user. It can also contain any valid values (not required
            to be actual means, and can be for instance a result of a convolution with
            a Gaussian kernel).</param>
            <param name="x">Tensor descriptor and pointers in device memory for the bottom layer's
            data and means. (Bottom layer is the earlier layer in the computation
            graph during inference). Note: the means tensor is expected to be
            precomputed by the user. It can also contain any valid values (not required
            to be actual means, and can be for instance a result of a convolution with
            a Gaussian kernel).</param>
            <param name="means">Tensor descriptor and pointers in device memory for the bottom layer's
            data and means. (Bottom layer is the earlier layer in the computation
            graph during inference). Note: the means tensor is expected to be
            precomputed by the user. It can also contain any valid values (not required
            to be actual means, and can be for instance a result of a convolution with
            a Gaussian kernel).</param>
            <param name="dy">Tensor pointer in device memory for the top layer's cumulative loss
            differential data (error backpropagation). (Top layer is the later layer in
            the computation graph during inference).</param>
            <param name="temp">Temporary tensors in device memory. These are used for computing
            intermediate values during the backward pass. These tensors do not have
            to be preserved from forward to backward pass. Both use srcDesc as a
            descriptor.</param>
            <param name="temp2">Temporary tensors in device memory. These are used for computing
            intermediate values during the backward pass. These tensors do not have
            to be preserved from forward to backward pass. Both use srcDesc as a
            descriptor.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="dXdMeansDesc">Tensor descriptor for destDataDiff and destMeansDiff.</param>
            <param name="dx">Tensor pointers (in device memory) for the bottom layer's resulting
            differentials (data and means). Both share the same descriptor.</param>
            <param name="dMeans">Tensor pointers (in device memory) for the bottom layer's resulting
            differentials (data and means). Both share the same descriptor.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnDivisiveNormalizationBackward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnLRNDescriptor,ManagedCuda.CudaDNN.cudnnDivNormMode,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function performs the backward DivisiveNormalization layer computation.
            </summary>
            <param name="handle">Handle to a previously created cuDNN library descriptor.</param>
            <param name="normDesc">Handle to a previously intialized LRN parameter descriptor (this descriptor
            is used for both LRN and DivisiveNormalization layers).</param>
            <param name="mode">DivisiveNormalization layer mode of operation. Currently only
            CUDNN_DIVNORM_PRECOMPUTED_MEANS is implemented. Normalization
            is performed using the means input tensor that is expected to be
            precomputed by the user.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="xDesc">Tensor descriptor and pointers in device memory for the bottom layer's
            data and means. (Bottom layer is the earlier layer in the computation
            graph during inference). Note: the means tensor is expected to be
            precomputed by the user. It can also contain any valid values (not required
            to be actual means, and can be for instance a result of a convolution with
            a Gaussian kernel).</param>
            <param name="x">Tensor descriptor and pointers in device memory for the bottom layer's
            data and means. (Bottom layer is the earlier layer in the computation
            graph during inference). Note: the means tensor is expected to be
            precomputed by the user. It can also contain any valid values (not required
            to be actual means, and can be for instance a result of a convolution with
            a Gaussian kernel).</param>
            <param name="means">Tensor descriptor and pointers in device memory for the bottom layer's
            data and means. (Bottom layer is the earlier layer in the computation
            graph during inference). Note: the means tensor is expected to be
            precomputed by the user. It can also contain any valid values (not required
            to be actual means, and can be for instance a result of a convolution with
            a Gaussian kernel).</param>
            <param name="dy">Tensor pointer in device memory for the top layer's cumulative loss
            differential data (error backpropagation). (Top layer is the later layer in
            the computation graph during inference).</param>
            <param name="temp">Temporary tensors in device memory. These are used for computing
            intermediate values during the backward pass. These tensors do not have
            to be preserved from forward to backward pass. Both use srcDesc as a
            descriptor.</param>
            <param name="temp2">Temporary tensors in device memory. These are used for computing
            intermediate values during the backward pass. These tensors do not have
            to be preserved from forward to backward pass. Both use srcDesc as a
            descriptor.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="dXdMeansDesc">Tensor descriptor for destDataDiff and destMeansDiff.</param>
            <param name="dx">Tensor pointers (in device memory) for the bottom layer's resulting
            differentials (data and means). Both share the same descriptor.</param>
            <param name="dMeans">Tensor pointers (in device memory) for the bottom layer's resulting
            differentials (data and means). Both share the same descriptor.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnDeriveBNTensorDescriptor(ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnBatchNormMode)">
            <summary>
            Derives a tensor descriptor from layer data descriptor for BatchNormalization 
            scale, invVariance, bnBias, bnScale tensors. Use this tensor desc for 
            bnScaleBiasMeanVarDesc and bnScaleBiasDiffDesc in Batch Normalization forward and backward functions.
            </summary>
            <param name="derivedBnDesc"></param>
            <param name="xDesc"></param>
            <param name="mode"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnBatchNormalizationForwardTraining(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnBatchNormMode,System.Single@,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,System.Double,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,System.Double,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            Computes y = BN(x). Also accumulates moving averages of mean and inverse variances
            </summary>
            <param name="handle"></param>
            <param name="mode"></param>
            <param name="alpha"></param>
            <param name="beta"></param>
            <param name="xDesc"></param>
            <param name="x"></param>
            <param name="yDesc"></param>
            <param name="y"></param>
            <param name="bnScaleBiasMeanVarDesc"></param>
            <param name="bnScale"></param>
            <param name="bnBias"></param>
            <param name="exponentialAverageFactor"></param>
            <param name="resultRunningMean"></param>
            <param name="resultRunningVariance"></param>
            <param name="epsilon"></param>
            <param name="resultSaveMean"></param>
            <param name="resultSaveVariance"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnBatchNormalizationForwardTraining(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnBatchNormMode,System.Double@,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,System.Double,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,System.Double,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            
            </summary>
            <param name="handle"></param>
            <param name="mode"></param>
            <param name="alpha"></param>
            <param name="beta"></param>
            <param name="xDesc"></param>
            <param name="x"></param>
            <param name="yDesc"></param>
            <param name="y"></param>
            <param name="bnScaleBiasMeanVarDesc"></param>
            <param name="bnScale"></param>
            <param name="bnBias"></param>
            <param name="exponentialAverageFactor"></param>
            <param name="resultRunningMean"></param>
            <param name="resultRunningVariance"></param>
            <param name="epsilon"></param>
            <param name="resultSaveMean"></param>
            <param name="resultSaveVariance"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnBatchNormalizationForwardInference(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnBatchNormMode,System.Single@,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,System.Double)">
            <summary>
            Performs Batch Normalization during Inference: 
            y[i] = bnScale[k]*(x[i]-estimatedMean[k])*estimatedInvVariance[k] + bnBias[k]
            with bnScale, bnBias, runningMean, runningInvVariance tensors indexed
            according to spatial or per-activation mode. Refer to cudnnBatchNormalizationForwardTraining
            above for notes on function arguments.
            </summary>
            <param name="handle"></param>
            <param name="mode"></param>
            <param name="alpha"></param>
            <param name="beta"></param>
            <param name="xDesc"></param>
            <param name="x"></param>
            <param name="yDesc"></param>
            <param name="y"></param>
            <param name="bnScaleBiasMeanVarDesc"></param>
            <param name="bnScale"></param>
            <param name="bnBias"></param>
            <param name="estimatedMean"></param>
            <param name="estimatedVariance"></param>
            <param name="epsilon"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnBatchNormalizationForwardInference(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnBatchNormMode,System.Double@,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,System.Double)">
            <summary>
            
            </summary>
            <param name="handle"></param>
            <param name="mode"></param>
            <param name="alpha"></param>
            <param name="beta"></param>
            <param name="xDesc"></param>
            <param name="x"></param>
            <param name="yDesc"></param>
            <param name="y"></param>
            <param name="bnScaleBiasMeanVarDesc"></param>
            <param name="bnScale"></param>
            <param name="bnBias"></param>
            <param name="estimatedMean"></param>
            <param name="estimatedVariance"></param>
            <param name="epsilon"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnBatchNormalizationBackward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnBatchNormMode,System.Single@,System.Single@,System.Single@,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,System.Double,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            Performs backward pass of Batch Normalization layer. Returns x gradient, bnScale gradient and bnBias gradient
            </summary>
            <param name="handle"></param>
            <param name="mode"></param>
            <param name="alphaDataDiff"></param>
            <param name="betaDataDiff"></param>
            <param name="alphaParamDiff"></param>
            <param name="betaParamDiff"></param>
            <param name="xDesc"></param>
            <param name="x"></param>
            <param name="dyDesc"></param>
            <param name="dy"></param>
            <param name="dxDesc"></param>
            <param name="dx"></param>
            <param name="dBnScaleBiasDesc"></param>
            <param name="bnScale"></param>
            <param name="dBnScaleResult"></param>
            <param name="dBnBiasResult"></param>
            <param name="epsilon"></param>
            <param name="savedMean"></param>
            <param name="savedInvVariance"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnBatchNormalizationBackward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnBatchNormMode,System.Double@,System.Double@,System.Double@,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,System.Double,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            
            </summary>
            <param name="handle"></param>
            <param name="mode"></param>
            <param name="alphaDataDiff"></param>
            <param name="betaDataDiff"></param>
            <param name="alphaParamDiff"></param>
            <param name="betaParamDiff"></param>
            <param name="xDesc"></param>
            <param name="x"></param>
            <param name="dyDesc"></param>
            <param name="dy"></param>
            <param name="dxDesc"></param>
            <param name="dx"></param>
            <param name="dBnScaleBiasDesc"></param>
            <param name="bnScale"></param>
            <param name="dBnScaleResult"></param>
            <param name="dBnBiasResult"></param>
            <param name="epsilon"></param>
            <param name="savedMean"></param>
            <param name="savedInvVariance"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnCreateSpatialTransformerDescriptor(ManagedCuda.CudaDNN.cudnnSpatialTransformerDescriptor@)">
            <summary>
            This function creates a generic spatial transformer descriptor object by allocating the memory needed to hold its opaque structure. 
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetSpatialTransformerNdDescriptor(ManagedCuda.CudaDNN.cudnnSpatialTransformerDescriptor,ManagedCuda.CudaDNN.cudnnSamplerType,ManagedCuda.CudaDNN.cudnnDataType,System.Int32,System.Int32[])">
            <summary>
            This function destroys a previously created spatial transformer descriptor object. 
            </summary>
            <param name="stDesc">Previously created spatial transformer descriptor object.</param>
            <param name="samplerType">Enumerant to specify the sampler type.</param>
            <param name="dataType">Data type.</param>
            <param name="nbDims">Dimension of the transformed tensor.</param>
            <param name="dimA">Array of dimension nbDims containing the size of the transformed tensor for every dimension.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnDestroySpatialTransformerDescriptor(ManagedCuda.CudaDNN.cudnnSpatialTransformerDescriptor)">
            <summary>
            This function destroys a previously created spatial transformer descriptor object. 
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSpatialTfGridGeneratorForward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnSpatialTransformerDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function generates a grid of coordinates in the input tensor corresponding to each pixel from the output tensor.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="stDesc">Previously created spatial transformer descriptor object.</param>
            <param name="theta">Affine transformation matrix. It should be of size n*2*3 for a 2d transformation, where n is the number of images specified in stDesc.</param>
            <param name="grid">A grid of coordinates. It is of size n*h*w*2 for a 2d transformation, where n, h, w is specified in stDesc. In the 4th dimension, the first coordinate is x, and the second coordinate is y.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSpatialTfGridGeneratorBackward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnSpatialTransformerDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function computes the gradient of a grid generation operation.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="stDesc">Previously created spatial transformer descriptor object.</param>
            <param name="dgrid">Data pointer to GPU memory contains the input differential data.</param>
            <param name="dtheta">Data pointer to GPU memory contains the output differential data.</param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSpatialTfSamplerForward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnSpatialTransformerDescriptor,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function performs a sampler operation and generates the output tensor using the grid given by the grid generator.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="stDesc">Previously created spatial transformer descriptor object.</param>
            <param name="alpha">Pointer to scaling factor (in host memory) used to blend the source value with prior value in the destination tensor as follows: dstValue = alpha[0]*srcValue + beta[0]*priorDstValue.</param>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor xDesc.</param>
            <param name="grid">A grid of coordinates generated by cudnnSpatialTfGridGeneratorForward.</param>
            <param name="beta">Pointer to scaling factor (in host memory) used to blend the source value with prior value in the destination tensor as follows: dstValue = alpha[0]*srcValue + beta[0]*priorDstValue.</param>
            <param name="yDesc">Handle to the previously initialized output tensor descriptor.</param>
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor yDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSpatialTfSamplerForward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnSpatialTransformerDescriptor,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            
            </summary>
            <param name="handle"></param>
            <param name="stDesc"></param>
            <param name="alpha"></param>
            <param name="xDesc"></param>
            <param name="x"></param>
            <param name="grid"></param>
            <param name="beta"></param>
            <param name="yDesc"></param>
            <param name="y"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSpatialTfSamplerBackward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnSpatialTransformerDescriptor,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function computes the gradient of a sampling operation.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="stDesc">Previously created spatial transformer descriptor object.</param>
            <param name="alpha">Pointer to scaling factor (in host memory) used to blend the source value with prior value in the destination tensor as follows: dstValue = alpha[0]*srcValue + beta[0]*priorDstValue.</param>
            <param name="xDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptor xDesc.</param>
            <param name="beta">Pointer to scaling factor (in host memory) used to blend the source value with prior value in the destination tensor as follows: dstValue = alpha[0]*srcValue + beta[0]*priorDstValue.</param>
            <param name="dxDesc">Handle to the previously initialized output differential tensor descriptor.</param>
            <param name="dx">Data pointer to GPU memory associated with the output tensor descriptor dxDesc.</param>
            <param name="alphaDgrid">Pointer to scaling factor (in host memory) used to blend the gradient outputs dgrid with prior value in the destination pointer as follows: dstValue = alpha[0]*srcValue + beta[0]*priorDstValue.</param>
            <param name="dyDesc">Handle to the previously initialized input differential tensor descriptor.</param>
            <param name="dy">Data pointer to GPU memory associated with the tensor descriptor dyDesc.</param>
            <param name="grid">A grid of coordinates generated by cudnnSpatialTfGridGeneratorForward.</param>
            <param name="betaDgrid">Pointer to scaling factor (in host memory) used to blend the gradient outputs dgrid with prior value in the destination pointer as follows: dstValue = alpha[0]*srcValue + beta[0]*priorDstValue.</param>
            <param name="dgrid">Data pointer to GPU memory contains the output differential data.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSpatialTfSamplerBackward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnSpatialTransformerDescriptor,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            
            </summary>
            <param name="handle"></param>
            <param name="stDesc"></param>
            <param name="alpha"></param>
            <param name="xDesc"></param>
            <param name="x"></param>
            <param name="beta"></param>
            <param name="dxDesc"></param>
            <param name="dx"></param>
            <param name="alphaDgrid"></param>
            <param name="dyDesc"></param>
            <param name="dy"></param>
            <param name="grid"></param>
            <param name="betaDgrid"></param>
            <param name="dgrid"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnCreateDropoutDescriptor(ManagedCuda.CudaDNN.cudnnDropoutDescriptor@)">
            <summary>
            This function creates a generic dropout descriptor object by allocating the memory needed to hold its opaque structure. 
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnDestroyDropoutDescriptor(ManagedCuda.CudaDNN.cudnnDropoutDescriptor)">
            <summary>
            This function destroys a previously created dropout descriptor object. 
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnDropoutGetStatesSize(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.BasicTypes.SizeT@)">
            <summary>
            This function is used to query the amount of space required to store the states of the random number generators used by cudnnDropoutForward function.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnDropoutGetReserveSpaceSize(ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.SizeT@)">
            <summary>
            This function is used to query the amount of reserve needed to run dropout with the input dimensions given by xDesc. 
            The same reserve space is expected to be passed to cudnnDropoutForward and cudnnDropoutBackward, and its contents is 
            expected to remain unchanged between cudnnDropoutForward and cudnnDropoutBackward calls. 
            </summary>
            <param name="xdesc">Handle to a previously initialized tensor descriptor, describing input to a dropout operation.</param>
            <param name="sizeInBytes">Amount of GPU memory needed as reserve space to be able to run dropout with an input tensor descriptor specified by xDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetDropoutDescriptor(ManagedCuda.CudaDNN.cudnnDropoutDescriptor,ManagedCuda.CudaDNN.cudnnHandle,System.Single,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT,System.UInt64)">
            <summary>
            This function initializes a previously created dropout descriptor object. If states argument is equal to 
            NULL, random number generator states won't be initialized, and only dropout value will be set. No other 
            function should be writing to the memory
            </summary>
            <param name="dropoutDesc">Previously created dropout descriptor object.</param>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="dropout">The probability with which the value from input would be propagated through the dropout layer.</param>
            <param name="states">Pointer to user-allocated GPU memory that will hold random number generator states.</param>
            <param name="stateSizeInBytes">Specifies size in bytes of the provided memory for the states.</param>
            <param name="seed">Seed used to initialize random number generator states.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnRestoreDropoutDescriptor(ManagedCuda.CudaDNN.cudnnDropoutDescriptor,ManagedCuda.CudaDNN.cudnnHandle,System.Single,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT,System.UInt64)">
            <summary>
            Restores the dropout descriptor to a previously saved-off state
            </summary>
            <param name="dropoutDesc"></param>
            <param name="handle"></param>
            <param name="dropout"></param>
            <param name="states"></param>
            <param name="stateSizeInBytes"></param>
            <param name="seed"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetDropoutDescriptor(ManagedCuda.CudaDNN.cudnnDropoutDescriptor,ManagedCuda.CudaDNN.cudnnHandle,System.Single@,ManagedCuda.BasicTypes.CUdeviceptr@,System.UInt64@)">
            <summary>
            
            </summary>
            <param name="dropoutDesc"></param>
            <param name="handle"></param>
            <param name="dropout"></param>
            <param name="states"></param>
            <param name="seed"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnDropoutForward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnDropoutDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT)">
            <summary>
            This function performs forward dropout operation over x returning results in y. If dropout was 
            used as a parameter to cudnnSetDropoutDescriptor, the approximately dropout fraction of x values 
            will be replaces by 0, and the rest will be scaled by 1/(1-dropout) This function should not be 
            running concurrently with another cudnnDropoutForward function using the same states.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="dropoutDesc">Previously created dropout descriptor object.</param>
            <param name="xdesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="x">Pointer to data of the tensor described by the xDesc descriptor.</param>
            <param name="ydesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="y">Pointer to data of the tensor described by the yDesc descriptor.</param>
            <param name="reserveSpace">Pointer to user-allocated GPU memory used by this function. It is expected that contents of reserveSpace doe not change between cudnnDropoutForward and cudnnDropoutBackward calls.</param>
            <param name="reserveSpaceSizeInBytes">Specifies size in bytes of the provided memory for the reserve space.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnDropoutBackward(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnDropoutDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT)">
            <summary>
            This function performs backward dropout operation over dy returning results in dx. If during 
            forward dropout operation value from x was propagated to y then during backward operation value 
            from dy will be propagated to dx, otherwise, dx value will be set to 0.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="dropoutDesc">Previously created dropout descriptor object.</param>
            <param name="dydesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="dy">Pointer to data of the tensor described by the dyDesc descriptor.</param>
            <param name="dxdesc">Handle to a previously initialized tensor descriptor.</param>
            <param name="dx">Pointer to data of the tensor described by the dxDesc descriptor.</param>
            <param name="reserveSpace">Pointer to user-allocated GPU memory used by this function. It is expected that reserveSpace was populated during a call to cudnnDropoutForward and has not been changed.</param>
            <param name="reserveSpaceSizeInBytes">Specifies size in bytes of the provided memory for the reserve space.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnCreateRNNDescriptor(ManagedCuda.CudaDNN.cudnnRNNDescriptor@)">
            <summary>
            This function creates a generic RNN descriptor object by allocating the memory 
            needed to hold its opaque structure.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnDestroyRNNDescriptor(ManagedCuda.CudaDNN.cudnnRNNDescriptor)">
            <summary>
            This function destroys a previously created RNN descriptor object.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetRNNForwardInferenceAlgorithmMaxCount(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnRNNDescriptor,System.Int32@)">
            <summary>
            
            </summary>
            <param name="handle"></param>
            <param name="rnnDesc"></param>
            <param name="count"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnFindRNNForwardInferenceAlgorithmEx(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnRNNDescriptor,System.Int32,ManagedCuda.CudaDNN.cudnnTensorDescriptor[],ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor[],ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Single,System.Int32,System.Int32@,ManagedCuda.CudaDNN.cudnnAlgorithmPerformance[],ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT)">
            <summary>
            This function attempts all available cuDNN algorithms for cudnnRNNForwardInference, using user-allocated GPU memory, and outputs performance metrics to a user-allocated array of cudnnAlgorithmPerformance_t. These metrics are written in sorted fashion where the first element has the lowest compute time. 
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetRNNForwardTrainingAlgorithmMaxCount(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnRNNDescriptor,System.Int32@)">
            <summary>
            
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnFindRNNForwardTrainingAlgorithmEx(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnRNNDescriptor,System.Int32,ManagedCuda.CudaDNN.cudnnTensorDescriptor[],ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor[],ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Single,System.Int32,System.Int32@,ManagedCuda.CudaDNN.cudnnAlgorithmPerformance[],ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT)">
            <summary>
            This function attempts all available cuDNN algorithms for cudnnRNNForwardTraining, using user-allocated GPU memory, and outputs performance metrics to a user-allocated array of cudnnAlgorithmPerformance_t. These metrics are written in sorted fashion where the first element has the lowest compute time. 
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetRNNBackwardDataAlgorithmMaxCount(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnRNNDescriptor,System.Int32@)">
            <summary>
            
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnFindRNNBackwardDataAlgorithmEx(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnRNNDescriptor,System.Int32,ManagedCuda.CudaDNN.cudnnTensorDescriptor[],ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor[],ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor[],ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Single,System.Int32,System.Int32@,ManagedCuda.CudaDNN.cudnnAlgorithmPerformance[],ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT)">
            <summary>
            
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetRNNBackwardWeightsAlgorithmMaxCount(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnRNNDescriptor,System.Int32@)">
            <summary>
            
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnFindRNNBackwardWeightsAlgorithmEx(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnRNNDescriptor,System.Int32,ManagedCuda.CudaDNN.cudnnTensorDescriptor[],ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor[],ManagedCuda.BasicTypes.CUdeviceptr,System.Single,System.Int32,System.Int32@,ManagedCuda.CudaDNN.cudnnAlgorithmPerformance[],ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT)">
            <summary>
            
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnCreatePersistentRNNPlan(ManagedCuda.CudaDNN.cudnnRNNDescriptor,System.Int32,ManagedCuda.CudaDNN.cudnnDataType,ManagedCuda.CudaDNN.cudnnPersistentRNNPlan@)">
            <summary>
            This function creates a plan to execute persistent RNNs when using the
            CUDNN_RNN_ALGO_PERSIST_DYNAMIC algo.This plan is tailored to the current GPU
            and problem hyperparemeters. This function call is expected to be expensive in terms of
            runtime, and should be used infrequently.
            </summary>
            <param name="rnnDesc"></param>
            <param name="minibatch"></param>
            <param name="dataType"></param>
            <param name="plan"></param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetPersistentRNNPlan(ManagedCuda.CudaDNN.cudnnRNNDescriptor,ManagedCuda.CudaDNN.cudnnPersistentRNNPlan)">
            <summary>
            This function sets the persistent RNN plan to be executed when using rnnDesc and
            CUDNN_RNN_ALGO_PERSIST_DYNAMIC algo.
            </summary>
            <param name="rnnDesc"></param>
            <param name="plan"></param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnDestroyPersistentRNNPlan(ManagedCuda.CudaDNN.cudnnPersistentRNNPlan)">
            <summary>
            This function destroys a previously created persistent RNN plan object.
            </summary>
            <param name="plan"></param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetRNNDescriptor(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnRNNDescriptor,System.Int32,System.Int32,ManagedCuda.CudaDNN.cudnnDropoutDescriptor,ManagedCuda.CudaDNN.cudnnRNNInputMode,ManagedCuda.CudaDNN.cudnnDirectionMode,ManagedCuda.CudaDNN.cudnnRNNMode,ManagedCuda.CudaDNN.cudnnRNNAlgo,ManagedCuda.CudaDNN.cudnnDataType)">
            <summary>
            This function initializes a previously created RNN descriptor object.
            </summary>
            <param name="handle">Handle to a previously created cuDNN library descriptor.</param>
            <param name="rnnDesc">A previously created RNN descriptor.</param>
            <param name="hiddenSize">Size of the internal hidden state for each layer.</param>
            <param name="numLayers">Number of stacked layers.</param>
            <param name="dropoutDesc">Handle to a previously created and initialized dropout descriptor.
            Dropout will be applied between layers(eg.a single layer network will have no dropout applied).</param>
            <param name="inputMode">Specifies the behavior at the input to the first layer</param>
            <param name="direction">Specifies the recurrence pattern. (eg. bidirectional)</param>
            <param name="mode">Specifies the type of RNN to compute.</param>
            <param name="algo">Specifies which RNN algorithm should be used to compute the results.</param>
            <param name="dataType">Compute precision.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetRNNProjectionLayers(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnRNNDescriptor,System.Int32,System.Int32)">
            <summary>
            The cudnnSetRNNProjectionLayers() function should be called after cudnnSetRNNDescriptor() to enable the "recurrent" and/or "output" projection in a recursive neural network
            </summary>
            <param name="handle"> Handle to a previously created cuDNN library descriptor</param>
            <param name="rnnDesc"> A previously created and initialized RNN descriptor. </param>
            <param name="recProjSize">The size of the LSTM cell output after the recurrent projection. This value should not be larger than hiddenSize programmed via cudnnSetRNNDescriptor().</param>
            <param name="outProjSize"> This parameter should be zero. </param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetRNNProjectionLayers(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnRNNDescriptor,System.Int32@,System.Int32@)">
            <summary>
            This function retrieves the current RNN projection parameters. By default the projection feature is disabled so invoking this function immediately after cudnnSetRNNDescriptor() will yield recProjSize equal to hiddenSize and outProjSize set to zero. The cudnnSetRNNProjectionLayers() method enables the RNN projection. 
            </summary>
            <param name="handle"></param>
            <param name="rnnDesc"></param>
            <param name="recProjSize"></param>
            <param name="outProjSize"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetRNNAlgorithmDescriptor(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnRNNDescriptor,ManagedCuda.CudaDNN.cudnnAlgorithmDescriptor)">
            <summary>
            
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetRNNDescriptor(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnRNNDescriptor,System.Int32@,System.Int32@,ManagedCuda.CudaDNN.cudnnDropoutDescriptor@,ManagedCuda.CudaDNN.cudnnRNNInputMode@,ManagedCuda.CudaDNN.cudnnDirectionMode@,ManagedCuda.CudaDNN.cudnnRNNMode@,ManagedCuda.CudaDNN.cudnnRNNAlgo@,ManagedCuda.CudaDNN.cudnnDataType@)">
            <summary>
            
            </summary>
            <param name="cudnnHandle"></param>
            <param name="rnnDesc"></param>
            <param name="hiddenSize"></param>
            <param name="numLayers"></param>
            <param name="dropoutDesc"></param>
            <param name="inputMode"></param>
            <param name="direction"></param>
            <param name="mode"></param>
            <param name="algo"></param>
            <param name="dataType"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetRNNMatrixMathType(ManagedCuda.CudaDNN.cudnnRNNDescriptor,ManagedCuda.CudaDNN.cudnnMathType)">
            <summary>
            
            </summary>
            <param name="desc"></param>
            <param name="math"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetRNNMatrixMathType(ManagedCuda.CudaDNN.cudnnRNNDescriptor,ManagedCuda.CudaDNN.cudnnMathType@)">
            <summary>
            
            </summary>
            <param name="rnnDesc"></param>
            <param name="mType"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetRNNWorkspaceSize(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnRNNDescriptor,System.Int32,ManagedCuda.CudaDNN.cudnnTensorDescriptor[],ManagedCuda.BasicTypes.SizeT@)">
            <summary>
            This function is used to query the amount of work space required to execute the RNN 
            described by rnnDesc with inputs dimensions defined by xDesc. 
            </summary>
            <param name="handle">Handle to a previously created cuDNN library descriptor.</param>
            <param name="rnnDesc">A previously initialized RNN descriptor.</param>
            <param name="seqLength">Number of iterations to unroll over.</param>
            <param name="xDesc">An array of tensor descriptors describing the input to each recurrent iteration.</param>
            <param name="sizeInBytes">Minimum amount of GPU memory needed as workspace to be able to execute an RNN with the specified descriptor and input tensors.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetRNNTrainingReserveSize(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnRNNDescriptor,System.Int32,ManagedCuda.CudaDNN.cudnnTensorDescriptor[],ManagedCuda.BasicTypes.SizeT@)">
            <summary>
            This function is used to query the amount of reserved space required for training the 
            RNN described by rnnDesc with inputs dimensions defined by xDesc. The same reserve 
            space must be passed to cudnnRNNForwardTraining, cudnnRNNBackwardData and cudnnRNNBackwardWeights.
            </summary>
            <param name="handle">Handle to a previously created cuDNN library descriptor.</param>
            <param name="rnnDesc">A previously initialized RNN descriptor.</param>
            <param name="seqLength">Number of iterations to unroll over.</param>
            <param name="xDesc">An array of tensor descriptors describing the input to each recurrent iteration.</param>
            <param name="sizeInBytes">Minimum amount of GPU memory needed as reserve space to be able to train an RNN with the specified descriptor and input tensors.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetRNNParamsSize(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnRNNDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.SizeT@,ManagedCuda.CudaDNN.cudnnDataType)">
            <summary>
            This function is used to query the amount of parameter space required to execute the RNN described by 
            rnnDesc with inputs dimensions defined by xDesc. 
            </summary>
            <param name="handle">Handle to a previously created cuDNN library descriptor.</param>
            <param name="rnnDesc">A previously initialized RNN descriptor.</param>
            <param name="xDesc">A fully packed tensor descriptor describing the input to one recurrent iteration.</param>
            <param name="sizeInBytes">Minimum amount of GPU memory needed as parameter space to be able to execute an RNN with the specified descriptor and input tensors.</param>
            <param name="dataType">The data type of the parameters.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetRNNLinLayerMatrixParams(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnRNNDescriptor,System.Int32,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Int32,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function is used to obtain a pointer and descriptor for the matrix parameters in layer within 
            the RNN described by rnnDesc with inputs dimensions defined by xDesc. 
            </summary>
            <param name="handle">Handle to a previously created cuDNN library descriptor.</param>
            <param name="rnnDesc">A previously initialized RNN descriptor.</param>
            <param name="layer">The layer to query.</param>
            <param name="xDesc">A fully packed tensor descriptor describing the input to one recurrent iteration.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor describing the weights for the RNN.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor wDesc.</param>
            <param name="linLayerID">
            The linear layer to obtain information about: 
            * If mode in rnnDesc was set to CUDNN_RNN_RELU or CUDNN_RNN_TANH a value of 0 references the matrix multiplication 
            applied to the input from the previous layer, a value of 1 references the matrix multiplication applied to the recurrent input.
            * If mode in rnnDesc was set to CUDNN_LSTM values of 0-3 reference matrix multiplications applied to the input from the 
            previous layer, value of 4-7 reference matrix multiplications applied to the recurrent input.
                 Values 0 and 4 reference the input gate. 
                 Values 1 and 5 reference the forget gate. 
                 Values 2 and 6 reference the new memory gate. 
                 Values 3 and 7 reference the output gate.
            * If mode in rnnDesc was set to CUDNN_GRU values of 0-2 reference matrix multiplications applied to the input 
            from the previous layer, value of 3-5 reference matrix multiplications applied to the recurrent input. 
                 Values 0 and 3 reference the reset gate. 
                 Values 1 and 4 reference the update gate. 
                 Values 2 and 5 reference the new memory gate.
            </param>
            <param name="linLayerMatDesc">Handle to a previously created filter descriptor.</param>
            <param name="linLayerMat">Data pointer to GPU memory associated with the filter descriptor linLayerMatDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetRNNLinLayerBiasParams(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnRNNDescriptor,System.Int32,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Int32,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function is used to obtain a pointer and descriptor for the bias parameters 
            in layer within the RNN described by rnnDesc with inputs dimensions defined by xDesc. 
            </summary>
            <param name="handle">Handle to a previously created cuDNN library descriptor.</param>
            <param name="rnnDesc">A previously initialized RNN descriptor.</param>
            <param name="layer">The layer to query.</param>
            <param name="xDesc">A fully packed tensor descriptor describing the input to one recurrent iteration.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor describing the weights for the RNN.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor wDesc.</param>
            <param name="linLayerID">
            The linear layer to obtain information about: 
            * If mode in rnnDesc was set to CUDNN_RNN_RELU or CUDNN_RNN_TANH a value of 0 references 
            the bias applied to the input from the previous layer, a value of 1 references the bias 
            applied to the recurrent input.
            * If mode in rnnDesc was set to CUDNN_LSTM values of 0, 1, 2 and 3 reference bias applied to the input 
            from the previous layer, value of 4, 5, 6 and 7 reference bias applied to the recurrent input.
                 Values 0 and 4 reference the input gate. 
                 Values 1 and 5 reference the forget gate. 
                 Values 2 and 6 reference the new memory gate. 
                 Values 3 and 7 reference the output gate.
            * If mode in rnnDesc was set to CUDNN_GRU values of 0, 1 and 2 reference bias applied to the 
            input from the previous layer, value of 3, 4 and 5 reference bias applied to the recurrent input.
                 Values 0 and 3 reference the reset gate. 
                 Values 1 and 4 reference the update gate. 
                 Values 2 and 5 reference the new memory gate.</param>
            <param name="linLayerBiasDesc">Handle to a previously created filter descriptor.</param>
            <param name="linLayerBias">Data pointer to GPU memory associated with the filter descriptor linLayerMatDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnRNNForwardInference(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnRNNDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor[],ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor[],ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT)">
            <summary>
            This routine executes the recurrent neural network described by rnnDesc with inputs x, hx, cx, weights w and 
            outputs y, hy, cy. workspace is required for intermediate storage. This function does not store data required 
            for training; cudnnRNNForwardTraining should be used for that purpose. 
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="rnnDesc">A previously initialized RNN descriptor.</param>
            <param name="xDesc">An array of tensor descriptors describing the input to each recurrent iteration. 
            Each tensor descriptor must have the same first dimension. The second dimension of the tensors may 
            decrease from element n to element n+1 but may not increase. The tensor must be fully packed.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptors in the array xDesc. 
            The data are expected to be packed contiguously with the first element of iteration n+1 following 
            directly from the last element of iteration n.</param>
            <param name="hxDesc">Handle to a previously initialized tensor descriptor describing the initial hidden 
            state of the RNN. The first dimension of the tensor must match the hiddenSize argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second 
            dimension of the first tensor described in xDesc. The third dimension must match the numLayers 
            argument passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be 
            fully packed.</param>
            <param name="hx">Data pointer to GPU memory associated with the tensor descriptor hxDesc. If a NULL pointer 
            is passed, the initial hidden state of the network will be initialized to zero.</param>
            <param name="cxDesc">A fully packed tensor descriptor describing the initial cell state for
            LSTM networks.The first dimension of the tensor depends on the
            direction argument passed to the cudnnSetRNNDescriptor call
            used to initialize rnnDesc:
             If direction is CUDNN_UNIDIRECTIONAL the first
              dimension should match the numLayers argument passed to
              cudnnSetRNNDescriptor.
             If direction is CUDNN_BIDIRECTIONAL the first dimension
              should match double the numLayers argument passed to
              cudnnSetRNNDescriptor.
            The second dimension must match the first dimension of the
            tensors described in xDesc.The third dimension must match the
            hiddenSize argument passed to the cudnnSetRNNDescriptor call
            used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="cx">Data pointer to GPU memory associated with the tensor descriptor
            cxDesc.If a NULL pointer is passed, the initial cell state of the network will be initialized to zero.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor describing the weights for the RNN.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor wDesc.</param>
            <param name="yDesc">A fully packed tensor descriptor describing the final cell state for
            LSTM networks.The first dimension of the tensor depends on the
            direction argument passed to the cudnnSetRNNDescriptor call
            used to initialize rnnDesc:
             If direction is CUDNN_UNIDIRECTIONAL the first
              dimension should match the numLayers argument passed to
              cudnnSetRNNDescriptor.
             If direction is CUDNN_BIDIRECTIONAL the first dimension
              should match double the numLayers argument passed to
              cudnnSetRNNDescriptor.
            The second dimension must match the first dimension of the
            tensors described in xDesc.The third dimension must match the
            hiddenSize argument passed to the cudnnSetRNNDescriptor call
            used to initialize rnnDesc.The tensor must be fully packed.</param>
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor yDesc. The data 
            are expected to be packed contiguously with the first element of iteration n+1 following directly 
            from the last element of iteration n.</param>
            <param name="hyDesc">Handle to a previously initialized tensor descriptor describing the final hidden 
            state of the RNN. The first dimension of the tensor must match the hiddenSize argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second 
            dimension of the first tensor described in xDesc. The third dimension must match the numLayers 
            argument passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be 
            fully packed.</param>
            <param name="hy">Data pointer to GPU memory associated with the tensor descriptor hyDesc. If a NULL 
            pointer is passed, the final hidden state of the network will not be saved.</param>
            <param name="cyDesc">Handle to a previously initialized tensor descriptor describing the final cell 
            state for LSTM networks. The first dimension of the tensor must match the hiddenSize argument passed 
            to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second 
            dimension of the first tensor described in xDesc. The third dimension must match the numLayers argument 
            passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="cy">Data pointer to GPU memory associated with the tensor descriptor cyDesc. If 
            a NULL pointer is passed, the final cell state of the network will be not be saved.</param>
            <param name="workspace">Data pointer to GPU memory to be used as a workspace for this call.</param>
            <param name="workSpaceSizeInBytes">Specifies the size in bytes of the provided workspace.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnRNNForwardTraining(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnRNNDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor[],ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor[],ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT)">
            <summary>
            This routine executes the recurrent neural network described by rnnDesc with inputs x, hx, cx, weights w 
            and outputs y, hy, cy. workspace is required for intermediate storage. reserveSpace stores data required 
            for training. The same reserveSpace data must be used for future calls to cudnnRNNBackwardData and 
            cudnnRNNBackwardWeights if these execute on the same input data. 
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="rnnDesc">A previously initialized RNN descriptor.</param>
            <param name="xDesc">An array of tensor descriptors describing the input to each recurrent iteration. Each 
            tensor descriptor must have the same first dimension. The second dimension of the tensors may decrease 
            from element n to element n+1 but may not increase. The tensor must be fully packed.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptors in the array xDesc.</param>
            <param name="hxDesc">Handle to a previously initialized tensor descriptor describing the initial hidden state 
            of the RNN. The first dimension of the tensor must match the hiddenSize argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second 
            dimension of the first tensor described in xDesc. The third dimension must match the numLayers argument 
            passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="hx">Data pointer to GPU memory associated with the tensor descriptor hxDesc. If a NULL pointer 
            is passed, the initial hidden state of the network will be initialized to zero.</param>
            <param name="cxDesc">Handle to a previously initialized tensor descriptor describing the initial 
            cell state for LSTM networks. The first dimension of the tensor must match the hiddenSize argument 
            passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match 
            the second dimension of the first tensor described in xDesc. The third dimension must match the numLayers 
            argument passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully 
            packed.</param>
            <param name="cx">Data pointer to GPU memory associated with the tensor descriptor cxDesc. If a NULL pointer is 
            passed, the initial cell state of the network will be initialized to zero.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor describing the weights for the RNN.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor wDesc.</param>
            <param name="yDesc">An array of tensor descriptors describing the output from each recurrent iteration. The first 
            dimension of the tensor depends on the direction argument passed to the cudnnSetRNNDescriptor 
            call used to initialize rnnDesc: 
            * If direction is CUDNN_UNIDIRECTIONAL the first dimension should match the hiddenSize 
            argument passed to cudnnSetRNNDescriptor.
            * If direction is CUDNN_BIDIRECTIONAL the first dimension should match double the hiddenSize 
            argument passed to cudnnSetRNNDescriptor.
            The second dimension of the tensor n must match the second dimension of the tensor 
            n in xDesc. The tensor must be fully packed.</param>
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor yDesc.</param>
            <param name="hyDesc">Handle to a previously initialized tensor descriptor describing the final 
            hidden state of the RNN. The first dimension of the tensor must match the hiddenSize argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second dimension 
            of the first tensor described in xDesc. The third dimension must match the numLayers argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="hy">Data pointer to GPU memory associated with the tensor descriptor hyDesc. If a 
            NULL pointer is passed, the final hidden state of the network will not be saved.</param>
            <param name="cyDesc">Handle to a previously initialized tensor descriptor describing the final cell state 
            for LSTM networks. The first dimension of the tensor must match the hiddenSize argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second dimension 
            of the first tensor described in xDesc. The third dimension must match the numLayers argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="cy">Data pointer to GPU memory associated with the tensor descriptor cyDesc. If a NULL pointer is 
            passed, the final cell state of the network will be not be saved.</param>
            <param name="workspace">Data pointer to GPU memory to be used as a workspace for this call.</param>
            <param name="workSpaceSizeInBytes">Specifies the size in bytes of the provided workspace.</param>
            <param name="reserveSpace">Data pointer to GPU memory to be used as a reserve space for this call.</param>
            <param name="reserveSpaceSizeInBytes">Specifies the size in bytes of the provided reserveSpace.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnRNNBackwardData(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnRNNDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor[],ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor[],ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor[],ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT)">
            <summary>
            This routine executes the recurrent neural network described by rnnDesc with 
            output gradients dy, dhy, dhc, weights w and input gradients dx, dhx, dcx. 
            workspace is required for intermediate storage. The data in reserveSpace must have 
            previously been generated by cudnnRNNForwardTraining. The same reserveSpace data must 
            be used for future calls to cudnnRNNBackwardWeights if they execute on the same input data. 
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="rnnDesc">A previously initialized RNN descriptor.</param>
            <param name="yDesc">An array of tensor descriptors describing the output from each 
            recurrent iteration. The first dimension of the tensor depends on the direction 
            argument passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc:
            * If direction is CUDNN_UNIDIRECTIONAL the first dimension should match the hiddenSize 
            argument passed to cudnnSetRNNDescriptor.
            * If direction is CUDNN_BIDIRECTIONAL the first dimension should match double the 
            hiddenSize argument passed to cudnnSetRNNDescriptor.
            The second dimension of the tensor n must match the second dimension of the tensor n in dyDesc. 
            The tensor must be fully packed.</param>
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor yDesc.</param>
            <param name="dyDesc">An array of tensor descriptors describing the gradient at the output from each 
            recurrent iteration. The first dimension of the tensor depends on the direction argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc: 
            * If direction is CUDNN_UNIDIRECTIONAL the first dimension should match the hiddenSize 
            argument passed to cudnnSetRNNDescriptor.
            * If direction is CUDNN_BIDIRECTIONAL the first dimension should match double the hiddenSize 
            argument passed to cudnnSetRNNDescriptor.
            The second dimension of the tensor n must match the second dimension of the tensor n in dxDesc. The 
            tensor must be fully packed.</param>
            <param name="dy">Data pointer to GPU memory associated with the tensor descriptors in the array dyDesc.</param>
            <param name="dhyDesc">Handle to a previously initialized tensor descriptor describing the gradients at the 
            final hidden state of the RNN. The first dimension of the tensor must match the hiddenSize argument passed 
            to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second 
            dimension of the first tensor described in dyDesc. The third dimension must match the numLayers argument 
            passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="dhy">Data pointer to GPU memory associated with the tensor descriptor dhyDesc. If a NULL pointer 
            is passed, the gradients at the final hidden state of the network will be initialized to zero.</param>
            <param name="dcyDesc">Handle to a previously initialized tensor descriptor describing the gradients at 
            the final cell state of the RNN. The first dimension of the tensor must match the hiddenSize argument 
            passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the 
            second dimension of the first tensor described in dyDesc. The third dimension must match the numLayers argument 
            passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="dcy">Data pointer to GPU memory associated with the tensor descriptor dcyDesc. If a NULL pointer 
            is passed, the gradients at the final cell state of the network will be initialized to zero.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor describing the weights for the RNN.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor wDesc.</param>
            <param name="hxDesc">Handle to a previously initialized tensor descriptor describing the initial hidden 
            state of the RNN. The first dimension of the tensor must match the hiddenSize argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second 
            dimension of the first tensor described in xDesc. The third dimension must match the numLayers 
            argument passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be 
            fully packed.</param>
            <param name="hx">Data pointer to GPU memory associated with the tensor descriptor hxDesc. If a NULL pointer is 
            passed, the initial hidden state of the network will be initialized to zero.</param>
            <param name="cxDesc">Handle to a previously initialized tensor descriptor describing the 
            initial cell state for LSTM networks. The first dimension of the tensor must match the 
            hiddenSize argument passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The 
            second dimension must match the second dimension of the first tensor described in xDesc. The 
            third dimension must match the numLayers argument passed to the cudnnSetRNNDescriptor call 
            used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="cx">Data pointer to GPU memory associated with the tensor descriptor cxDesc. 
            If a NULL pointer is passed, the initial cell state of the network will be initialized to zero.</param>
            <param name="dxDesc">An array of tensor descriptors describing the gradient at the input of each recurrent iteration. 
            Each tensor descriptor must have the same first dimension. The second dimension of the tensors may decrease from 
            element n to element n+1 but may not increase. The tensor must be fully packed.</param>
            <param name="dx">Data pointer to GPU memory associated with the tensor descriptors in the array dxDesc. </param>
            <param name="dhxDesc">Handle to a previously initialized tensor descriptor describing the gradient at the initial hidden 
            state of the RNN. The first dimension of the tensor must match the hiddenSize argument passed to the cudnnSetRNNDescriptor 
            call used to initialize rnnDesc. The second dimension must match the second dimension of the first tensor described in xDesc. 
            The third dimension must match the numLayers argument passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. 
            The tensor must be fully packed.</param>
            <param name="dhx">Data pointer to GPU memory associated with the tensor descriptor dhxDesc. If a NULL pointer is passed, the 
            gradient at the hidden input of the network will not be set.</param>
            <param name="dcxDesc">Handle to a previously initialized tensor descriptor describing the gradient 
            at the initial cell state of the RNN. The first dimension of the tensor must match the hiddenSize argument passed 
            to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second dimension 
            of the first tensor described in xDesc. The third dimension must match the numLayers argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="dcx">Data pointer to GPU memory associated with the tensor descriptor dcxDesc. If 
            a NULL pointer is passed, the gradient at the cell input of the network will not be set.</param>
            <param name="workspace">Data pointer to GPU memory to be used as a workspace for this call.</param>
            <param name="workSpaceSizeInBytes">Specifies the size in bytes of the provided workspace.</param>
            <param name="reserveSpace">Data pointer to GPU memory to be used as a reserve space for this call.</param>
            <param name="reserveSpaceSizeInBytes">Specifies the size in bytes of the provided reserveSpace.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnRNNBackwardWeights(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnRNNDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor[],ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor[],ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT,ManagedCuda.CudaDNN.cudnnFilterDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT)">
            <summary>
            This routine accumulates weight gradients dw from the recurrent neural network described 
            by rnnDesc with inputs x, hx, and outputs y. The mode of operation in this case is additive, 
            the weight gradients calculated will be added to those already existing in dw. workspace 
            is required for intermediate storage. The data in reserveSpace must have previously been 
            generated by cudnnRNNBackwardData.
            </summary>
            <param name="handle">Handle to a previously created cuDNN context.</param>
            <param name="rnnDesc">A previously initialized RNN descriptor.</param>
            <param name="xDesc">An array of tensor descriptors describing the input to each recurrent iteration. 
            Each tensor descriptor must have the same first dimension. The second dimension of the tensors may 
            decrease from element n to element n+1 but may not increase. The tensor must be fully packed.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptors in the array xDesc.</param>
            <param name="hxDesc">Handle to a previously initialized tensor descriptor describing the initial hidden 
            state of the RNN. The first dimension of the tensor must match the hiddenSize argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second dimension
            of the first tensor described in xDesc. The third dimension must match the numLayers argument passed to 
            the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully packed. </param>
            <param name="hx">Data pointer to GPU memory associated with the tensor descriptor hxDesc. If 
            a NULL pointer is passed, the initial hidden state of the network will be initialized to zero.</param>
            <param name="yDesc">An array of tensor descriptors describing the output from each 
            recurrent iteration. The first dimension of the tensor depends on the direction 
            argument passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc:
            * If direction is CUDNN_UNIDIRECTIONAL the first dimension should match the hiddenSize 
            argument passed to cudnnSetRNNDescriptor.
            * If direction is CUDNN_BIDIRECTIONAL the first dimension should match double the hiddenSize 
            argument passed to cudnnSetRNNDescriptor.
            The second dimension of the tensor n must match the second dimension of the tensor n in dyDesc. 
            The tensor must be fully packed.</param>
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor yDesc.</param>
            <param name="workspace">Data pointer to GPU memory to be used as a workspace for this call.</param>
            <param name="workSpaceSizeInBytes">Specifies the size in bytes of the provided workspace.</param>
            <param name="dwDesc">Handle to a previously initialized filter descriptor describing the gradients of the weights for the RNN.</param>
            <param name="dw">Data pointer to GPU memory associated with the filter descriptor dwDesc.</param>
            <param name="reserveSpace">Data pointer to GPU memory to be used as a reserve space for this call.</param>
            <param name="reserveSpaceSizeInBytes">Specifies the size in bytes of the provided reserveSpace.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnCreateCTCLossDescriptor(ManagedCuda.CudaDNN.cudnnCTCLossDescriptor@)">
            <summary>
            Create an instance of a CTC (Connectionist Temporal Classification) loss descriptor
            </summary>
            <param name="ctcLossDesc"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnSetCTCLossDescriptor(ManagedCuda.CudaDNN.cudnnCTCLossDescriptor,ManagedCuda.CudaDNN.cudnnDataType)">
            <summary>
            
            </summary>
            <param name="ctcLossDesc"></param>
            <param name="compType"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetCTCLossDescriptor(ManagedCuda.CudaDNN.cudnnCTCLossDescriptor,ManagedCuda.CudaDNN.cudnnDataType@)">
            <summary>
            
            </summary>
            <param name="ctcLossDesc"></param>
            <param name="compType"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnDestroyCTCLossDescriptor(ManagedCuda.CudaDNN.cudnnCTCLossDescriptor)">
            <summary>
            
            </summary>
            <param name="ctcLossDesc"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnCTCLoss(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Int32[],System.Int32[],System.Int32[],ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnCTCLossAlgo,ManagedCuda.CudaDNN.cudnnCTCLossDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.SizeT)">
            <summary>
            return the ctc costs and gradients, given the probabilities and labels
            </summary>
            <param name="handle"></param>
            <param name="probsDesc"></param>
            <param name="probs"></param>
            <param name="labels"></param>
            <param name="labelLengths"></param>
            <param name="inputLengths"></param>
            <param name="costs"></param>
            <param name="gradientsDesc"></param>
            <param name="gradients"></param>
            <param name="algo"></param>
            <param name="ctcLossDesc"></param>
            <param name="workspace"></param>
            <param name="workSpaceSizeInBytes"></param>
            <returns></returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.CudaDNNNativeMethods.cudnnGetCTCLossWorkspaceSize(ManagedCuda.CudaDNN.cudnnHandle,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnTensorDescriptor,System.Int32[],System.Int32[],System.Int32[],ManagedCuda.CudaDNN.cudnnCTCLossAlgo,ManagedCuda.CudaDNN.cudnnCTCLossDescriptor,ManagedCuda.BasicTypes.SizeT@)">
            <summary>
            return the workspace size needed for ctc
            </summary>
            <param name="handle"></param>
            <param name="probsDesc"></param>
            <param name="gradientsDesc"></param>
            <param name="labels"></param>
            <param name="labelLengths"></param>
            <param name="inputLengths"></param>
            <param name="algo"></param>
            <param name="ctcLossDesc"></param>
            <param name="sizeInBytes"></param>
            <returns></returns>
        </member>
        <member name="T:ManagedCuda.CudaDNN.LRNConstants">
            <summary>
            Constants for LRN, #define in cudnn.h
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.LRNConstants.MinN">
            <summary>
            minimum allowed lrnN
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.LRNConstants.MaxN">
            <summary>
            maximum allowed lrnN
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.LRNConstants.MinK">
            <summary>
            minimum allowed lrnK
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.LRNConstants.MinBeta">
            <summary>
            minimum allowed lrnBeta
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.BNConstants">
            <summary>
            Constant values for BN
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.BNConstants.MinEpsilon">
            <summary>
            MinEpsilon = 1e-5
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnCallback">
            <summary>
            
            </summary>
            <param name="sev"></param>
            <param name="udata"></param>
            <param name="dbg"></param>
            <param name="msg"></param>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgoPerf">
            <summary>
            cudnnConvolutionFwdAlgoPerf is a structure containing performance results
            returned by cudnnFindConvolutionForwardAlgorithm().
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgoPerf.algo">
            <summary>
            The algorithm run to obtain the associated performance metrics.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgoPerf.status">
            <summary>
            If any error occurs during the workspace allocation or timing of cudnnConvolutionForward(),
            this status will represent that error. Otherwise, this status will be the return status of
            cudnnConvolutionForward().<para/>
            - CUDNN_STATUS_ALLOC_FAILED if any error occured during workspace allocation or deallocation.<para/>
            - CUDNN_STATUS_EXECUTION_FAILED if any error occured during timing calculations.<para/>
            - Otherwise, this will be the return status of cudnnConvolutionForward().<para/>
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgoPerf.time">
            <summary>
            The execution time of cudnnConvolutionForward() (in milliseconds).
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgoPerf.memory">
            <summary>
            The workspace size (in bytes).
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgoPerf.determinism">
            <summary>
            The determinism of the algorithm.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgoPerf.mathType">
            <summary>
            
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterAlgoPerf">
            <summary>
            cudnnConvolutionBwdFilterAlgoPerf is a structure containing performance
            results returned by cudnnFindConvolutionBackwardFilterAlgorithm().
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterAlgoPerf.algo">
            <summary>
            The algorithm run to obtain the associated performance metrics.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterAlgoPerf.status">
            <summary>
            If any error occurs during the workspace allocation or timing of
            cudnnConvolutionBackwardFilter_v3(), this status will represent that error. Otherwise,
            this status will be the return status of cudnnConvolutionBackwardFilter_v3().<para/>
            - CUDNN_STATUS_ALLOC_FAILED if any error occured during workspace allocation or deallocation.<para/>
            - CUDNN_STATUS_EXECUTION_FAILED if any error occured during timing calculations.<para/>
            - Otherwise, this will be the return status of cudnnConvolutionBackwardFilter_v3().<para/>
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterAlgoPerf.time">
            <summary>
            The execution time of cudnnConvolutionBackwardFilter_v3() (in milliseconds).
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterAlgoPerf.memory">
            <summary>
            The workspace size (in bytes).
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterAlgoPerf.determinism">
            <summary>
            The determinism of the algorithm.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterAlgoPerf.mathType">
            <summary>
            
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnConvolutionBwdDataAlgoPerf">
            <summary>
            cudnnConvolutionBwdDataAlgoPerf is a structure containing performance results
            returned by cudnnFindConvolutionBackwardDataAlgorithm().
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdDataAlgoPerf.algo">
            <summary>
            The algorithm run to obtain the associated performance metrics.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdDataAlgoPerf.status">
            <summary>
            If any error occurs during the workspace allocation or timing of
            cudnnConvolutionBackwardData_v3(), this status will represent that error. Otherwise,
            this status will be the return status of cudnnConvolutionBackwardData_v3().<para/>
            - CUDNN_STATUS_ALLOC_FAILED if any error occured during workspace allocation or deallocation.<para/>
            - CUDNN_STATUS_EXECUTION_FAILED if any error occured during timing calculations.<para/>
            - Otherwise, this will be the return status of cudnnConvolutionBackwardData_v3().
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdDataAlgoPerf.time">
            <summary>
            The execution time of cudnnConvolutionBackwardData_v3() (in milliseconds).
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdDataAlgoPerf.memory">
            <summary>
            The workspace size (in bytes).
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdDataAlgoPerf.determinism">
            <summary>
            The determinism of the algorithm.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdDataAlgoPerf.mathType">
            <summary>
            
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnAlgorithm">
            <summary>
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnAlgorithm.convFwdAlgo">
            <summary>
            
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnAlgorithm.convBwdFilterAlgo">
            <summary>
            
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnAlgorithm.convBwdDataAlgo">
            <summary>
            
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnAlgorithm.RNNAlgo">
            <summary>
            
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnAlgorithm.CTCLossAlgo">
            <summary>
            
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnDebug">
            <summary>
            
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnDebug.cudnn_version">
            <summary>
            
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnDebug.cudnnStatus">
            <summary>
            
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnDebug.time_sec">
            <summary>
            epoch time in seconds
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnDebug.time_usec">
            <summary>
            microseconds part of epoch time
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnDebug.time_delta">
            <summary>
            time since start in seconds
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnDebug.handle">
            <summary>
            cudnn handle 
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnDebug.stream">
            <summary>
            cuda stream ID
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnDebug.pid">
            <summary>
            process ID
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnDebug.tid">
            <summary>
            thread ID
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnDebug.cudaDeviceId">
            <summary>
            CUDA device ID
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnHandle">
            <summary>
            cudnnHandle is a pointer to an opaque structure holding the cuDNN library context.<para/>
            The cuDNN library context must be created using cudnnCreate() and the returned
            handle must be passed to all subsequent library function calls. The context should be
            destroyed at the end using cudnnDestroy(). The context is associated with only one
            GPU device, the current device at the time of the call to cudnnCreate(). However
            multiple contexts can be created on the same GPU device.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnTensorDescriptor">
            <summary>
            cudnnCreateTensorDescriptor is a pointer to an opaque structure holding the
            description of a generic n-D dataset.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnConvolutionDescriptor">
            <summary>
            cudnnConvolutionDescriptor is a pointer to an opaque structure holding the
            description of a convolution operation.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionDescriptor.Pointer">
            <summary>
            
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnPoolingDescriptor">
            <summary>
            cudnnPoolingDescriptor is a pointer to an opaque structure holding
            the description of a pooling operation.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnFilterDescriptor">
            <summary>
            cudnnFilterDescriptor is a pointer to an opaque structure holding the description
            of a filter dataset.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnLRNDescriptor">
            <summary>
            cudnnLRNDescriptor is a pointer to an opaque structure holding the description
            of a local response normalization operation.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnActivationDescriptor">
            <summary>
            cudnnActivationDescriptor is a pointer to an opaque structure holding the description
            of a activation operation.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnSpatialTransformerDescriptor">
            <summary>
            cudnnSpatialTransformerDescriptor_t is a pointer to an opaque structure 
            holding the description of a spatial transformation operation. 
            cudnnCreateSpatialTransformerDescriptor() is used to create one instance, 
            cudnnSetSpatialTransformerNdDescriptor() is used to initialize this instance, 
            cudnnDestroySpatialTransformerDescriptor() is used to destroy this instance.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnOpTensorDescriptor">
            <summary>
            cudnnOpTensorDescriptor is a pointer to an opaque structure holding the 
            description of a tensor operation, used as a parameter to cudnnOpTensor(). 
            cudnnCreateOpTensorDescriptor() is used to create one instance, and 
            cudnnSetOpTensorDescriptor() must be used to initialize this instance.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnDropoutDescriptor">
            <summary>
            cudnnDropoutDescriptor_t is a pointer to an opaque structure holding the description of a dropout operation. 
            cudnnCreateDropoutDescriptor() is used to create one instance, cudnnSetDropoutDescriptor() is be used to 
            initialize this instance, cudnnDestroyDropoutDescriptor() is be used to destroy this instance.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnRNNDescriptor">
            <summary>
            cudnnRNNDescriptor_t is a pointer to an opaque structure holding the description of an RNN operation. 
            cudnnCreateRNNDescriptor() is used to create one instance, and cudnnSetRNNDescriptor() must be used to 
            initialize this instance.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnReduceTensorDescriptor">
            <summary>
            cudnnReduceTensorDescriptor_t is a pointer to an opaque structure
            holding the description of a tensor reduction operation, used as a parameter to
            cudnnReduceTensor(). cudnnCreateReduceTensorDescriptor() is used to create
            one instance, and cudnnSetReduceTensorDescriptor() must be used to initialize this instance.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnPersistentRNNPlan">
            <summary>
            cudnnPersistentRNNPlan_t is a pointer to an opaque structure holding a plan to
            execute a dynamic persistent RNN.cudnnCreatePersistentRNNPlan() is used to
            create and initialize one instance.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnRuntimeTag">
            <summary>
            Forward definition in this version only
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnCTCLossDescriptor">
            <summary>
            
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnAlgorithmDescriptor">
            <summary>
            
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnAlgorithmPerformance">
            <summary>
            
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnStatus">
            <summary>
            CUDNN return codes
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnStatus.Success">
            <summary>
            The operation completed successfully.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnStatus.NotInitialized">
            <summary>
            The cuDNN library was not initialized properly.<para/>
            This error is usually returned when a call to
            cudnnCreate() fails or when cudnnCreate()
            has not been called prior to calling another cuDNN
            routine. In the former case, it is usually due
            to an error in the CUDA Runtime API called by
            cudnnCreate() or by an error in the hardware
            setup.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnStatus.AllocFailed">
            <summary>
            Resource allocation failed inside the cuDNN
            library. This is usually caused by an internal
            cudaMalloc() failure.<para/>
            To correct: prior to the function call, deallocate
            previously allocated memory as much as possible.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnStatus.BadParam">
            <summary>
            An incorrect value or parameter was passed to the
            function.<para/>
            To correct: ensure that all the parameters being
            passed have valid values.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnStatus.InternalError">
            <summary>
            An internal cuDNN operation failed.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnStatus.InvalidValue">
            <summary>
            
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnStatus.ArchMismatch">
            <summary>
            The function requires a feature absent from
            the current GPU device. Note that cuDNN only
            supports devices with compute capabilities greater
            than or equal to 3.0.<para/>
            To correct: compile and run the application on a
            device with appropriate compute capability.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnStatus.MappingError">
            <summary>
            An access to GPU memory space failed, which is
            usually caused by a failure to bind a texture.<para/>
            To correct: prior to the function call, unbind any
            previously bound textures.<para/>
            Otherwise, this may indicate an internal error/bug
            in the library.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnStatus.ExecutionFailed">
            <summary>
            The GPU program failed to execute. This is usually
            caused by a failure to launch some cuDNN kernel
            on the GPU, which can occur for multiple reasons.<para/>
            To correct: check that the hardware, an
            appropriate version of the driver, and the cuDNN
            library are correctly installed.<para/>
            Otherwise, this may indicate a internal error/bug
            in the library.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnStatus.NotSupported">
            <summary>
            The functionality requested is not presently supported by cuDNN.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnStatus.LicenseError">
            <summary>
            The functionality requested requires some license
            and an error was detected when trying to check
            the current licensing. This error can happen if
            the license is not present or is expired or if the
            environment variable NVIDIA_LICENSE_FILE is not
            set properly.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnStatus.RuntimePrerequisiteMissing">
            <summary>
            
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnStatus.RuntimInProgress">
            <summary>
            
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnStatus.RuntimeFPOverflow">
            <summary>
            
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnDataType">
            <summary>
            cudnnDataType is an enumerated type indicating the data type to which a tensor
            descriptor or filter descriptor refers.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnDataType.Float">
            <summary>
            The data is 32-bit single-precision floating point (float).
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnDataType.Double">
            <summary>
            The data is 64-bit double-precision floating point (double).
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnDataType.Half">
            <summary>
            The data is 16-bit floating point.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnDataType.Int8">
            <summary>
            The data is 8-bit signed integer.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnDataType.Int32">
            <summary>
            The data is 32-bit signed integer.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnDataType.Int8x4">
            <summary>
            The data is 32-bit element composed of 4 8-bit signed integer. This data type
            is only supported with tensor format CUDNN_TENSOR_NCHW_VECT_C.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnDataType.UInt8">
            <summary>
            The data is 8-bit unsigned integer.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnDataType.UInt8x4">
            <summary>
            The data is 32-bit element composed of 4 8-bit unsigned integer. This data type
            is only supported with tensor format CUDNN_TENSOR_NCHW_VECT_C.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnNanPropagation">
            <summary>
            cudnnNanPropagation is an enumerated type for the NanPropagation flag.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnNanPropagation.NotPropagateNan">
            <summary>
            Selects the not propagate NaN option.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnNanPropagation.PropagateNan">
            <summary>
            Selects the propagate NaN option.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnTensorFormat">
            <summary>
            cudnnTensorFormat is an enumerated type used by
            cudnnSetTensor4dDescriptor() to create a tensor with a pre-defined layout.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnTensorFormat.NCHW">
            <summary>
            This tensor format specifies that the data is laid out in the following order: image, features map,
            rows, columns. The strides are implicitly defined in such a way that the data are contiguous in
            memory with no padding between images, feature maps, rows, and columns; the columns are the
            inner dimension and the images are the outermost dimension.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnTensorFormat.NHWC">
            <summary>
            This tensor format specifies that the data is laid out in the following order: image, rows, columns,
            features maps. The strides are implicitly defined in such a way that the data are contiguous in memory
            with no padding between images, rows, columns, and features maps; the feature maps are the
            inner dimension and the images are the outermost dimension.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnTensorFormat.NCHW_VECT_C">
            <summary>
            This tensor format specifies that the data is laid out in the following order: batch size, feature
            maps, rows, columns. However, each element of the tensor is a vector of multiple feature
            maps. The length of the vector is carried by the data type of the tensor. The strides are
            implicitly defined in such a way that the data are contiguous in memory with no padding
            between images, feature maps, rows, and columns; the columns are the inner dimension
            and the images are the outermost dimension. This format is only supported with tensor data type
            CUDNN_DATA_INT8x4.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnAddMode">
            <summary>
            cudnnAddMode is an enumerated type used by cudnnAddTensor() to specify how a
            bias tensor is added to an input/output tensor.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnAddMode.Image">
            <summary>
            In this mode, the bias tensor is defined as one
            image with one feature map. This image will be
            added to every feature map of every image of the
            input/output tensor.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnAddMode.SameHW">
            <summary>
            In this mode, the bias tensor is defined as one
            image with one feature map. This image will be
            added to every feature map of every image of the
            input/output tensor.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnAddMode.FeatureMap">
            <summary>
            In this mode, the bias tensor is defined as one
            image with multiple feature maps. This image
            will be added to every image of the input/output
            tensor.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnAddMode.SameCHW">
            <summary>
            In this mode, the bias tensor is defined as one
            image with multiple feature maps. This image
            will be added to every image of the input/output
            tensor.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnAddMode.SameC">
            <summary>
            In this mode, the bias tensor is defined as one
            image with multiple feature maps of dimension
            1x1; it can be seen as an vector of feature maps.
            Each feature map of the bias tensor will be added
            to the corresponding feature map of all height-bywidth
            pixels of every image of the input/output
            tensor.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnAddMode.FullTensor">
            <summary>
            In this mode, the bias tensor has the same
            dimensions as the input/output tensor. It will be
            added point-wise to the input/output tensor.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnConvolutionMode">
            <summary>
            cudnnConvolutionMode is an enumerated type used by
            cudnnSetConvolutionDescriptor() to configure a convolution descriptor.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionMode.Convolution">
            <summary>
            In this mode, a convolution operation will be done
            when applying the filter to the images.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionMode.CrossCorrelation">
            <summary>
            In this mode, a cross-correlation operation will be
            done when applying the filter to the images.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnConvolutionFwdPreference">
            <summary>
            cudnnConvolutionFwdPreference is an enumerated type used by
            cudnnGetConvolutionForwardAlgorithm() to help the choice of the algorithm used
            for the forward convolution.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionFwdPreference.NoWorkspace">
            <summary>
            In this configuration, the routine cudnnGetConvolutionForwardAlgorithm() is
            guaranteed to return an algorithm that does not require any extra workspace to be provided by the
            user.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionFwdPreference.PreferFastest">
            <summary>
            In this configuration, the routine cudnnGetConvolutionForwardAlgorithm() will
            return the fastest algorithm regardless how much workspace is needed to execute it.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionFwdPreference.SpecifyWorkspaceLimit">
            <summary>
            In this configuration, the routine cudnnGetConvolutionForwardAlgorithm() will
            return the fastest algorithm that fits within the memory limit that the user provided.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgo">
            <summary>
            cudnnConvolutionFwdAlgo is an enumerated type that exposes the different
            algorithms available to execute the forward convolution operation.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgo.ImplicitGEMM">
            <summary>
            This algorithm expresses the convolution as a matrix product without actually explicitly form the
            matrix that holds the input tensor data.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgo.ImplicitPrecompGEMM">
            <summary>
            This algorithm expresses the convolution as a matrix product without actually explicitly form
            the matrix that holds the input tensor data, but still needs some memory workspace to precompute
            some indices in order to facilitate the implicit construction of the matrix that holds the input
            tensor data
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgo.GEMM">
            <summary>
            This algorithm expresses the convolution as an explicit matrix product. A significant memory
            workspace is needed to store the matrix that holds the input tensor data.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgo.Direct">
            <summary>
            This algorithm expresses the convolution as a direct convolution (e.g without implicitly or
            explicitly doing a matrix multiplication).
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgo.FFT">
            <summary>
            This algorithm uses a Fast-Fourier Transform approach to compute the convolution. A
            significant memory workspace is needed to store intermediate results.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgo.FFTWithTiling">
            <summary>
            This algorithm uses a Fast-Fourier Transform approach but splits the inputs into 32x32 tiles. A
            significant memory workspace is needed to store intermediate results but significantly less than
            FFT for big size images.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionFwdAlgo.Winograd">
            <summary>
            This algorithm uses a Winograd Transform approach to compute the convolution. A reasonably 
            sized workspace is needed to store intermediate results.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnSoftmaxAlgorithm">
            <summary>
            cudnnSoftmaxAlgorithm is used to select an implementation of the softmax
            function used in cudnnSoftmaxForward() and cudnnSoftmaxBackward().
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnSoftmaxAlgorithm.Fast">
            <summary>
            This implementation applies the straightforward softmax operation.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnSoftmaxAlgorithm.Accurate">
            <summary>
            This implementation scales each point of the softmax input domain by its maximum value to
            avoid potential floating point overflows in the softmax evaluation.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnSoftmaxAlgorithm.Log">
            <summary>
            This entry performs the Log softmax operation, avoiding overflows by scaling each point in the
            input domain as in CUDNN_SOFTMAX_ACCURATE
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnSoftmaxMode">
            <summary>
            cudnnSoftmaxMode is used to select over which data the cudnnSoftmaxForward()
            and cudnnSoftmaxBackward() are computing their results.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnSoftmaxMode.Instance">
            <summary>
            The softmax operation is computed per image (N) across the dimensions C,H,W.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnSoftmaxMode.Channel">
            <summary>
            The softmax operation is computed per spatial location (H,W) per image (N) across the dimension C.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnPoolingMode">
            <summary>
            cudnnPoolingMode is an enumerated type passed to cudnnSetPoolingDescriptor() to select the pooling method to be used by
            cudnnPoolingForward() and cudnnPoolingBackward().
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnPoolingMode.Max">
            <summary>
            The maximum value inside the pooling window will be used.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnPoolingMode.AverageCountIncludePadding">
            <summary>
            The values inside the pooling window will be averaged. The number of padded values will be
            taken into account when computing the average value.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnPoolingMode.AverageCountExcludePadding">
            <summary>
            The values inside the pooling window will be averaged. The number of padded values will not
            be taken into account when computing the average value.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnActivationMode">
            <summary>
            cudnnActivationMode is an enumerated type used to select the neuron activation
            function used in cudnnActivationForward() and cudnnActivationBackward().
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnActivationMode.Sigmoid">
            <summary>
            Selects the sigmoid function.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnActivationMode.Relu">
            <summary>
            Selects the rectified linear function.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnActivationMode.Tanh">
            <summary>
            Selects the hyperbolic tangent function.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnActivationMode.ClippedRelu">
            <summary>
            Selects the clipped rectified linear function.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnActivationMode.Elu">
            <summary>
            Selects the exponential linear function
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnActivationMode.Identity">
            <summary>
            Selects the identity function, intended for bypassing the activation step in cudnnConvolutionBiasActivationForward() (need to use CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM). Does not work with cudnnActivationForward() or cudnnActivationBackward().
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterPreference">
            <summary>
            cudnnConvolutionBwdFilterPreference is an enumerated type used by
            cudnnGetConvolutionBackwardFilterAlgorithm() to help the choice of the
            algorithm used for the backward filter convolution.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterPreference.NoWorkspace">
            <summary>
            In this configuration, the routine cudnnGetConvolutionBackwardFilterAlgorithm()
            is guaranteed to return an algorithm that does not require any extra workspace to be provided by the user.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterPreference.PreferFastest">
            <summary>
            In this configuration, the routine cudnnGetConvolutionBackwardFilterAlgorithm()
            will return the fastest algorithm regardless how much workspace is needed to execute it.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterPreference.SpecifyWorkspaceLimit">
            <summary>
            In this configuration, the routine cudnnGetConvolutionBackwardFilterAlgorithm()
            will return the fastest algorithm that fits within the memory limit that the user provided.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterAlgo">
            <summary>
            cudnnConvolutionBwdFilterAlgo is an enumerated type that exposes the different
            algorithms available to execute the backward filter convolution operation.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterAlgo.Algo0">
            <summary>
            This algorithm expresses the convolution as a sum of matrix product without actually explicitly form
            the matrix that holds the input tensor data. The sum is done using atomic adds operation, thus the
            results are non-deterministic.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterAlgo.Algo1">
            <summary>
            This algorithm expresses the convolution as a matrix product without actually explicitly form
            the matrix that holds the input tensor data. The results are deterministic.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterAlgo.AlgoFFT">
            <summary>
            This algorithm uses a Fast-Fourier Transform approach to compute the convolution. A
            significant memory workspace is needed to store intermediate results. The results are
            deterministic.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterAlgo.Algo3">
            <summary>
            This algorithm is similar to CUDNN_CONVOLUTION_BWD_FILTER_ALGO_0 but
            uses some small workspace to precomputes some indices. The results are also non-deterministic.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterAlgo.AlgoWinograd">
            <summary>
            Not implemented
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterAlgo.AlgoWinogradNonFused">
            <summary>
            This algorithm uses the Winograd Transform
            approach to compute the convolution. Significant
            workspace may be needed to store intermediate
            results. The results are deterministic.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdFilterAlgo.AlgoFFTTiling">
            <summary>
            This algorithm uses the Fast-Fourier Transform
            approach to compute the convolution but splits
            the input tensor into tiles. Significant workspace
            may be needed to store intermediate results. The
            results are deterministic.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnConvolutionBwdDataPreference">
            <summary>
            cudnnConvolutionBwdDataPreference is an enumerated type used by
            cudnnGetConvolutionBackwardDataAlgorithm() to help the choice of the
            algorithm used for the backward data convolution.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdDataPreference.NoWorkspace">
            <summary>
            In this configuration, the routine cudnnGetConvolutionBackwardDataAlgorithm()
            is guaranteed to return an algorithm that does not require any extra workspace to be provided by the
            user.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdDataPreference.PreferFastest">
            <summary>
            In this configuration, the routine cudnnGetConvolutionBackwardDataAlgorithm()
            will return the fastest algorithm regardless how much workspace is needed to execute it.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdDataPreference.SpecifyWorkspaceLimit">
            <summary>
            In this configuration, the routine cudnnGetConvolutionBackwardDataAlgorithm()
            will return the fastest algorithm that fits within the memory limit that the user provided.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnConvolutionBwdDataAlgo">
            <summary>
            cudnnConvolutionBwdDataAlgo is an enumerated type that exposes the different
            algorithms available to execute the backward data convolution operation.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdDataAlgo.Algo0">
            <summary>
            This algorithm expresses the convolution as a sum of matrix product without actually explicitly form
            the matrix that holds the input tensor data. The sum is done using atomic adds operation, thus the
            results are non-deterministic.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdDataAlgo.Algo1">
            <summary>
            This algorithm expresses the convolution as a matrix product without actually explicitly form
            the matrix that holds the input tensor data. The results are deterministic.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdDataAlgo.AlgoFFT">
            <summary>
            This algorithm uses a Fast-Fourier Transform approach to compute the convolution. A
            significant memory workspace is needed to store intermediate results. The results are
            deterministic.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnConvolutionBwdDataAlgo.Winograd">
            <summary>
            This algorithm uses a Winograd Transform approach to compute the convolution. 
            A reasonably sized workspace is needed to store intermediate results. The results are deterministic.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnLRNMode">
            <summary>
            cudnnLRNMode is an enumerated type used to specify the mode of operation in cudnnLRNCrossChannelForward() and cudnnLRNCrossChannelBackward().
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnLRNMode.CrossChannelDim1">
            <summary>
            LRN co mputation is performed across tensor's dimension dimA[1].
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnDivNormMode">
            <summary>
            cudnnDivNormMode is an enumerated type used to specify the
            mode of operation in cudnnDivisiveNormalizationForward() and
            cudnnDivisiveNormalizationBackward().
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnDivNormMode.PrecomputedMeans">
            <summary>
            The means tensor data pointer is expected to
            contain means or other kernel convolution values
            precomputed by the user. The means pointer
            can also be NULL, in that case it's considered
            to be filled with zeroes. This is equivalent to
            spatial LRN. Note that in the backward pass
            the means are treated as independent inputs
            and the gradient over means is computed
            independently. In this mode to yield a net gradient
            over the entire LCN computational graph the
            destDiffMeans result should be backpropagated
            through the user's means layer (which can
            be impelemented using average pooling) and
            added to the destDiffData tensor produced by
            cudnnDivisiveNormalizationBackward.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnBatchNormMode">
            <summary>
            cudnnBatchNormMode is an enumerated type used to specify the mode of operation in 
            cudnnBatchNormalizationForwardInference(), cudnnBatchNormalizationForwardTraining(), 
            cudnnBatchNormalizationBackward() and cudnnDeriveBNTensorDescriptor() routines. 
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnBatchNormMode.BatchNormPerActivation">
            <summary>
            Normalization is performed per-activation. This mode is intended to be used after nonconvolutional
            network layers. In this mode bnBias and bnScale tensor dimensions are 1xCxHxW.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnBatchNormMode.BatchNormSpatial">
            <summary>
            Normalization is performed over N+spatial dimensions. This mode is intended for use after
            convolutional layers (where spatial invariance is desired). In this mode bnBias, bnScale tensor
            dimensions are 1xCx1x1.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnBatchNormMode.BatchNormSpatialPersitent">
            <summary>
            bnScale, bnBias tensor dims are 1xCx1x1 (one value per C-dim normalized over Nx1xHxW subtensors). 
            May be faster than CUDNN_BATCHNORM_SPATIAL but imposes some limits on the range of values
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnOpTensorOp">
            <summary>
            cudnnOpTensorOp is an enumerated type used to indicate the tensor operation to be used 
            by the cudnnOpTensor() routine. This enumerated type is used as a field for the 
            cudnnOpTensorDescriptor descriptor.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnOpTensorOp.OpTensorAdd">
            <summary>
            The operation to be performed is addition.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnOpTensorOp.OpTensorMul">
            <summary>
            The operation to be performed is multiplication.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnOpTensorOp.OpTensorMin">
            <summary>
            The operation to be performed is a minimum comparison.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnOpTensorOp.OpTensorMax">
            <summary>
            The operation to be performed is a maximum comparison.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnOpTensorOp.OpTensorSqrt">
            <summary>
            
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnOpTensorOp.OpTensorNot">
            <summary>
            
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnSamplerType">
            <summary>
            cudnnSamplerType_t is an enumerated type passed to cudnnSetSpatialTransformerNdDescriptor() to 
            select the sampler type to be used by cudnnSpatialTfSamplerForward() and cudnnSpatialTfSamplerBackward().
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnSamplerType.SamplerBilinear">
            <summary>
            Selects the bilinear sampler.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnRNNMode">
            <summary>
            cudnnRNNMode_t is an enumerated type used to specify the type of network used in the 
            cudnnRNNForwardInference(), cudnnRNNForwardTraining(), cudnnRNNBackwardData() and 
            cudnnRNNBackwardWeights() routines.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnRNNMode.RNNRelu">
            <summary>
            A single-gate recurrent neural network with a ReLU activation function. In the forward pass the output ht for a 
            given iteration can be computed from the recurrent input ht-1 and the previous layer input xt given matrices 
            W, R and biases bW, bR from the following equation:
            h_t = ReLU(W_i x_t + R_i h_(t-1) + b_Wi + b_Ri) 
            Where ReLU(x) = max(x, 0). 
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnRNNMode.RNNTanh">
            <summary>
            A single-gate recurrent neural network with a tanh activation function. In the forward pass the output ht 
            for a given iteration can be computed from the recurrent input ht-1 and the previous layer input xt given 
            matrices W, R and biases bW, bR from the following equation:
            h_t = tanh(W_i x_t + R_i h_(t-1) + b_Wi + b_Ri) 
            Where tanh is the hyperbolic tangent function.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnRNNMode.LSTM">
            <summary>
            A four-gate Long Short-Term Memory network with no peephole connections. In the forward pass the output ht 
            and cell output c_t for a given iteration can be computed from the recurrent input h_(t-1), the cell input c_(t-1)
            and the previous layer input x_t given matrices W, R and biases b_W, b_R from the following equations: 
            i_t = (W_i x_t + R_i h_(t-1) + b_Wi + b_Ri) 
            f_t = (W_f x_t + R_f h_(t-1) + b_Wf + b_Rf) 
            o_t = (W_o x_t + R_o h_(t-1) + b_Wo + b_Ro)
            c_'t = tanh(W_c x_t + R_c h_(t-1) + b_Wc + b_Rc) 
            c_t = f_tc_'(t-1) + i_tc_'t 
            h_t = o_ttanh(c_t)
            Where  is the sigmoid operator: (x) = 1 / (1 + e^-x),  represents a point-wise multiplication 
            and tanh is the hyperbolic tangent function. i_t, f_t, o_t, c_'t represent the input, forget, output 
            and new gates respectively. 
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnRNNMode.GRU">
            <summary>
            A three-gate network consisting of Gated Recurrent Units. In the forward pass the output ht 
            for a given iteration can be computed from the recurrent input ht-1 and the previous layer input 
            xt given matrices W, R and biases bW, bR from the following equations:
            i_t = (W_i x_t + R_i h_(t-1) + b_Wi + b_Ru)
            r_t = (W_r x_t + R_r h_(t-1) + b_Wr + b_Rr)
            h_'t = tanh(W_h x_t + r_tR_h h_(t-1) + b_Wh + b_Rh) 
            h_t = (1 - i_th_'t) + i_th_(t-1)
            Where  is the sigmoid operator: (x) = 1 / (1 + e^-x),  represents a point-wise multiplication 
            and tanh is the hyperbolic tangent function. i_t, r_t, h_'t represent the input, reset, new gates respectively.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnDirectionMode">
            <summary>
            cudnnDirectionMode_t is an enumerated type used to specify the recurrence pattern in the cudnnRNNForwardInference(), 
            cudnnRNNForwardTraining(), cudnnRNNBackwardData() and cudnnRNNBackwardWeights() routines.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnDirectionMode.Unidirectional">
            <summary>
            The network iterates recurrently from the first input to the last.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnDirectionMode.Bidirectional">
            <summary>
            Each layer of the the network iterates recurrently from the first input to the last and separately 
            from the last input to the first. The outputs of the two are concatenated at each iteration giving 
            the output of the layer.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnRNNInputMode">
            <summary>
            cudnnRNNInputMode_t is an enumerated type used to specify the behavior of the first 
            layer in the cudnnRNNForwardInference(), cudnnRNNForwardTraining(), 
            cudnnRNNBackwardData() and cudnnRNNBackwardWeights() routines.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnRNNInputMode.LinearInput">
            <summary>
            A biased matrix multiplication is performed at the input of the first recurrent layer.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnRNNInputMode.SkipInput">
            <summary>
            No operation is performed at the input of the first recurrent layer. If CUDNN_SKIP_INPUT 
            is used the leading dimension of the input tensor must be equal to the hidden state size 
            of the network.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.libraryPropertyType">
            <summary>
            
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.libraryPropertyType.MajorVersion">
            <summary>
            
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.libraryPropertyType.MinorVersion">
            <summary>
            
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.libraryPropertyType.PatchLevel">
            <summary>
            
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnDeterminism">
            <summary>
            cudnnDeterminism_t is an enumerated type used to indicate if the computed results
            are deterministic(reproducible). See section 2.5 (Reproducibility) for more details on
            determinism.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnDeterminism.NonDeterministic">
            <summary>
            Results are not guaranteed to be reproducible
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnDeterminism.Deterministic">
            <summary>
            Results are guaranteed to be reproducible
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnReduceTensorOp">
            <summary>
            cudnnReduceTensorOp is an enumerated type used to indicate the tensor operation
            to be used by the cudnnReduceTensor() routine.This enumerated type is used as a
            field for the cudnnReduceTensorDescriptor_t descriptor.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnReduceTensorOp.Add">
            <summary>
            The operation to be performed is addition
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnReduceTensorOp.Mul">
            <summary>
            The operation to be performed is multiplication
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnReduceTensorOp.Min">
            <summary>
            The operation to be performed is a minimum comparison
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnReduceTensorOp.Max">
            <summary>
            The operation to be performed is a maximum comparison
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnReduceTensorOp.AMax">
            <summary>
            The operation to be performed is a maximum comparison of absolute values
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnReduceTensorOp.Avg">
            <summary>
            The operation to be performed is averaging
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnReduceTensorOp.Norm1">
            <summary>
            The operation to be performed is addition of absolute values
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnReduceTensorOp.Norm2">
            <summary>
            The operation to be performed is a square root of sum of squares
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnReduceTensorOp.MulNoZeros">
            <summary>
            
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnReduceTensorIndices">
            <summary>
            cudnnReduceTensorIndices_t is an enumerated type used to indicate whether
            indices are to be computed by the cudnnReduceTensor() routine.This enumerated
            type is used as a field for the cudnnReduceTensorDescriptor_t descriptor.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnReduceTensorIndices.NoIndices">
            <summary>
            Do not compute indices
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnReduceTensorIndices.FlattenedIndices">
            <summary>
            Compute indices. The resulting indices are relative, and flattened.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnIndicesType">
            <summary>
            cudnnIndicesType_t is an enumerated type used to indicate the data type for the
            indices to be computed by the cudnnReduceTensor() routine. This enumerated type is
            used as a field for the cudnnReduceTensorDescriptor_t descriptor.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnIndicesType.Indices32Bit">
            <summary>
            Compute unsigned int indices
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnIndicesType.Indices64Bit">
            <summary>
            Compute unsigned long long indices
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnIndicesType.Indices16Bit">
            <summary>
            Compute unsigned short indices
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnIndicesType.Indices8Bit">
            <summary>
            Compute unsigned char indices
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnRNNAlgo">
            <summary>
            cudnnRNNAlgo_t is an enumerated type used to specify the algorithm used
            in the cudnnRNNForwardInference(), cudnnRNNForwardTraining(),
            cudnnRNNBackwardData() and cudnnRNNBackwardWeights() routines.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnRNNAlgo.Standard">
            <summary>
            Each RNN layer is executed as a sequence of operations. This
            algorithm is expected to have robust performance across a wide
            range of network parameters.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnRNNAlgo.PersistStatic">
            <summary>
            The recurrent parts of the network are executed using a persistent
            kernel approach. This method is expected to be fast when the first
            dimension of the input tensor is small (ie. a small minibatch).
            CUDNN_RNN_ALGO_PERSIST_STATIC is only supported on devices
            with compute capability >= 6.0.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnRNNAlgo.PersistDynamic">
            <summary>
            The recurrent parts of the network are executed using a persistent
            kernel approach. This method is expected to be fast when the first
            dimension of the input tensor is small (ie. a small minibatch). When
            using CUDNN_RNN_ALGO_PERSIST_DYNAMIC persistent kernels are
            prepared at runtime and are able to optimized using the specific
            parameters of the network and active GPU.As such, when using
            CUDNN_RNN_ALGO_PERSIST_DYNAMIC a one-time plan preparation
            stage must be executed.These plans can then be reused in repeated
            calls with the same model parameters.<para/>
            The limits on the maximum number of hidden units
            supported when using CUDNN_RNN_ALGO_PERSIST_DYNAMIC
            are significantly higher than the limits when using
            CUDNN_RNN_ALGO_PERSIST_STATIC, however throughput is likely
            to significantly reduce when exceeding the maximums supported by
            CUDNN_RNN_ALGO_PERSIST_STATIC.In this regime this method will
            still outperform CUDNN_RNN_ALGO_STANDARD for some cases.<para/>
            CUDNN_RNN_ALGO_PERSIST_DYNAMIC is only supported on devices
            with compute capability >= 6.0 on Linux machines.
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnRNNAlgo.Count">
            <summary>
            
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnErrQueryMode">
            <summary>
            
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnErrQueryMode.RawCode">
            <summary>
            
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnErrQueryMode.NonBlocking">
            <summary>
            
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnErrQueryMode.Blocking">
            <summary>
            
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnMathType">
            <summary>
            CUDNN math type
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnMathType.Default">
            <summary>
            
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnMathType.TensorOP">
            <summary>
            
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnCTCLossAlgo">
            <summary>
            
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnCTCLossAlgo.Deterministic">
            <summary>
            
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnCTCLossAlgo.NonDeterministic">
            <summary>
            
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.cudnnSeverity">
            <summary>
            
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnSeverity.Fatal">
            <summary>
            
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnSeverity.Error">
            <summary>
            
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnSeverity.Warning">
            <summary>
            
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.cudnnSeverity.Info">
            <summary>
            
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.MessageMask">
            <summary>
            Message masks to be used with cudnnSetCallback()  
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.MessageMask.Error">
            <summary>
            
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.MessageMask.Warning">
            <summary>
            
            </summary>
        </member>
        <member name="F:ManagedCuda.CudaDNN.MessageMask.Info">
            <summary>
            
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.DropoutDescriptor">
            <summary>
            An opaque structure holding the
            description of a generic n-D dataset.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.DropoutDescriptor.#ctor(ManagedCuda.CudaDNN.CudaDNNContext)">
            <summary>
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.DropoutDescriptor.Finalize">
            <summary>
            For dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.DropoutDescriptor.Dispose">
            <summary>
            Dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.DropoutDescriptor.Dispose(System.Boolean)">
            <summary>
            For IDisposable
            </summary>
            <param name="fDisposing"></param>
        </member>
        <member name="P:ManagedCuda.CudaDNN.DropoutDescriptor.Desc">
            <summary>
            Returns the inner handle.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.DropoutDescriptor.SetDropoutDescriptor(System.Single,ManagedCuda.CudaDeviceVariable{System.Byte},ManagedCuda.BasicTypes.SizeT,System.UInt64)">
            <summary>
            This function initializes a previously created dropout descriptor object. If states argument is equal to 
            NULL, random number generator states won't be initialized, and only dropout value will be set. No other 
            function should be writing to the memory
            </summary>
            <param name="dropout">The probability with which the value from input would be propagated through the dropout layer.</param>
            <param name="states">Pointer to user-allocated GPU memory that will hold random number generator states.</param>
            <param name="stateSizeInBytes">Specifies size in bytes of the provided memory for the states.</param>
            <param name="seed">Seed used to initialize random number generator states.</param>
        </member>
        <member name="T:ManagedCuda.CudaDNN.FilterDescriptor">
            <summary>
            An opaque structure holding the description
            of a filter dataset.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.FilterDescriptor.#ctor">
            <summary>
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.FilterDescriptor.Finalize">
            <summary>
            For dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.FilterDescriptor.Dispose">
            <summary>
            Dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.FilterDescriptor.Dispose(System.Boolean)">
            <summary>
            For IDisposable
            </summary>
            <param name="fDisposing"></param>
        </member>
        <member name="P:ManagedCuda.CudaDNN.FilterDescriptor.Desc">
            <summary>
            Returns the inner handle.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.FilterDescriptor.SetFilter4dDescriptor(ManagedCuda.CudaDNN.cudnnDataType,ManagedCuda.CudaDNN.cudnnTensorFormat,System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            This function initializes a previously created filter descriptor object into a 4D filter.
            Filters layout must be contiguous in memory.
            </summary>
            <param name="dataType">Data type.</param>
            <param name="format">Enumerant holding the layout format.</param>
            <param name="k">Number of output feature maps.</param>
            <param name="c">Number of input feature maps.</param>
            <param name="h">Height of each filter.</param>
            <param name="w">Width of each filter.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.FilterDescriptor.GetFilter4dDescriptor(ManagedCuda.CudaDNN.cudnnDataType@,ManagedCuda.CudaDNN.cudnnTensorFormat@,System.Int32@,System.Int32@,System.Int32@,System.Int32@)">
            <summary>
            This function queries the parameters of the previouly initialized filter descriptor object.
            </summary>
            <param name="dataType">Data type.</param>
            <param name="format">Enumerant holding the layout format.</param>
            <param name="k">Number of output feature maps.</param>
            <param name="c">Number of input feature maps.</param>
            <param name="h">Height of each filter.</param>
            <param name="w">Width of each filter.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.FilterDescriptor.SetFilterNdDescriptor(ManagedCuda.CudaDNN.cudnnDataType,ManagedCuda.CudaDNN.cudnnTensorFormat,System.Int32,System.Int32[])">
            <summary>
            This function initializes a previously created filter descriptor object. Filters layout must
            be contiguous in memory.
            </summary>
            <param name="dataType">Data type.</param>
            <param name="format">Enumerant holding the layout format.</param>
            <param name="nbDims">Dimension of the filter.</param>
            <param name="filterDimA">Array of dimension nbDims containing the size of the filter for each dimension.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.FilterDescriptor.GetFilterNdDescriptor(System.Int32,ManagedCuda.CudaDNN.cudnnDataType@,ManagedCuda.CudaDNN.cudnnTensorFormat@,System.Int32@,System.Int32[])">
            <summary>
            This function queries a previously initialized filter descriptor object.
            </summary>
            <param name="nbDimsRequested">Dimension of the expected filter descriptor. It is also the minimum size of
            the arrays filterDimA in order to be able to hold the results</param>
            <param name="dataType">Data type.</param>
            <param name="format">Enumerant holding the layout format.</param>
            <param name="nbDims">Actual dimension of the filter.</param>
            <param name="filterDimA">Array of dimension of at least nbDimsRequested that will be filled with
            the filter parameters from the provided filter descriptor.</param>
        </member>
        <member name="T:ManagedCuda.CudaDNN.LRNDescriptor">
            <summary>
            
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.LRNDescriptor.#ctor(ManagedCuda.CudaDNN.CudaDNNContext)">
            <summary>
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.LRNDescriptor.Finalize">
            <summary>
            For dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.LRNDescriptor.Dispose">
            <summary>
            Dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.LRNDescriptor.Dispose(System.Boolean)">
            <summary>
            For IDisposable
            </summary>
            <param name="fDisposing"></param>
        </member>
        <member name="P:ManagedCuda.CudaDNN.LRNDescriptor.Desc">
            <summary>
            Returns the inner handle.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.LRNDescriptor.SetLRNDescriptor(System.UInt32,System.Double,System.Double,System.Double)">
            <summary>
            This function initializes a previously created LRN descriptor object.
            </summary>
            <param name="lrnN">Normalization window width in elements. LRN layer uses a window
            [center-lookBehind, center+lookAhead], where lookBehind =
            floor( (lrnN-1)/2 ), lookAhead = lrnN-lookBehind-1. So for n=10,
            the window is [k-4...k...k+5] with a total of 10 samples. For
            DivisiveNormalization layer the window has the same extents as above in
            all 'spatial' dimensions (dimA[2], dimA[3], dimA[4]). By default lrnN is set
            to 5 in cudnnCreateLRNDescriptor.</param>
            <param name="lrnAlpha">Value of the alpha variance scaling parameter in the normalization
            formula. Inside the library code this value is divided by the
            window width for LRN and by (window width)^#spatialDimensions
            for DivisiveNormalization. By default this value is set to 1e-4 in
            cudnnCreateLRNDescriptor.</param>
            <param name="lrnBeta">Value of the beta power parameter in the normalization formula. By
            default this value is set to 0.75 in cudnnCreateLRNDescriptor.</param>
            <param name="lrnK">Value of the k parameter in normalization formula. By default this value is set to 2.0.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.LRNDescriptor.GetLRNDescriptor(System.UInt32@,System.Double@,System.Double@,System.Double@)">
            <summary>
            This function retrieves values stored in the previously initialized LRN descriptor object.
            </summary>
            <param name="lrnN">Pointers to receive values of parameters stored in the descriptor object.
            See cudnnSetLRNDescriptor for more details. Any of these pointers can be
            NULL (no value is returned for the corresponding parameter).</param>
            <param name="lrnAlpha">Pointers to receive values of parameters stored in the descriptor object.
            See cudnnSetLRNDescriptor for more details. Any of these pointers can be
            NULL (no value is returned for the corresponding parameter).</param>
            <param name="lrnBeta">Pointers to receive values of parameters stored in the descriptor object.
            See cudnnSetLRNDescriptor for more details. Any of these pointers can be
            NULL (no value is returned for the corresponding parameter).</param>
            <param name="lrnK">Pointers to receive values of parameters stored in the descriptor object.
            See cudnnSetLRNDescriptor for more details. Any of these pointers can be
            NULL (no value is returned for the corresponding parameter).</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.LRNDescriptor.cudnnLRNCrossChannelForward(ManagedCuda.CudaDNN.cudnnLRNMode,System.Single,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Single,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function performs the forward LRN layer computation.
            </summary>
            <param name="lrnMode">LRN layer mode of operation. Currently only
            CUDNN_LRN_CROSS_CHANNEL_DIM1 is implemented. Normalization is
            performed along the tensor's dimA[1].</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="xDesc">Tensor descriptor objects for the input and output tensors.</param>
            <param name="x">Input tensor data pointer in device memory.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="yDesc">Tensor descriptor objects for the input and output tensors.</param>
            <param name="y">Output tensor data pointer in device memory.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.LRNDescriptor.cudnnLRNCrossChannelForward(ManagedCuda.CudaDNN.cudnnLRNMode,System.Double,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Double,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function performs the forward LRN layer computation.
            </summary>
            <param name="lrnMode">LRN layer mode of operation. Currently only
            CUDNN_LRN_CROSS_CHANNEL_DIM1 is implemented. Normalization is
            performed along the tensor's dimA[1].</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="xDesc">Tensor descriptor objects for the input and output tensors.</param>
            <param name="x">Input tensor data pointer in device memory.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="yDesc">Tensor descriptor objects for the input and output tensors.</param>
            <param name="y">Output tensor data pointer in device memory.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.LRNDescriptor.cudnnLRNCrossChannelBackward(ManagedCuda.CudaDNN.cudnnLRNMode,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function performs the backward LRN layer computation.
            </summary>
            <param name="lrnMode">LRN layer mode of operation. Currently only
            CUDNN_LRN_CROSS_CHANNEL_DIM1 is implemented. Normalization is
            performed along the tensor's dimA[1].</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="yDesc">Tensor descriptor and pointer in device memory for the bottom layer's
            data. (Bottom layer is the earlier layer in the computation graph during
            inference).</param>
            <param name="y">Tensor descriptor and pointer in device memory for the bottom layer's
            data. (Bottom layer is the earlier layer in the computation graph during
            inference).</param>
            <param name="dyDesc">Tensor descriptor and pointer in device memory for the top layer's
            cumulative loss differential data (error backpropagation). (Top layer is the
            later layer in the computation graph during inference).</param>
            <param name="dy">Tensor descriptor and pointer in device memory for the top layer's
            cumulative loss differential data (error backpropagation). (Top layer is the
            later layer in the computation graph during inference).</param>
            <param name="xDesc">Tensor descriptor and pointer in device memory for the bottom layer's
            data. (Bottom layer is the earlier layer in the computation graph
            during inference). Note that these values are not modified during
            backpropagation.</param>
            <param name="x">Tensor descriptor and pointer in device memory for the bottom layer's
            data. (Bottom layer is the earlier layer in the computation graph
            during inference). Note that these values are not modified during
            backpropagation.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="dxDesc">Tensor descriptor and pointer in device memory for the bottom layer's
            cumulative loss differential data (error backpropagation). (Bottom layer is
            the earlier layer in the computation graph during inference).</param>
            <param name="dx">Tensor descriptor and pointer in device memory for the bottom layer's
            cumulative loss differential data (error backpropagation). (Bottom layer is
            the earlier layer in the computation graph during inference).</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.LRNDescriptor.cudnnLRNCrossChannelBackward(ManagedCuda.CudaDNN.cudnnLRNMode,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function performs the backward LRN layer computation.
            </summary>
            <param name="lrnMode">LRN layer mode of operation. Currently only
            CUDNN_LRN_CROSS_CHANNEL_DIM1 is implemented. Normalization is
            performed along the tensor's dimA[1].</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="yDesc">Tensor descriptor and pointer in device memory for the bottom layer's
            data. (Bottom layer is the earlier layer in the computation graph during
            inference).</param>
            <param name="y">Tensor descriptor and pointer in device memory for the bottom layer's
            data. (Bottom layer is the earlier layer in the computation graph during
            inference).</param>
            <param name="dyDesc">Tensor descriptor and pointer in device memory for the top layer's
            cumulative loss differential data (error backpropagation). (Top layer is the
            later layer in the computation graph during inference).</param>
            <param name="dy">Tensor descriptor and pointer in device memory for the top layer's
            cumulative loss differential data (error backpropagation). (Top layer is the
            later layer in the computation graph during inference).</param>
            <param name="xDesc">Tensor descriptor and pointer in device memory for the bottom layer's
            data. (Bottom layer is the earlier layer in the computation graph
            during inference). Note that these values are not modified during
            backpropagation.</param>
            <param name="x">Tensor descriptor and pointer in device memory for the bottom layer's
            data. (Bottom layer is the earlier layer in the computation graph
            during inference). Note that these values are not modified during
            backpropagation.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="dxDesc">Tensor descriptor and pointer in device memory for the bottom layer's
            cumulative loss differential data (error backpropagation). (Bottom layer is
            the earlier layer in the computation graph during inference).</param>
            <param name="dx">Tensor descriptor and pointer in device memory for the bottom layer's
            cumulative loss differential data (error backpropagation). (Bottom layer is
            the earlier layer in the computation graph during inference).</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.LRNDescriptor.cudnnDivisiveNormalizationForward(ManagedCuda.CudaDNN.cudnnDivNormMode,System.Single,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,System.Single,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function performs the forward DivisiveNormalization layer computation.
            </summary>
            <param name="mode">DivisiveNormalization layer mode of operation. Currently only
            CUDNN_DIVNORM_PRECOMPUTED_MEANS is implemented. Normalization
            is performed using the means input tensor that is expected to be
            precomputed by the user.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="xDesc">Tensor descriptor objects for the input and output tensors. Note that
            srcDesc is shared between srcData, srcMeansData, tempData, tempData2
            tensors.</param>
            <param name="x">Input tensor data pointer in device memory.</param>
            <param name="means">Input means tensor data pointer in device memory. Note that this tensor
            can be NULL (in that case it's values are assumed to be zero during the
            computation). This tensor also doesn't have to contain means, these can
            be any values, a frequently used variation is a result of convolution with a
            normalized positive kernel (such as Gaussian).</param>
            <param name="temp">Temporary tensors in device memory. These are used for computing
            intermediate values during the forward pass. These tensors do not have
            to be preserved as inputs from forward to the backward pass. Both use
            srcDesc as a descriptor.</param>
            <param name="temp2">Temporary tensors in device memory. These are used for computing
            intermediate values during the forward pass. These tensors do not have
            to be preserved as inputs from forward to the backward pass. Both use
            srcDesc as a descriptor.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="yDesc">Tensor descriptor objects for the input and output tensors. Note that
            srcDesc is shared between srcData, srcMeansData, tempData, tempData2
            tensors.</param>
            <param name="y">Pointer in device memory to a tensor for the result of the forward DivisiveNormalization pass.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.LRNDescriptor.cudnnDivisiveNormalizationForward(ManagedCuda.CudaDNN.cudnnDivNormMode,System.Double,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,System.Double,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function performs the forward DivisiveNormalization layer computation.
            </summary>
            <param name="mode">DivisiveNormalization layer mode of operation. Currently only
            CUDNN_DIVNORM_PRECOMPUTED_MEANS is implemented. Normalization
            is performed using the means input tensor that is expected to be
            precomputed by the user.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="xDesc">Tensor descriptor objects for the input and output tensors. Note that
            srcDesc is shared between srcData, srcMeansData, tempData, tempData2
            tensors.</param>
            <param name="x">Input tensor data pointer in device memory.</param>
            <param name="means">Input means tensor data pointer in device memory. Note that this tensor
            can be NULL (in that case it's values are assumed to be zero during the
            computation). This tensor also doesn't have to contain means, these can
            be any values, a frequently used variation is a result of convolution with a
            normalized positive kernel (such as Gaussian).</param>
            <param name="temp">Temporary tensors in device memory. These are used for computing
            intermediate values during the forward pass. These tensors do not have
            to be preserved as inputs from forward to the backward pass. Both use
            srcDesc as a descriptor.</param>
            <param name="temp2">Temporary tensors in device memory. These are used for computing
            intermediate values during the forward pass. These tensors do not have
            to be preserved as inputs from forward to the backward pass. Both use
            srcDesc as a descriptor.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="yDesc">Tensor descriptor objects for the input and output tensors. Note that
            srcDesc is shared between srcData, srcMeansData, tempData, tempData2
            tensors.</param>
            <param name="y">Pointer in device memory to a tensor for the result of the forward DivisiveNormalization pass.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.LRNDescriptor.cudnnDivisiveNormalizationBackward(ManagedCuda.CudaDNN.cudnnDivNormMode,System.Single,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,System.Single,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function performs the backward DivisiveNormalization layer computation.
            </summary>
            <param name="mode">DivisiveNormalization layer mode of operation. Currently only
            CUDNN_DIVNORM_PRECOMPUTED_MEANS is implemented. Normalization
            is performed using the means input tensor that is expected to be
            precomputed by the user.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="xDesc">Tensor descriptor and pointers in device memory for the bottom layer's
            data and means. (Bottom layer is the earlier layer in the computation
            graph during inference). Note: the means tensor is expected to be
            precomputed by the user. It can also contain any valid values (not required
            to be actual means, and can be for instance a result of a convolution with
            a Gaussian kernel).</param>
            <param name="x">Tensor descriptor and pointers in device memory for the bottom layer's
            data and means. (Bottom layer is the earlier layer in the computation
            graph during inference). Note: the means tensor is expected to be
            precomputed by the user. It can also contain any valid values (not required
            to be actual means, and can be for instance a result of a convolution with
            a Gaussian kernel).</param>
            <param name="means">Tensor descriptor and pointers in device memory for the bottom layer's
            data and means. (Bottom layer is the earlier layer in the computation
            graph during inference). Note: the means tensor is expected to be
            precomputed by the user. It can also contain any valid values (not required
            to be actual means, and can be for instance a result of a convolution with
            a Gaussian kernel).</param>
            <param name="dy">Tensor pointer in device memory for the top layer's cumulative loss
            differential data (error backpropagation). (Top layer is the later layer in
            the computation graph during inference).</param>
            <param name="temp">Temporary tensors in device memory. These are used for computing
            intermediate values during the backward pass. These tensors do not have
            to be preserved from forward to backward pass. Both use srcDesc as a
            descriptor.</param>
            <param name="temp2">Temporary tensors in device memory. These are used for computing
            intermediate values during the backward pass. These tensors do not have
            to be preserved from forward to backward pass. Both use srcDesc as a
            descriptor.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="dXdMeansDesc">Tensor descriptor for destDataDiff and destMeansDiff.</param>
            <param name="dx">Tensor pointers (in device memory) for the bottom layer's resulting
            differentials (data and means). Both share the same descriptor.</param>
            <param name="dMeans">Tensor pointers (in device memory) for the bottom layer's resulting
            differentials (data and means). Both share the same descriptor.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.LRNDescriptor.cudnnDivisiveNormalizationBackward(ManagedCuda.CudaDNN.cudnnDivNormMode,System.Double,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,System.Double,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr)">
            <summary>
            This function performs the backward DivisiveNormalization layer computation.
            </summary>
            <param name="mode">DivisiveNormalization layer mode of operation. Currently only
            CUDNN_DIVNORM_PRECOMPUTED_MEANS is implemented. Normalization
            is performed using the means input tensor that is expected to be
            precomputed by the user.</param>
            <param name="alpha">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="xDesc">Tensor descriptor and pointers in device memory for the bottom layer's
            data and means. (Bottom layer is the earlier layer in the computation
            graph during inference). Note: the means tensor is expected to be
            precomputed by the user. It can also contain any valid values (not required
            to be actual means, and can be for instance a result of a convolution with
            a Gaussian kernel).</param>
            <param name="x">Tensor descriptor and pointers in device memory for the bottom layer's
            data and means. (Bottom layer is the earlier layer in the computation
            graph during inference). Note: the means tensor is expected to be
            precomputed by the user. It can also contain any valid values (not required
            to be actual means, and can be for instance a result of a convolution with
            a Gaussian kernel).</param>
            <param name="means">Tensor descriptor and pointers in device memory for the bottom layer's
            data and means. (Bottom layer is the earlier layer in the computation
            graph during inference). Note: the means tensor is expected to be
            precomputed by the user. It can also contain any valid values (not required
            to be actual means, and can be for instance a result of a convolution with
            a Gaussian kernel).</param>
            <param name="dy">Tensor pointer in device memory for the top layer's cumulative loss
            differential data (error backpropagation). (Top layer is the later layer in
            the computation graph during inference).</param>
            <param name="temp">Temporary tensors in device memory. These are used for computing
            intermediate values during the backward pass. These tensors do not have
            to be preserved from forward to backward pass. Both use srcDesc as a
            descriptor.</param>
            <param name="temp2">Temporary tensors in device memory. These are used for computing
            intermediate values during the backward pass. These tensors do not have
            to be preserved from forward to backward pass. Both use srcDesc as a
            descriptor.</param>
            <param name="beta">Pointer to scaling factors (in host memory) used to blend the layer output
            value with prior value in the destination tensor as follows: dstValue =
            alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
            for additional details.</param>
            <param name="dXdMeansDesc">Tensor descriptor for destDataDiff and destMeansDiff.</param>
            <param name="dx">Tensor pointers (in device memory) for the bottom layer's resulting
            differentials (data and means). Both share the same descriptor.</param>
            <param name="dMeans">Tensor pointers (in device memory) for the bottom layer's resulting
            differentials (data and means). Both share the same descriptor.</param>
        </member>
        <member name="T:ManagedCuda.CudaDNN.OpTensorDescriptor">
            <summary>
            An opaque structure holding the
            description of a generic n-D dataset.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.OpTensorDescriptor.#ctor(ManagedCuda.CudaDNN.CudaDNNContext)">
            <summary>
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.OpTensorDescriptor.Finalize">
            <summary>
            For dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.OpTensorDescriptor.Dispose">
            <summary>
            Dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.OpTensorDescriptor.Dispose(System.Boolean)">
            <summary>
            For IDisposable
            </summary>
            <param name="fDisposing"></param>
        </member>
        <member name="P:ManagedCuda.CudaDNN.OpTensorDescriptor.Desc">
            <summary>
            Returns the inner handle.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.OpTensorDescriptor.SetOpTensorDescriptor(ManagedCuda.CudaDNN.cudnnOpTensorOp,ManagedCuda.CudaDNN.cudnnDataType,ManagedCuda.CudaDNN.cudnnNanPropagation)">
            <summary>
            
            </summary>
            <param name="opTensorOp"></param>
            <param name="opTensorCompType"></param>
            <param name="opTensorNanOpt"></param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.OpTensorDescriptor.GetOpTensorDescriptor(ManagedCuda.CudaDNN.cudnnOpTensorOp@,ManagedCuda.CudaDNN.cudnnDataType@,ManagedCuda.CudaDNN.cudnnNanPropagation@)">
            <summary>
            
            </summary>
            <param name="opTensorOp"></param>
            <param name="opTensorCompType"></param>
            <param name="opTensorNanOpt"></param>
        </member>
        <member name="T:ManagedCuda.CudaDNN.PersistentRNNPlan">
            <summary>
            PersistentRNNPlan is a pointer to an opaque structure holding a plan to
            execute a dynamic persistent RNN. cudnnCreatePersistentRNNPlan() is used to
            create and initialize one instance.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.PersistentRNNPlan.#ctor(ManagedCuda.CudaDNN.RNNDescriptor,System.Int32,ManagedCuda.CudaDNN.cudnnDataType)">
            <summary>
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.PersistentRNNPlan.Finalize">
            <summary>
            For dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.PersistentRNNPlan.Dispose">
            <summary>
            Dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.PersistentRNNPlan.Dispose(System.Boolean)">
            <summary>
            For IDisposable
            </summary>
            <param name="fDisposing"></param>
        </member>
        <member name="P:ManagedCuda.CudaDNN.PersistentRNNPlan.Plan">
            <summary>
            Returns the inner handle.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.PoolingDescriptor">
            <summary>
            An opaque structure holding
            the description of a pooling operation.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.PoolingDescriptor.#ctor">
            <summary>
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.PoolingDescriptor.Finalize">
            <summary>
            For dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.PoolingDescriptor.Dispose">
            <summary>
            Dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.PoolingDescriptor.Dispose(System.Boolean)">
            <summary>
            For IDisposable
            </summary>
            <param name="fDisposing"></param>
        </member>
        <member name="P:ManagedCuda.CudaDNN.PoolingDescriptor.Desc">
            <summary>
            Returns the inner handle.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.PoolingDescriptor.SetPooling2dDescriptor(ManagedCuda.CudaDNN.cudnnPoolingMode,ManagedCuda.CudaDNN.cudnnNanPropagation,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            This function initializes a previously created generic pooling descriptor object into a 2D description.
            </summary>
            <param name="mode">Enumerant to specify the pooling mode.</param>
            <param name="maxpoolingNanOpt">Nan propagation option for max pooling.</param>
            <param name="windowHeight">Height of the pooling window.</param>
            <param name="windowWidth">Width of the pooling window.</param>
            <param name="verticalPadding">Size of vertical padding.</param>
            <param name="horizontalPadding">Size of horizontal padding</param>
            <param name="verticalStride">Pooling vertical stride.</param>
            <param name="horizontalStride">Pooling horizontal stride.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.PoolingDescriptor.GetPooling2dDescriptor(ManagedCuda.CudaDNN.cudnnPoolingMode@,ManagedCuda.CudaDNN.cudnnNanPropagation@,System.Int32@,System.Int32@,System.Int32@,System.Int32@,System.Int32@,System.Int32@)">
            <summary>
            This function queries a previously created 2D pooling descriptor object.
            </summary>
            <param name="mode">Enumerant to specify the pooling mode.</param>
            <param name="maxpoolingNanOpt">Nan propagation option for max pooling.</param>
            <param name="windowHeight">Height of the pooling window.</param>
            <param name="windowWidth">Width of the pooling window.</param>
            <param name="verticalPadding">Size of vertical padding.</param>
            <param name="horizontalPadding">Size of horizontal padding.</param>
            <param name="verticalStride">Pooling vertical stride.</param>
            <param name="horizontalStride">Pooling horizontal stride.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.PoolingDescriptor.SetPoolingNdDescriptor(ManagedCuda.CudaDNN.cudnnPoolingMode,ManagedCuda.CudaDNN.cudnnNanPropagation,System.Int32,System.Int32[],System.Int32[],System.Int32[])">
            <summary>
            This function initializes a previously created generic pooling descriptor object.
            </summary>
            <param name="mode">Enumerant to specify the pooling mode.</param>
            <param name="maxpoolingNanOpt">Nan propagation option for max pooling.</param>
            <param name="nbDims">Dimension of the pooling operation.</param>
            <param name="windowDimA">Array of dimension nbDims containing the window size for each dimension.</param>
            <param name="paddingA">Array of dimension nbDims containing the padding size for each dimension.</param>
            <param name="strideA">Array of dimension nbDims containing the striding size for each dimension.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.PoolingDescriptor.GetPoolingNdDescriptor(System.Int32,ManagedCuda.CudaDNN.cudnnPoolingMode@,ManagedCuda.CudaDNN.cudnnNanPropagation@,System.Int32@,System.Int32[],System.Int32[],System.Int32[])">
            <summary>
            This function queries a previously initialized generic pooling descriptor object.
            </summary>
            <param name="nbDimsRequested">Dimension of the expected pooling descriptor. It is also the minimum
            size of the arrays windowDimA, paddingA and strideA in order to be
            able to hold the results</param>
            <param name="mode">Enumerant to specify the pooling mode.</param>
            <param name="maxpoolingNanOpt">Nan propagation option for max pooling.</param>
            <param name="nbDims">Actual dimension of the pooling descriptor.</param>
            <param name="windowDimA">Array of dimension of at least nbDimsRequested that will be filled with
            the window parameters from the provided pooling descriptor.</param>
            <param name="paddingA">Array of dimension of at least nbDimsRequested that will be filled with
            the padding parameters from the provided pooling descriptor.</param>
            <param name="strideA">Array of dimension at least nbDimsRequested that will be filled with
            the stride parameters from the provided pooling descriptor.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.PoolingDescriptor.GetPoolingNdForwardOutputDim(ManagedCuda.CudaDNN.TensorDescriptor,System.Int32,System.Int32[])">
            <summary>
            This function provides the output dimensions of a tensor after Nd pooling has been applied
            </summary>
            <param name="inputTensorDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="nbDims">Number of dimensions in which pooling is to be applied.</param>
            <param name="outputTensorDimA">Array of nbDims output dimensions</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.PoolingDescriptor.GetPooling2dForwardOutputDim(ManagedCuda.CudaDNN.TensorDescriptor,System.Int32@,System.Int32@,System.Int32@,System.Int32@)">
            <summary>
            This function provides the output dimensions of a tensor after 2d pooling has been applied
            </summary>
            <param name="inputTensorDesc">Handle to the previously initialized input tensor descriptor.</param>
            <param name="n">Number of images in the output</param>
            <param name="c">Number of channels in the output</param>
            <param name="h">Height of images in the output</param>
            <param name="w">Width of images in the output</param>
        </member>
        <member name="T:ManagedCuda.CudaDNN.ReduceTensorDescriptor">
            <summary>
            ReduceTensorDescriptor is a pointer to an opaque structure
            holding the description of a tensor reduction operation, used as a parameter to
            cudnnReduceTensor(). cudnnCreateReduceTensorDescriptor() is used to create
            one instance, and cudnnSetReduceTensorDescriptor() must be used to initialize this instance.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.ReduceTensorDescriptor.#ctor">
            <summary>
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.ReduceTensorDescriptor.Finalize">
            <summary>
            For dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.ReduceTensorDescriptor.Dispose">
            <summary>
            Dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.ReduceTensorDescriptor.Dispose(System.Boolean)">
            <summary>
            For IDisposable
            </summary>
            <param name="fDisposing"></param>
        </member>
        <member name="P:ManagedCuda.CudaDNN.ReduceTensorDescriptor.Desc">
            <summary>
            Returns the inner handle.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.ReduceTensorDescriptor.SetReduceTensorDescriptor(ManagedCuda.CudaDNN.cudnnReduceTensorOp,ManagedCuda.CudaDNN.cudnnDataType,ManagedCuda.CudaDNN.cudnnNanPropagation,ManagedCuda.CudaDNN.cudnnReduceTensorIndices,ManagedCuda.CudaDNN.cudnnIndicesType)">
            <summary>
            
            </summary>
            <param name="reduceTensorOp"></param>
            <param name="reduceTensorCompType"></param>
            <param name="reduceTensorNanOpt"></param>
            <param name="reduceTensorIndices"></param>
            <param name="reduceTensorIndicesType"></param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.ReduceTensorDescriptor.GetReduceTensorDescriptor(ManagedCuda.CudaDNN.cudnnReduceTensorOp@,ManagedCuda.CudaDNN.cudnnDataType@,ManagedCuda.CudaDNN.cudnnNanPropagation@,ManagedCuda.CudaDNN.cudnnReduceTensorIndices@,ManagedCuda.CudaDNN.cudnnIndicesType@)">
            <summary>
            
            </summary>
            <param name="reduceTensorOp"></param>
            <param name="reduceTensorCompType"></param>
            <param name="reduceTensorNanOpt"></param>
            <param name="reduceTensorIndices"></param>
            <param name="reduceTensorIndicesType"></param>
        </member>
        <member name="T:ManagedCuda.CudaDNN.RNNDescriptor">
            <summary>
            
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.RNNDescriptor.#ctor(ManagedCuda.CudaDNN.CudaDNNContext)">
            <summary>
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.RNNDescriptor.Finalize">
            <summary>
            For dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.RNNDescriptor.Dispose">
            <summary>
            Dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.RNNDescriptor.Dispose(System.Boolean)">
            <summary>
            For IDisposable
            </summary>
            <param name="fDisposing"></param>
        </member>
        <member name="P:ManagedCuda.CudaDNN.RNNDescriptor.Desc">
            <summary>
            Returns the inner handle.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.RNNDescriptor.SetRNNDescriptor(ManagedCuda.CudaDNN.CudaDNNContext,System.Int32,System.Int32,ManagedCuda.CudaDNN.DropoutDescriptor,ManagedCuda.CudaDNN.cudnnRNNInputMode,ManagedCuda.CudaDNN.cudnnDirectionMode,ManagedCuda.CudaDNN.cudnnRNNMode,ManagedCuda.CudaDNN.cudnnRNNAlgo,ManagedCuda.CudaDNN.cudnnDataType)">
            <summary>
            This function initializes a previously created RNN descriptor object.
            </summary>
            <param name="ctx">Handle to a previously created cuDNN library descriptor.</param>
            <param name="hiddenSize">Size of the internal hidden state for each layer.</param>
            <param name="numLayers">Number of layers.</param>
            <param name="dropoutDesc">Handle to a previously created and initialized dropout descriptor.</param>
            <param name="inputMode">Specifies the behavior at the input to the first layer.</param>
            <param name="direction">Specifies the recurrence pattern. (eg. bidirectional)</param>
            <param name="mode">The type of RNN to compute.</param>
            <param name="algo">Specifies which RNN algorithm should be used to compute the results.</param>
            <param name="dataType">Math precision.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.RNNDescriptor.GetRNNWorkspaceSize(System.Int32,ManagedCuda.CudaDNN.TensorDescriptor[],ManagedCuda.BasicTypes.SizeT@)">
            <summary>
            This function is used to query the amount of work space required to execute the RNN 
            described by rnnDesc with inputs dimensions defined by xDesc. 
            </summary>
            <param name="seqLength">Number of iterations to unroll over.</param>
            <param name="xDesc">An array of tensor descriptors describing the input to each recurrent iteration.</param>
            <param name="sizeInBytes">Minimum amount of GPU memory needed as workspace to be able to execute an RNN with the specified descriptor and input tensors.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.RNNDescriptor.GetRNNTrainingReserveSize(System.Int32,ManagedCuda.CudaDNN.TensorDescriptor[],ManagedCuda.BasicTypes.SizeT@)">
            <summary>
            This function is used to query the amount of reserved space required for training the 
            RNN described by rnnDesc with inputs dimensions defined by xDesc. The same reserve 
            space must be passed to cudnnRNNForwardTraining, cudnnRNNBackwardData and cudnnRNNBackwardWeights.
            </summary>
            <param name="seqLength">Number of iterations to unroll over.</param>
            <param name="xDesc">An array of tensor descriptors describing the input to each recurrent iteration.</param>
            <param name="sizeInBytes">Minimum amount of GPU memory needed as reserve space to be able to train an RNN with the specified descriptor and input tensors.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.RNNDescriptor.cudnnGetRNNParamsSize(ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.BasicTypes.SizeT@,ManagedCuda.CudaDNN.cudnnDataType)">
            <summary>
            This function is used to query the amount of parameter space required to execute the RNN described by 
            rnnDesc with inputs dimensions defined by xDesc. 
            </summary>
            <param name="xDesc">A fully packed tensor descriptor describing the input to one recurrent iteration.</param>
            <param name="sizeInBytes">Minimum amount of GPU memory needed as parameter space to be able to execute an RNN with the specified descriptor and input tensors.</param>
            <param name="dataType">The data type of the parameters.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.RNNDescriptor.GetRNNLinLayerMatrixParams(System.Int32,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},System.Int32,ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDeviceVariable{ManagedCuda.BasicTypes.SizeT})">
            <summary>
            This function is used to obtain a pointer and descriptor for the matrix parameters in layer within 
            the RNN described by rnnDesc with inputs dimensions defined by xDesc. 
            </summary>
            <param name="layer">The layer to query.</param>
            <param name="xDesc">A fully packed tensor descriptor describing the input to one recurrent iteration.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor describing the weights for the RNN.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor wDesc.</param>
            <param name="linLayerID">
            The linear layer to obtain information about: 
            * If mode in rnnDesc was set to CUDNN_RNN_RELU or CUDNN_RNN_TANH a value of 0 references the matrix multiplication 
            applied to the input from the previous layer, a value of 1 references the matrix multiplication applied to the recurrent input.
            * If mode in rnnDesc was set to CUDNN_LSTM values of 0-3 reference matrix multiplications applied to the input from the 
            previous layer, value of 4-7 reference matrix multiplications applied to the recurrent input.
                 Values 0 and 4 reference the input gate. 
                 Values 1 and 5 reference the forget gate. 
                 Values 2 and 6 reference the new memory gate. 
                 Values 3 and 7 reference the output gate.
            * If mode in rnnDesc was set to CUDNN_GRU values of 0-2 reference matrix multiplications applied to the input 
            from the previous layer, value of 3-5 reference matrix multiplications applied to the recurrent input. 
                 Values 0 and 3 reference the reset gate. 
                 Values 1 and 4 reference the update gate. 
                 Values 2 and 5 reference the new memory gate.
            </param>
            <param name="linLayerMatDesc">Handle to a previously created filter descriptor.</param>
            <param name="linLayerMat">Data pointer to GPU memory associated with the filter descriptor linLayerMatDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.RNNDescriptor.GetRNNLinLayerMatrixParams(System.Int32,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},System.Int32,ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDeviceVariable{ManagedCuda.BasicTypes.SizeT})">
            <summary>
            This function is used to obtain a pointer and descriptor for the matrix parameters in layer within 
            the RNN described by rnnDesc with inputs dimensions defined by xDesc. 
            </summary>
            <param name="layer">The layer to query.</param>
            <param name="xDesc">A fully packed tensor descriptor describing the input to one recurrent iteration.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor describing the weights for the RNN.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor wDesc.</param>
            <param name="linLayerID">
            The linear layer to obtain information about: 
            * If mode in rnnDesc was set to CUDNN_RNN_RELU or CUDNN_RNN_TANH a value of 0 references the matrix multiplication 
            applied to the input from the previous layer, a value of 1 references the matrix multiplication applied to the recurrent input.
            * If mode in rnnDesc was set to CUDNN_LSTM values of 0-3 reference matrix multiplications applied to the input from the 
            previous layer, value of 4-7 reference matrix multiplications applied to the recurrent input.
                 Values 0 and 4 reference the input gate. 
                 Values 1 and 5 reference the forget gate. 
                 Values 2 and 6 reference the new memory gate. 
                 Values 3 and 7 reference the output gate.
            * If mode in rnnDesc was set to CUDNN_GRU values of 0-2 reference matrix multiplications applied to the input 
            from the previous layer, value of 3-5 reference matrix multiplications applied to the recurrent input. 
                 Values 0 and 3 reference the reset gate. 
                 Values 1 and 4 reference the update gate. 
                 Values 2 and 5 reference the new memory gate.
            </param>
            <param name="linLayerMatDesc">Handle to a previously created filter descriptor.</param>
            <param name="linLayerMat">Data pointer to GPU memory associated with the filter descriptor linLayerMatDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.RNNDescriptor.GetRNNLinLayerBiasParams(System.Int32,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},System.Int32,ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDeviceVariable{ManagedCuda.BasicTypes.SizeT})">
            <summary>
            This function is used to obtain a pointer and descriptor for the bias parameters 
            in layer within the RNN described by rnnDesc with inputs dimensions defined by xDesc. 
            </summary>
            <param name="layer">The layer to query.</param>
            <param name="xDesc">A fully packed tensor descriptor describing the input to one recurrent iteration.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor describing the weights for the RNN.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor wDesc.</param>
            <param name="linLayerID">
            The linear layer to obtain information about: 
            * If mode in rnnDesc was set to CUDNN_RNN_RELU or CUDNN_RNN_TANH a value of 0 references 
            the bias applied to the input from the previous layer, a value of 1 references the bias 
            applied to the recurrent input.
            * If mode in rnnDesc was set to CUDNN_LSTM values of 0, 1, 2 and 3 reference bias applied to the input 
            from the previous layer, value of 4, 5, 6 and 7 reference bias applied to the recurrent input.
                 Values 0 and 4 reference the input gate. 
                 Values 1 and 5 reference the forget gate. 
                 Values 2 and 6 reference the new memory gate. 
                 Values 3 and 7 reference the output gate.
            * If mode in rnnDesc was set to CUDNN_GRU values of 0, 1 and 2 reference bias applied to the 
            input from the previous layer, value of 3, 4 and 5 reference bias applied to the recurrent input.
                 Values 0 and 3 reference the reset gate. 
                 Values 1 and 4 reference the update gate. 
                 Values 2 and 5 reference the new memory gate.</param>
            <param name="linLayerBiasDesc">Handle to a previously created filter descriptor.</param>
            <param name="linLayerBias">Data pointer to GPU memory associated with the filter descriptor linLayerMatDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.RNNDescriptor.GetRNNLinLayerBiasParams(System.Int32,ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},System.Int32,ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDeviceVariable{ManagedCuda.BasicTypes.SizeT})">
            <summary>
            This function is used to obtain a pointer and descriptor for the bias parameters 
            in layer within the RNN described by rnnDesc with inputs dimensions defined by xDesc. 
            </summary>
            <param name="layer">The layer to query.</param>
            <param name="xDesc">A fully packed tensor descriptor describing the input to one recurrent iteration.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor describing the weights for the RNN.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor wDesc.</param>
            <param name="linLayerID">
            The linear layer to obtain information about: 
            * If mode in rnnDesc was set to CUDNN_RNN_RELU or CUDNN_RNN_TANH a value of 0 references 
            the bias applied to the input from the previous layer, a value of 1 references the bias 
            applied to the recurrent input.
            * If mode in rnnDesc was set to CUDNN_LSTM values of 0, 1, 2 and 3 reference bias applied to the input 
            from the previous layer, value of 4, 5, 6 and 7 reference bias applied to the recurrent input.
                 Values 0 and 4 reference the input gate. 
                 Values 1 and 5 reference the forget gate. 
                 Values 2 and 6 reference the new memory gate. 
                 Values 3 and 7 reference the output gate.
            * If mode in rnnDesc was set to CUDNN_GRU values of 0, 1 and 2 reference bias applied to the 
            input from the previous layer, value of 3, 4 and 5 reference bias applied to the recurrent input.
                 Values 0 and 3 reference the reset gate. 
                 Values 1 and 4 reference the update gate. 
                 Values 2 and 5 reference the new memory gate.</param>
            <param name="linLayerBiasDesc">Handle to a previously created filter descriptor.</param>
            <param name="linLayerBias">Data pointer to GPU memory associated with the filter descriptor linLayerMatDesc.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.RNNDescriptor.RNNForwardInference(ManagedCuda.CudaDNN.TensorDescriptor[],ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor[],ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDeviceVariable{System.Byte},ManagedCuda.BasicTypes.SizeT)">
            <summary>
            This routine executes the recurrent neural network described by rnnDesc with inputs x, hx, cx, weights w and 
            outputs y, hy, cy. workspace is required for intermediate storage. This function does not store data required 
            for training; cudnnRNNForwardTraining should be used for that purpose. 
            </summary>
            <param name="xDesc">An array of tensor descriptors describing the input to each recurrent iteration. 
            Each tensor descriptor must have the same first dimension. The second dimension of the tensors may 
            decrease from element n to element n+1 but may not increase. The tensor must be fully packed.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptors in the array xDesc. 
            The data are expected to be packed contiguously with the first element of iteration n+1 following 
            directly from the last element of iteration n.</param>
            <param name="hxDesc">Handle to a previously initialized tensor descriptor describing the initial hidden 
            state of the RNN. The first dimension of the tensor must match the hiddenSize argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second 
            dimension of the first tensor described in xDesc. The third dimension must match the numLayers 
            argument passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be 
            fully packed.</param>
            <param name="hx">Data pointer to GPU memory associated with the tensor descriptor hxDesc. If a NULL pointer 
            is passed, the initial hidden state of the network will be initialized to zero.</param>
            <param name="cxDesc">Handle to a previously initialized tensor descriptor describing the initial cell 
            state for LSTM networks. The first dimension of the tensor must match the hiddenSize argument passed to 
            the cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second 
            dimension of the first tensor described in xDesc. The third dimension must match the numLayers argument 
            passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="cx">Data pointer to GPU memory associated with the tensor descriptor cxDesc. If a NULL 
            pointer is passed, the initial cell state of the network will be initialized to zero.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor describing the weights for the RNN.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor wDesc.</param>
            <param name="yDesc">An array of tensor descriptors describing the output from each recurrent iteration. 
            The first dimension of the tensor depends on the direction argument passed to the cudnnSetRNNDescriptor 
            call used to initialize rnnDesc:
            * If direction is CUDNN_UNIDIRECTIONAL the first dimension should match the hiddenSize 
            argument passed to cudnnSetRNNDescriptor.
            * If direction is CUDNN_BIDIRECTIONAL the first dimension should match double the hiddenSize 
            argument passed to cudnnSetRNNDescriptor.
            The second dimension of the tensor n must match the second dimension of the tensor n in xDesc. 
            The tensor must be fully packed.</param>
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor yDesc. The data 
            are expected to be packed contiguously with the first element of iteration n+1 following directly 
            from the last element of iteration n.</param>
            <param name="hyDesc">Handle to a previously initialized tensor descriptor describing the final hidden 
            state of the RNN. The first dimension of the tensor must match the hiddenSize argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second 
            dimension of the first tensor described in xDesc. The third dimension must match the numLayers 
            argument passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be 
            fully packed.</param>
            <param name="hy">Data pointer to GPU memory associated with the tensor descriptor hyDesc. If a NULL 
            pointer is passed, the final hidden state of the network will not be saved.</param>
            <param name="cyDesc">Handle to a previously initialized tensor descriptor describing the final cell 
            state for LSTM networks. The first dimension of the tensor must match the hiddenSize argument passed 
            to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second 
            dimension of the first tensor described in xDesc. The third dimension must match the numLayers argument 
            passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="cy">Data pointer to GPU memory associated with the tensor descriptor cyDesc. If 
            a NULL pointer is passed, the final cell state of the network will be not be saved.</param>
            <param name="workspace">Data pointer to GPU memory to be used as a workspace for this call.</param>
            <param name="workSpaceSizeInBytes">Specifies the size in bytes of the provided workspace.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.RNNDescriptor.RNNForwardInference(ManagedCuda.CudaDNN.TensorDescriptor[],ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor[],ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDeviceVariable{System.Byte},ManagedCuda.BasicTypes.SizeT)">
            <summary>
            This routine executes the recurrent neural network described by rnnDesc with inputs x, hx, cx, weights w and 
            outputs y, hy, cy. workspace is required for intermediate storage. This function does not store data required 
            for training; cudnnRNNForwardTraining should be used for that purpose. 
            </summary>
            <param name="xDesc">An array of tensor descriptors describing the input to each recurrent iteration. 
            Each tensor descriptor must have the same first dimension. The second dimension of the tensors may 
            decrease from element n to element n+1 but may not increase. The tensor must be fully packed.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptors in the array xDesc. 
            The data are expected to be packed contiguously with the first element of iteration n+1 following 
            directly from the last element of iteration n.</param>
            <param name="hxDesc">Handle to a previously initialized tensor descriptor describing the initial hidden 
            state of the RNN. The first dimension of the tensor must match the hiddenSize argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second 
            dimension of the first tensor described in xDesc. The third dimension must match the numLayers 
            argument passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be 
            fully packed.</param>
            <param name="hx">Data pointer to GPU memory associated with the tensor descriptor hxDesc. If a NULL pointer 
            is passed, the initial hidden state of the network will be initialized to zero.</param>
            <param name="cxDesc">Handle to a previously initialized tensor descriptor describing the initial cell 
            state for LSTM networks. The first dimension of the tensor must match the hiddenSize argument passed to 
            the cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second 
            dimension of the first tensor described in xDesc. The third dimension must match the numLayers argument 
            passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="cx">Data pointer to GPU memory associated with the tensor descriptor cxDesc. If a NULL 
            pointer is passed, the initial cell state of the network will be initialized to zero.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor describing the weights for the RNN.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor wDesc.</param>
            <param name="yDesc">An array of tensor descriptors describing the output from each recurrent iteration. 
            The first dimension of the tensor depends on the direction argument passed to the cudnnSetRNNDescriptor 
            call used to initialize rnnDesc:
            * If direction is CUDNN_UNIDIRECTIONAL the first dimension should match the hiddenSize 
            argument passed to cudnnSetRNNDescriptor.
            * If direction is CUDNN_BIDIRECTIONAL the first dimension should match double the hiddenSize 
            argument passed to cudnnSetRNNDescriptor.
            The second dimension of the tensor n must match the second dimension of the tensor n in xDesc. 
            The tensor must be fully packed.</param>
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor yDesc. The data 
            are expected to be packed contiguously with the first element of iteration n+1 following directly 
            from the last element of iteration n.</param>
            <param name="hyDesc">Handle to a previously initialized tensor descriptor describing the final hidden 
            state of the RNN. The first dimension of the tensor must match the hiddenSize argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second 
            dimension of the first tensor described in xDesc. The third dimension must match the numLayers 
            argument passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be 
            fully packed.</param>
            <param name="hy">Data pointer to GPU memory associated with the tensor descriptor hyDesc. If a NULL 
            pointer is passed, the final hidden state of the network will not be saved.</param>
            <param name="cyDesc">Handle to a previously initialized tensor descriptor describing the final cell 
            state for LSTM networks. The first dimension of the tensor must match the hiddenSize argument passed 
            to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second 
            dimension of the first tensor described in xDesc. The third dimension must match the numLayers argument 
            passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="cy">Data pointer to GPU memory associated with the tensor descriptor cyDesc. If 
            a NULL pointer is passed, the final cell state of the network will be not be saved.</param>
            <param name="workspace">Data pointer to GPU memory to be used as a workspace for this call.</param>
            <param name="workSpaceSizeInBytes">Specifies the size in bytes of the provided workspace.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.RNNDescriptor.RNNForwardTraining(ManagedCuda.CudaDNN.TensorDescriptor[],ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor[],ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDeviceVariable{System.Byte},ManagedCuda.BasicTypes.SizeT,ManagedCuda.CudaDeviceVariable{System.Byte},ManagedCuda.BasicTypes.SizeT)">
            <summary>
            This routine executes the recurrent neural network described by rnnDesc with inputs x, hx, cx, weights w 
            and outputs y, hy, cy. workspace is required for intermediate storage. reserveSpace stores data required 
            for training. The same reserveSpace data must be used for future calls to cudnnRNNBackwardData and 
            cudnnRNNBackwardWeights if these execute on the same input data. 
            </summary>
            <param name="xDesc">An array of tensor descriptors describing the input to each recurrent iteration. Each 
            tensor descriptor must have the same first dimension. The second dimension of the tensors may decrease 
            from element n to element n+1 but may not increase. The tensor must be fully packed.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptors in the array xDesc.</param>
            <param name="hxDesc">Handle to a previously initialized tensor descriptor describing the initial hidden state 
            of the RNN. The first dimension of the tensor must match the hiddenSize argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second 
            dimension of the first tensor described in xDesc. The third dimension must match the numLayers argument 
            passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="hx">Data pointer to GPU memory associated with the tensor descriptor hxDesc. If a NULL pointer 
            is passed, the initial hidden state of the network will be initialized to zero.</param>
            <param name="cxDesc">Handle to a previously initialized tensor descriptor describing the initial 
            cell state for LSTM networks. The first dimension of the tensor must match the hiddenSize argument 
            passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match 
            the second dimension of the first tensor described in xDesc. The third dimension must match the numLayers 
            argument passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully 
            packed.</param>
            <param name="cx">Data pointer to GPU memory associated with the tensor descriptor cxDesc. If a NULL pointer is 
            passed, the initial cell state of the network will be initialized to zero.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor describing the weights for the RNN.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor wDesc.</param>
            <param name="yDesc">An array of tensor descriptors describing the output from each recurrent iteration. The first 
            dimension of the tensor depends on the direction argument passed to the cudnnSetRNNDescriptor 
            call used to initialize rnnDesc: 
            * If direction is CUDNN_UNIDIRECTIONAL the first dimension should match the hiddenSize 
            argument passed to cudnnSetRNNDescriptor.
            * If direction is CUDNN_BIDIRECTIONAL the first dimension should match double the hiddenSize 
            argument passed to cudnnSetRNNDescriptor.
            The second dimension of the tensor n must match the second dimension of the tensor 
            n in xDesc. The tensor must be fully packed.</param>
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor yDesc.</param>
            <param name="hyDesc">Handle to a previously initialized tensor descriptor describing the final 
            hidden state of the RNN. The first dimension of the tensor must match the hiddenSize argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second dimension 
            of the first tensor described in xDesc. The third dimension must match the numLayers argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="hy">Data pointer to GPU memory associated with the tensor descriptor hyDesc. If a 
            NULL pointer is passed, the final hidden state of the network will not be saved.</param>
            <param name="cyDesc">Handle to a previously initialized tensor descriptor describing the final cell state 
            for LSTM networks. The first dimension of the tensor must match the hiddenSize argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second dimension 
            of the first tensor described in xDesc. The third dimension must match the numLayers argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="cy">Data pointer to GPU memory associated with the tensor descriptor cyDesc. If a NULL pointer is 
            passed, the final cell state of the network will be not be saved.</param>
            <param name="workspace">Data pointer to GPU memory to be used as a workspace for this call.</param>
            <param name="workSpaceSizeInBytes">Specifies the size in bytes of the provided workspace.</param>
            <param name="reserveSpace">Data pointer to GPU memory to be used as a reserve space for this call.</param>
            <param name="reserveSpaceSizeInBytes">Specifies the size in bytes of the provided reserveSpace.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.RNNDescriptor.RNNForwardTraining(ManagedCuda.CudaDNN.TensorDescriptor[],ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor[],ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDeviceVariable{System.Byte},ManagedCuda.BasicTypes.SizeT,ManagedCuda.CudaDeviceVariable{System.Byte},ManagedCuda.BasicTypes.SizeT)">
            <summary>
            This routine executes the recurrent neural network described by rnnDesc with inputs x, hx, cx, weights w 
            and outputs y, hy, cy. workspace is required for intermediate storage. reserveSpace stores data required 
            for training. The same reserveSpace data must be used for future calls to cudnnRNNBackwardData and 
            cudnnRNNBackwardWeights if these execute on the same input data. 
            </summary>
            <param name="xDesc">An array of tensor descriptors describing the input to each recurrent iteration. Each 
            tensor descriptor must have the same first dimension. The second dimension of the tensors may decrease 
            from element n to element n+1 but may not increase. The tensor must be fully packed.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptors in the array xDesc.</param>
            <param name="hxDesc">Handle to a previously initialized tensor descriptor describing the initial hidden state 
            of the RNN. The first dimension of the tensor must match the hiddenSize argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second 
            dimension of the first tensor described in xDesc. The third dimension must match the numLayers argument 
            passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="hx">Data pointer to GPU memory associated with the tensor descriptor hxDesc. If a NULL pointer 
            is passed, the initial hidden state of the network will be initialized to zero.</param>
            <param name="cxDesc">Handle to a previously initialized tensor descriptor describing the initial 
            cell state for LSTM networks. The first dimension of the tensor must match the hiddenSize argument 
            passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match 
            the second dimension of the first tensor described in xDesc. The third dimension must match the numLayers 
            argument passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully 
            packed.</param>
            <param name="cx">Data pointer to GPU memory associated with the tensor descriptor cxDesc. If a NULL pointer is 
            passed, the initial cell state of the network will be initialized to zero.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor describing the weights for the RNN.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor wDesc.</param>
            <param name="yDesc">An array of tensor descriptors describing the output from each recurrent iteration. The first 
            dimension of the tensor depends on the direction argument passed to the cudnnSetRNNDescriptor 
            call used to initialize rnnDesc: 
            * If direction is CUDNN_UNIDIRECTIONAL the first dimension should match the hiddenSize 
            argument passed to cudnnSetRNNDescriptor.
            * If direction is CUDNN_BIDIRECTIONAL the first dimension should match double the hiddenSize 
            argument passed to cudnnSetRNNDescriptor.
            The second dimension of the tensor n must match the second dimension of the tensor 
            n in xDesc. The tensor must be fully packed.</param>
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor yDesc.</param>
            <param name="hyDesc">Handle to a previously initialized tensor descriptor describing the final 
            hidden state of the RNN. The first dimension of the tensor must match the hiddenSize argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second dimension 
            of the first tensor described in xDesc. The third dimension must match the numLayers argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="hy">Data pointer to GPU memory associated with the tensor descriptor hyDesc. If a 
            NULL pointer is passed, the final hidden state of the network will not be saved.</param>
            <param name="cyDesc">Handle to a previously initialized tensor descriptor describing the final cell state 
            for LSTM networks. The first dimension of the tensor must match the hiddenSize argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second dimension 
            of the first tensor described in xDesc. The third dimension must match the numLayers argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="cy">Data pointer to GPU memory associated with the tensor descriptor cyDesc. If a NULL pointer is 
            passed, the final cell state of the network will be not be saved.</param>
            <param name="workspace">Data pointer to GPU memory to be used as a workspace for this call.</param>
            <param name="workSpaceSizeInBytes">Specifies the size in bytes of the provided workspace.</param>
            <param name="reserveSpace">Data pointer to GPU memory to be used as a reserve space for this call.</param>
            <param name="reserveSpaceSizeInBytes">Specifies the size in bytes of the provided reserveSpace.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.RNNDescriptor.RNNBackwardData(ManagedCuda.CudaDNN.TensorDescriptor[],ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor[],ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor[],ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDeviceVariable{System.Byte},ManagedCuda.BasicTypes.SizeT,ManagedCuda.CudaDeviceVariable{System.Byte},ManagedCuda.BasicTypes.SizeT)">
            <summary>
            This routine executes the recurrent neural network described by rnnDesc with 
            output gradients dy, dhy, dhc, weights w and input gradients dx, dhx, dcx. 
            workspace is required for intermediate storage. The data in reserveSpace must have 
            previously been generated by cudnnRNNForwardTraining. The same reserveSpace data must 
            be used for future calls to cudnnRNNBackwardWeights if they execute on the same input data. 
            </summary>
            <param name="yDesc">An array of tensor descriptors describing the output from each 
            recurrent iteration. The first dimension of the tensor depends on the direction 
            argument passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc:
            * If direction is CUDNN_UNIDIRECTIONAL the first dimension should match the hiddenSize 
            argument passed to cudnnSetRNNDescriptor.
            * If direction is CUDNN_BIDIRECTIONAL the first dimension should match double the 
            hiddenSize argument passed to cudnnSetRNNDescriptor.
            The second dimension of the tensor n must match the second dimension of the tensor n in dyDesc. 
            The tensor must be fully packed.</param>
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor yDesc.</param>
            <param name="dyDesc">An array of tensor descriptors describing the gradient at the output from each 
            recurrent iteration. The first dimension of the tensor depends on the direction argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc: 
            * If direction is CUDNN_UNIDIRECTIONAL the first dimension should match the hiddenSize 
            argument passed to cudnnSetRNNDescriptor.
            * If direction is CUDNN_BIDIRECTIONAL the first dimension should match double the hiddenSize 
            argument passed to cudnnSetRNNDescriptor.
            The second dimension of the tensor n must match the second dimension of the tensor n in dxDesc. The 
            tensor must be fully packed.</param>
            <param name="dy">Data pointer to GPU memory associated with the tensor descriptors in the array dyDesc.</param>
            <param name="dhyDesc">Handle to a previously initialized tensor descriptor describing the gradients at the 
            final hidden state of the RNN. The first dimension of the tensor must match the hiddenSize argument passed 
            to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second 
            dimension of the first tensor described in dyDesc. The third dimension must match the numLayers argument 
            passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="dhy">Data pointer to GPU memory associated with the tensor descriptor dhyDesc. If a NULL pointer 
            is passed, the gradients at the final hidden state of the network will be initialized to zero.</param>
            <param name="dcyDesc">Handle to a previously initialized tensor descriptor describing the gradients at 
            the final cell state of the RNN. The first dimension of the tensor must match the hiddenSize argument 
            passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the 
            second dimension of the first tensor described in dyDesc. The third dimension must match the numLayers argument 
            passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="dcy">Data pointer to GPU memory associated with the tensor descriptor dcyDesc. If a NULL pointer 
            is passed, the gradients at the final cell state of the network will be initialized to zero.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor describing the weights for the RNN.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor wDesc.</param>
            <param name="hxDesc">Handle to a previously initialized tensor descriptor describing the initial hidden 
            state of the RNN. The first dimension of the tensor must match the hiddenSize argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second 
            dimension of the first tensor described in xDesc. The third dimension must match the numLayers 
            argument passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be 
            fully packed.</param>
            <param name="hx">Data pointer to GPU memory associated with the tensor descriptor hxDesc. If a NULL pointer is 
            passed, the initial hidden state of the network will be initialized to zero.</param>
            <param name="cxDesc">Handle to a previously initialized tensor descriptor describing the 
            initial cell state for LSTM networks. The first dimension of the tensor must match the 
            hiddenSize argument passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The 
            second dimension must match the second dimension of the first tensor described in xDesc. The 
            third dimension must match the numLayers argument passed to the cudnnSetRNNDescriptor call 
            used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="cx">Data pointer to GPU memory associated with the tensor descriptor cxDesc. 
            If a NULL pointer is passed, the initial cell state of the network will be initialized to zero.</param>
            <param name="dxDesc">An array of tensor descriptors describing the gradient at the input of each recurrent iteration. 
            Each tensor descriptor must have the same first dimension. The second dimension of the tensors may decrease from 
            element n to element n+1 but may not increase. The tensor must be fully packed.</param>
            <param name="dx">Data pointer to GPU memory associated with the tensor descriptors in the array dxDesc. </param>
            <param name="dhxDesc">Handle to a previously initialized tensor descriptor describing the gradient at the initial hidden 
            state of the RNN. The first dimension of the tensor must match the hiddenSize argument passed to the cudnnSetRNNDescriptor 
            call used to initialize rnnDesc. The second dimension must match the second dimension of the first tensor described in xDesc. 
            The third dimension must match the numLayers argument passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. 
            The tensor must be fully packed.</param>
            <param name="dhx">Data pointer to GPU memory associated with the tensor descriptor dhxDesc. If a NULL pointer is passed, the 
            gradient at the hidden input of the network will not be set.</param>
            <param name="dcxDesc">Handle to a previously initialized tensor descriptor describing the gradient 
            at the initial cell state of the RNN. The first dimension of the tensor must match the hiddenSize argument passed 
            to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second dimension 
            of the first tensor described in xDesc. The third dimension must match the numLayers argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="dcx">Data pointer to GPU memory associated with the tensor descriptor dcxDesc. If 
            a NULL pointer is passed, the gradient at the cell input of the network will not be set.</param>
            <param name="workspace">Data pointer to GPU memory to be used as a workspace for this call.</param>
            <param name="workSpaceSizeInBytes">Specifies the size in bytes of the provided workspace.</param>
            <param name="reserveSpace">Data pointer to GPU memory to be used as a reserve space for this call.</param>
            <param name="reserveSpaceSizeInBytes">Specifies the size in bytes of the provided reserveSpace.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.RNNDescriptor.RNNBackwardData(ManagedCuda.CudaDNN.TensorDescriptor[],ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor[],ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor[],ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDeviceVariable{System.Byte},ManagedCuda.BasicTypes.SizeT,ManagedCuda.CudaDeviceVariable{System.Byte},ManagedCuda.BasicTypes.SizeT)">
            <summary>
            This routine executes the recurrent neural network described by rnnDesc with 
            output gradients dy, dhy, dhc, weights w and input gradients dx, dhx, dcx. 
            workspace is required for intermediate storage. The data in reserveSpace must have 
            previously been generated by cudnnRNNForwardTraining. The same reserveSpace data must 
            be used for future calls to cudnnRNNBackwardWeights if they execute on the same input data. 
            </summary>
            <param name="yDesc">An array of tensor descriptors describing the output from each 
            recurrent iteration. The first dimension of the tensor depends on the direction 
            argument passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc:
            * If direction is CUDNN_UNIDIRECTIONAL the first dimension should match the hiddenSize 
            argument passed to cudnnSetRNNDescriptor.
            * If direction is CUDNN_BIDIRECTIONAL the first dimension should match double the 
            hiddenSize argument passed to cudnnSetRNNDescriptor.
            The second dimension of the tensor n must match the second dimension of the tensor n in dyDesc. 
            The tensor must be fully packed.</param>
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor yDesc.</param>
            <param name="dyDesc">An array of tensor descriptors describing the gradient at the output from each 
            recurrent iteration. The first dimension of the tensor depends on the direction argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc: 
            * If direction is CUDNN_UNIDIRECTIONAL the first dimension should match the hiddenSize 
            argument passed to cudnnSetRNNDescriptor.
            * If direction is CUDNN_BIDIRECTIONAL the first dimension should match double the hiddenSize 
            argument passed to cudnnSetRNNDescriptor.
            The second dimension of the tensor n must match the second dimension of the tensor n in dxDesc. The 
            tensor must be fully packed.</param>
            <param name="dy">Data pointer to GPU memory associated with the tensor descriptors in the array dyDesc.</param>
            <param name="dhyDesc">Handle to a previously initialized tensor descriptor describing the gradients at the 
            final hidden state of the RNN. The first dimension of the tensor must match the hiddenSize argument passed 
            to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second 
            dimension of the first tensor described in dyDesc. The third dimension must match the numLayers argument 
            passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="dhy">Data pointer to GPU memory associated with the tensor descriptor dhyDesc. If a NULL pointer 
            is passed, the gradients at the final hidden state of the network will be initialized to zero.</param>
            <param name="dcyDesc">Handle to a previously initialized tensor descriptor describing the gradients at 
            the final cell state of the RNN. The first dimension of the tensor must match the hiddenSize argument 
            passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the 
            second dimension of the first tensor described in dyDesc. The third dimension must match the numLayers argument 
            passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="dcy">Data pointer to GPU memory associated with the tensor descriptor dcyDesc. If a NULL pointer 
            is passed, the gradients at the final cell state of the network will be initialized to zero.</param>
            <param name="wDesc">Handle to a previously initialized filter descriptor describing the weights for the RNN.</param>
            <param name="w">Data pointer to GPU memory associated with the filter descriptor wDesc.</param>
            <param name="hxDesc">Handle to a previously initialized tensor descriptor describing the initial hidden 
            state of the RNN. The first dimension of the tensor must match the hiddenSize argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second 
            dimension of the first tensor described in xDesc. The third dimension must match the numLayers 
            argument passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be 
            fully packed.</param>
            <param name="hx">Data pointer to GPU memory associated with the tensor descriptor hxDesc. If a NULL pointer is 
            passed, the initial hidden state of the network will be initialized to zero.</param>
            <param name="cxDesc">Handle to a previously initialized tensor descriptor describing the 
            initial cell state for LSTM networks. The first dimension of the tensor must match the 
            hiddenSize argument passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The 
            second dimension must match the second dimension of the first tensor described in xDesc. The 
            third dimension must match the numLayers argument passed to the cudnnSetRNNDescriptor call 
            used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="cx">Data pointer to GPU memory associated with the tensor descriptor cxDesc. 
            If a NULL pointer is passed, the initial cell state of the network will be initialized to zero.</param>
            <param name="dxDesc">An array of tensor descriptors describing the gradient at the input of each recurrent iteration. 
            Each tensor descriptor must have the same first dimension. The second dimension of the tensors may decrease from 
            element n to element n+1 but may not increase. The tensor must be fully packed.</param>
            <param name="dx">Data pointer to GPU memory associated with the tensor descriptors in the array dxDesc. </param>
            <param name="dhxDesc">Handle to a previously initialized tensor descriptor describing the gradient at the initial hidden 
            state of the RNN. The first dimension of the tensor must match the hiddenSize argument passed to the cudnnSetRNNDescriptor 
            call used to initialize rnnDesc. The second dimension must match the second dimension of the first tensor described in xDesc. 
            The third dimension must match the numLayers argument passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc. 
            The tensor must be fully packed.</param>
            <param name="dhx">Data pointer to GPU memory associated with the tensor descriptor dhxDesc. If a NULL pointer is passed, the 
            gradient at the hidden input of the network will not be set.</param>
            <param name="dcxDesc">Handle to a previously initialized tensor descriptor describing the gradient 
            at the initial cell state of the RNN. The first dimension of the tensor must match the hiddenSize argument passed 
            to the cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second dimension 
            of the first tensor described in xDesc. The third dimension must match the numLayers argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully packed.</param>
            <param name="dcx">Data pointer to GPU memory associated with the tensor descriptor dcxDesc. If 
            a NULL pointer is passed, the gradient at the cell input of the network will not be set.</param>
            <param name="workspace">Data pointer to GPU memory to be used as a workspace for this call.</param>
            <param name="workSpaceSizeInBytes">Specifies the size in bytes of the provided workspace.</param>
            <param name="reserveSpace">Data pointer to GPU memory to be used as a reserve space for this call.</param>
            <param name="reserveSpaceSizeInBytes">Specifies the size in bytes of the provided reserveSpace.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.RNNDescriptor.RNNBackwardWeights(ManagedCuda.CudaDNN.TensorDescriptor[],ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDNN.TensorDescriptor[],ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDeviceVariable{System.Byte},ManagedCuda.BasicTypes.SizeT,ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDeviceVariable{System.Single},ManagedCuda.CudaDeviceVariable{System.Byte},ManagedCuda.BasicTypes.SizeT)">
            <summary>
            This routine accumulates weight gradients dw from the recurrent neural network described 
            by rnnDesc with inputs x, hx, and outputs y. The mode of operation in this case is additive, 
            the weight gradients calculated will be added to those already existing in dw. workspace 
            is required for intermediate storage. The data in reserveSpace must have previously been 
            generated by cudnnRNNBackwardData.
            </summary>
            <param name="xDesc">An array of tensor descriptors describing the input to each recurrent iteration. 
            Each tensor descriptor must have the same first dimension. The second dimension of the tensors may 
            decrease from element n to element n+1 but may not increase. The tensor must be fully packed.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptors in the array xDesc.</param>
            <param name="hxDesc">Handle to a previously initialized tensor descriptor describing the initial hidden 
            state of the RNN. The first dimension of the tensor must match the hiddenSize argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second dimension
            of the first tensor described in xDesc. The third dimension must match the numLayers argument passed to 
            the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully packed. </param>
            <param name="hx">Data pointer to GPU memory associated with the tensor descriptor hxDesc. If 
            a NULL pointer is passed, the initial hidden state of the network will be initialized to zero.</param>
            <param name="yDesc">An array of tensor descriptors describing the output from each 
            recurrent iteration. The first dimension of the tensor depends on the direction 
            argument passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc:
            * If direction is CUDNN_UNIDIRECTIONAL the first dimension should match the hiddenSize 
            argument passed to cudnnSetRNNDescriptor.
            * If direction is CUDNN_BIDIRECTIONAL the first dimension should match double the hiddenSize 
            argument passed to cudnnSetRNNDescriptor.
            The second dimension of the tensor n must match the second dimension of the tensor n in dyDesc. 
            The tensor must be fully packed.</param>
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor yDesc.</param>
            <param name="workspace">Data pointer to GPU memory to be used as a workspace for this call.</param>
            <param name="workSpaceSizeInBytes">Specifies the size in bytes of the provided workspace.</param>
            <param name="dwDesc">Handle to a previously initialized filter descriptor describing the gradients of the weights for the RNN.</param>
            <param name="dw">Data pointer to GPU memory associated with the filter descriptor dwDesc.</param>
            <param name="reserveSpace">Data pointer to GPU memory to be used as a reserve space for this call.</param>
            <param name="reserveSpaceSizeInBytes">Specifies the size in bytes of the provided reserveSpace.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.RNNDescriptor.RNNBackwardWeights(ManagedCuda.CudaDNN.TensorDescriptor[],ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDNN.TensorDescriptor[],ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDeviceVariable{System.Byte},ManagedCuda.BasicTypes.SizeT,ManagedCuda.CudaDNN.FilterDescriptor,ManagedCuda.CudaDeviceVariable{System.Double},ManagedCuda.CudaDeviceVariable{System.Byte},ManagedCuda.BasicTypes.SizeT)">
            <summary>
            This routine accumulates weight gradients dw from the recurrent neural network described 
            by rnnDesc with inputs x, hx, and outputs y. The mode of operation in this case is additive, 
            the weight gradients calculated will be added to those already existing in dw. workspace 
            is required for intermediate storage. The data in reserveSpace must have previously been 
            generated by cudnnRNNBackwardData.
            </summary>
            <param name="xDesc">An array of tensor descriptors describing the input to each recurrent iteration. 
            Each tensor descriptor must have the same first dimension. The second dimension of the tensors may 
            decrease from element n to element n+1 but may not increase. The tensor must be fully packed.</param>
            <param name="x">Data pointer to GPU memory associated with the tensor descriptors in the array xDesc.</param>
            <param name="hxDesc">Handle to a previously initialized tensor descriptor describing the initial hidden 
            state of the RNN. The first dimension of the tensor must match the hiddenSize argument passed to the 
            cudnnSetRNNDescriptor call used to initialize rnnDesc. The second dimension must match the second dimension
            of the first tensor described in xDesc. The third dimension must match the numLayers argument passed to 
            the cudnnSetRNNDescriptor call used to initialize rnnDesc. The tensor must be fully packed. </param>
            <param name="hx">Data pointer to GPU memory associated with the tensor descriptor hxDesc. If 
            a NULL pointer is passed, the initial hidden state of the network will be initialized to zero.</param>
            <param name="yDesc">An array of tensor descriptors describing the output from each 
            recurrent iteration. The first dimension of the tensor depends on the direction 
            argument passed to the cudnnSetRNNDescriptor call used to initialize rnnDesc:
            * If direction is CUDNN_UNIDIRECTIONAL the first dimension should match the hiddenSize 
            argument passed to cudnnSetRNNDescriptor.
            * If direction is CUDNN_BIDIRECTIONAL the first dimension should match double the hiddenSize 
            argument passed to cudnnSetRNNDescriptor.
            The second dimension of the tensor n must match the second dimension of the tensor n in dyDesc. 
            The tensor must be fully packed.</param>
            <param name="y">Data pointer to GPU memory associated with the output tensor descriptor yDesc.</param>
            <param name="workspace">Data pointer to GPU memory to be used as a workspace for this call.</param>
            <param name="workSpaceSizeInBytes">Specifies the size in bytes of the provided workspace.</param>
            <param name="dwDesc">Handle to a previously initialized filter descriptor describing the gradients of the weights for the RNN.</param>
            <param name="dw">Data pointer to GPU memory associated with the filter descriptor dwDesc.</param>
            <param name="reserveSpace">Data pointer to GPU memory to be used as a reserve space for this call.</param>
            <param name="reserveSpaceSizeInBytes">Specifies the size in bytes of the provided reserveSpace.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.RNNDescriptor.SetPersistentRNNPlan(ManagedCuda.CudaDNN.PersistentRNNPlan)">
            <summary>
            This function sets the persistent RNN plan to be executed when using rnnDesc and
            CUDNN_RNN_ALGO_PERSIST_DYNAMIC algo.
            </summary>
            <param name="plan"></param>
        </member>
        <member name="P:ManagedCuda.CudaDNN.RNNDescriptor.MathType">
            <summary>
            The math type specified in a given RNN descriptor.
            </summary>
        </member>
        <member name="T:ManagedCuda.CudaDNN.SpatialTransformerDescriptor">
            <summary>
            An opaque structure holding the
            description of a generic n-D dataset.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.SpatialTransformerDescriptor.#ctor(ManagedCuda.CudaDNN.CudaDNNContext)">
            <summary>
            
            </summary>
            <param name="context"></param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.SpatialTransformerDescriptor.Finalize">
            <summary>
            For dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.SpatialTransformerDescriptor.Dispose">
            <summary>
            Dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.SpatialTransformerDescriptor.Dispose(System.Boolean)">
            <summary>
            For IDisposable
            </summary>
            <param name="fDisposing"></param>
        </member>
        <member name="P:ManagedCuda.CudaDNN.SpatialTransformerDescriptor.Desc">
            <summary>
            Returns the inner handle.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.SpatialTransformerDescriptor.SetSpatialTransformerNdDescriptor(ManagedCuda.CudaDNN.cudnnSamplerType,ManagedCuda.CudaDNN.cudnnDataType,System.Int32,System.Int32[])">
            <summary>
            This function destroys a previously created spatial transformer descriptor object. 
            </summary>
            <param name="samplerType">Enumerant to specify the sampler type.</param>
            <param name="dataType">Data type.</param>
            <param name="nbDims">Dimension of the transformed tensor.</param>
            <param name="dimA">Array of dimension nbDims containing the size of the transformed tensor for every dimension.</param>
        </member>
        <member name="T:ManagedCuda.CudaDNN.TensorDescriptor">
            <summary>
            An opaque structure holding the
            description of a generic n-D dataset.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.TensorDescriptor.#ctor">
            <summary>
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.TensorDescriptor.Finalize">
            <summary>
            For dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.TensorDescriptor.Dispose">
            <summary>
            Dispose
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.TensorDescriptor.Dispose(System.Boolean)">
            <summary>
            For IDisposable
            </summary>
            <param name="fDisposing"></param>
        </member>
        <member name="P:ManagedCuda.CudaDNN.TensorDescriptor.Desc">
            <summary>
            Returns the inner handle.
            </summary>
        </member>
        <member name="M:ManagedCuda.CudaDNN.TensorDescriptor.SetTensor4dDescriptor(ManagedCuda.CudaDNN.cudnnTensorFormat,ManagedCuda.CudaDNN.cudnnDataType,System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            This function initializes a previously created generic Tensor descriptor object into a
            4D tensor. The strides of the four dimensions are inferred from the format parameter
            and set in such a way that the data is contiguous in memory with no padding between
            dimensions.
            </summary>
            <param name="format">Type of format.</param>
            <param name="dataType">Data type.</param>
            <param name="n">Number of images.</param>
            <param name="c">Number of feature maps per image.</param>
            <param name="h">Height of each feature map.</param>
            <param name="w">Width of each feature map.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.TensorDescriptor.SetTensor4dDescriptorEx(ManagedCuda.CudaDNN.cudnnDataType,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            This function initializes a previously created generic Tensor descriptor object into a
            4D tensor, similarly to cudnnSetTensor4dDescriptor but with the strides explicitly
            passed as parameters. This can be used to lay out the 4D tensor in any order or simply to
            define gaps between dimensions.
            </summary>
            <param name="dataType">Data type.</param>
            <param name="n">Number of images.</param>
            <param name="c">Number of feature maps per image.</param>
            <param name="h">Height of each feature map.</param>
            <param name="w">Width of each feature map.</param>
            <param name="nStride">Stride between two consecutive images.</param>
            <param name="cStride">Stride between two consecutive feature maps.</param>
            <param name="hStride">Stride between two consecutive rows.</param>
            <param name="wStride">Stride between two consecutive columns.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.TensorDescriptor.GetTensor4dDescriptor(ManagedCuda.CudaDNN.cudnnDataType@,System.Int32@,System.Int32@,System.Int32@,System.Int32@,System.Int32@,System.Int32@,System.Int32@,System.Int32@)">
            <summary>
            This function queries the parameters of the previouly initialized Tensor4D descriptor object.
            </summary>
            <param name="dataType">Data type.</param>
            <param name="n">Number of images.</param>
            <param name="c">Number of feature maps per image.</param>
            <param name="h">Height of each feature map.</param>
            <param name="w">Width of each feature map.</param>
            <param name="nStride">Stride between two consecutive images.</param>
            <param name="cStride">Stride between two consecutive feature maps.</param>
            <param name="hStride">Stride between two consecutive rows.</param>
            <param name="wStride">Stride between two consecutive columns.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.TensorDescriptor.SetTensorNdDescriptor(ManagedCuda.CudaDNN.cudnnDataType,System.Int32,System.Int32[],System.Int32[])">
            <summary>
            This function initializes a previously created generic Tensor descriptor object.
            </summary>
            <param name="dataType">Data type.</param>
            <param name="nbDims">Dimension of the tensor.</param>
            <param name="dimA">Array of dimension nbDims that contain the size of the tensor for every dimension.</param>
            <param name="strideA">Array of dimension nbDims that contain the stride of the tensor for every dimension.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.TensorDescriptor.SetTensorNdDescriptorEx(ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.CudaDNN.cudnnTensorFormat,ManagedCuda.CudaDNN.cudnnDataType,System.Int32,System.Int32[])">
            <summary>
            This function initializes a previously created generic Tensor descriptor object.
            </summary>
            <param name="tensorDesc">Handle to a previously created tensor descriptor.</param>
            <param name="format"></param>
            <param name="dataType">Data type.</param>
            <param name="nbDims">Dimension of the tensor.</param>
            <param name="dimA">Array of dimension nbDims that contain the size of the tensor for every dimension.</param>
        </member>
        <member name="M:ManagedCuda.CudaDNN.TensorDescriptor.GetTensorSizeInBytes">
            <summary>
            This function returns the size of the tensor in memory in respect to the given descriptor.
            This function can be used to know the amount of GPU memory to be allocated to hold that tensor.
            </summary>
            <returns>Size in bytes needed to hold the tensor in GPU memory.</returns>
        </member>
        <member name="M:ManagedCuda.CudaDNN.TensorDescriptor.GetTensorNdDescriptor(System.Int32,ManagedCuda.CudaDNN.cudnnDataType@,System.Int32@,System.Int32[],System.Int32[])">
            <summary>
            This function retrieves values stored in a previously initialized Tensor descriptor object.
            </summary>
            <param name="nbDimsRequested">Number of dimensions to extract from a given tensor descriptor. It is
            also the minimum size of the arrays dimA and strideA. If this number is
            greater than the resulting nbDims[0], only nbDims[0] dimensions will be
            returned.</param>
            <param name="dataType">Data type.</param>
            <param name="nbDims">Actual number of dimensions of the tensor will be returned in nbDims[0].</param>
            <param name="dimA">Array of dimension of at least nbDimsRequested that will be filled with
            the dimensions from the provided tensor descriptor.</param>
            <param name="strideA">Array of dimension of at least nbDimsRequested that will be filled with
            the strides from the provided tensor descriptor.</param>
        </member>
    </members>
</doc>
